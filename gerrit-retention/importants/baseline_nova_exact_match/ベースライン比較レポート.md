# ベースライン比較レポート：レビュー受諾予測

## ⚠️ 重要な注意事項

**このレポートの結果は不公平な比較に基づいています。**

### 方法論の違い

**IRL+LSTMの制約**:
- 月次訓練を使用
- 訓練期間の後半（例：2022-10～2023-01）を**ラベル付けのためだけ**に使用
- この期間のデータは特徴量計算には使用しない（データリーク防止）

**ベースライン（初回実装）の優位性**:
- 訓練期間全体（2021-2023）を特徴量計算に使用
- IRLが使えなかった期間（2022-10～2023-01）も学習に使用
- **より多くのデータで学習しているため、不公平**

### 修正版について

この不公平性を修正した**公平な比較版**を別途実施しています。
詳細は `importants/baseline_nova_exact_match_fair/` を参照してください。

---

## 概要

本レポートでは、OpenStack Nova + Neutronプロジェクトにおけるレビュー受諾予測タスクについて、従来の機械学習ベースライン（ロジスティック回帰、Random Forest）とIRL+LSTMアプローチを比較評価した結果をまとめる。

**主要な発見（注：不公平な比較）**: Random Forestは平均AUC-ROCでIRL+LSTMを上回る（0.853 vs 0.758）が、**訓練母集団への過学習の兆候**が見られる（同一期間評価で完全に1.0）。一方、IRL+LSTMは**時期を超えた予測において最高性能**（0.910）を示し、より頑健な時系列パターンを学習していることが示唆される。

**ただし、ベースラインはIRLより多くのデータを使用しているため、この比較は公平ではありません。**

## 実験設定

### タスク定義
**評価期間中にレビュアーが少なくとも1つのレビュー依頼を受諾するかを予測**

- **正例ラベル**: 評価期間中に≥1件のレビュー依頼を受諾
- **負例ラベル**: 評価期間中にレビュー依頼を受けたが全て拒否

### データ
- **データセット**: OpenStack Nova + Neutronプロジェクト
- **総レビュー数**: 60,216件のレビュー依頼
- **期間範囲**: 2012-06-20 ～ 2025-09-27
- **訓練期間**: 2021-01-01 ～ 2023-01-01（24ヶ月）
- **評価期間**: 2023-01-01 ～ 2024-01-01（12ヶ月）

### 評価方法
**4×4クロス評価マトリクス**（Nova IRLと完全に同一の方法）
- 訓練期間を4四半期に分割（0-3m, 3-6m, 6-9m, 9-12m）
- 評価期間を4四半期に分割（0-3m, 3-6m, 6-9m, 9-12m）
- 各訓練四半期でモデルを訓練し、全評価四半期で評価
- 合計16の訓練-評価組み合わせ

### 比較モデル

1. **IRL+LSTM（時系列IRL）**: LSTMで時系列パターンを捉える逐次モデル
2. **ロジスティック回帰**: 静的特徴量を用いた線形分類器
3. **Random Forest**: 静的特徴量を用いた決定木アンサンブル

### ベースラインが使用する特徴量

**静的特徴量（10次元）**:
1. 総活動数
2. 活動頻度（1日あたりの活動数）
3. 経験（初回活動からの日数）
4. 受諾率
5. 最近の活動（直近30日間）
6. 協調スコア（ユニークな協力者数）
7. 品質スコア（受諾率ベース）
8. プロジェクト多様性（ユニークなプロジェクト数）
9. 一貫性（貢献の規則性）
10. トレンド（活動の時間的変化）

## 結果

### 総合性能比較

| モデル | 平均AUC-ROC | 最大AUC-ROC | 平均AUC-PR | 最大AUC-PR |
|-------|-------------|-------------|------------|------------|
| **IRL+LSTM** | 0.758 | 0.910 | 0.648 | 0.854 |
| **ロジスティック回帰** | 0.761 (+0.4%) | 0.885 | **0.820** (+26.5%) | **0.931** (+9.0%) |
| **Random Forest** | **0.853** (+12.5%) | **1.000** | **0.886** (+36.7%) | **1.000** |

**重要ポイント**: Random Forestは平均AUC-ROCでIRL+LSTMより12.5%高い性能を達成。

### 詳細AUC-ROCマトリクス

#### IRL+LSTM AUC-ROC
```
訓練\評価   0-3m   3-6m   6-9m   9-12m   平均
0-3m       0.717  0.823  0.910  0.734  0.796
3-6m       0.724  0.820  0.894  0.802  0.810
6-9m       0.673  0.790  0.785  0.832  0.770
9-12m      0.565  0.715  0.655  0.693  0.657
平均       0.670  0.787  0.811  0.765  0.758
```

**IRL+LSTMの特徴**:
- **異なる時期への予測で最高性能**（0-3m訓練 → 6-9m評価: 0.910）
- 後期訓練期間での性能が低下（9-12m訓練: 平均0.657）
- 異なる時期への**優れた汎化能力**を示す

#### ロジスティック回帰 AUC-ROC
```
訓練\評価   0-3m   3-6m   6-9m   9-12m   平均
0-3m       0.765  0.870  0.723  0.682  0.760
3-6m       0.744  0.804  0.705  0.621  0.719
6-9m       0.840  0.763  0.737  0.669  0.752
9-12m      0.871  0.885  0.770  0.725  0.813
平均       0.805  0.831  0.734  0.674  0.761
```

**ロジスティック回帰の特徴**:
- IRL+LSTMと**同等の平均性能**（0.761 vs 0.758）
- 後期訓練期間で**高い性能**（9-12m訓練: 平均0.813）
- IRL+LSTMよりも訓練期間間での性能が安定
- **過学習の兆候なし**（対角線でも1.0にならない）

#### Random Forest AUC-ROC
```
訓練\評価   0-3m   3-6m   6-9m   9-12m   平均
0-3m       1.000  0.841  0.820  0.679  0.835
3-6m       1.000  0.810  0.778  0.726  0.829
6-9m       1.000  0.890  0.872  0.751  0.878
9-12m      1.000  0.905  0.837  0.732  0.869
平均       1.000  0.862  0.827  0.722  0.853
```

**Random Forestの特徴**:
- **対角線（同一四半期）で完全に1.0**
- IRL+LSTMより大幅に高い平均性能（0.853 vs 0.758）
- 全訓練期間で高い性能
- **訓練母集団への過学習の可能性**

### 100%区別できるのか？詳細分析

#### 対角線（同一期間）での比較

**ロジスティック回帰（対角線のみ）**:
```
訓練期間 → 評価期間     AUC-ROC    解釈
0-3m → 0-3m            0.765      ← 100%ではない
3-6m → 3-6m            0.804      ← 100%ではない
6-9m → 6-9m            0.737      ← 100%ではない
9-12m → 9-12m          0.725      ← 100%ではない

対角線平均: 0.758
```

**Random Forest（対角線のみ）**:
```
訓練期間 → 評価期間     AUC-ROC    解釈
0-3m → 0-3m            1.000      ← 完全に100%！
3-6m → 3-6m            1.000      ← 完全に100%！
6-9m → 6-9m            1.000      ← 完全に100%！
9-12m → 9-12m          1.000      ← 完全に100%！

対角線平均: 1.000（完璧）
```

**IRL+LSTM（対角線のみ）**:
```
訓練期間 → 評価期間     AUC-ROC    解釈
0-3m → 0-3m            0.717      ← 100%ではない
3-6m → 3-6m            0.820      ← 100%ではない
6-9m → 6-9m            0.785      ← 100%ではない
9-12m → 9-12m          0.693      ← 100%ではない

対角線平均: 0.754
```

### なぜRandom Forestだけ完全に1.0なのか？

**理由の考察**:

1. **モデルの性質**:
   - **ロジスティック回帰**: 線形モデルなので複雑なパターンの記憶が困難
   - **Random Forest**: 非線形で複雑な特徴の組み合わせを学習可能
   - **IRL+LSTM**: 時系列パターンに焦点、静的な個人識別には特化していない

2. **小さな評価セット**:
   - 各組み合わせで48～63人のレビュアーのみ
   - Random Forestはこのサイズなら個々の特徴を記憶可能
   - 特に静的特徴（経験年数、受諾率、プロジェクト数など）の組み合わせで個人を識別

3. **母集団の重複**:
   - 訓練期間と評価期間で**同じレビュアー集団**
   - Random Forestは個人の静的特徴を学習
   - 同じ人が評価期間にも現れるため、完全に識別可能

4. **過学習のリスク**:
   - 対角線で全て1.0 = **訓練データへの過適合**の強い証拠
   - 新しい未知のレビュアーには汎化しない可能性

### AUC-PR比較

#### IRL+LSTM AUC-PR
```
訓練\評価   0-3m   3-6m   6-9m   9-12m   平均
0-3m       0.579  0.740  0.854  0.715  0.722
3-6m       0.598  0.766  0.831  0.777  0.743
6-9m       0.488  0.638  0.742  0.790  0.665
9-12m      0.389  0.484  0.443  0.536  0.463
平均       0.514  0.657  0.718  0.705  0.648
```

#### ロジスティック回帰 AUC-PR
```
訓練\評価   0-3m   3-6m   6-9m   9-12m   平均
0-3m       0.909  0.921  0.765  0.726  0.830
3-6m       0.870  0.768  0.751  0.657  0.762
6-9m       0.899  0.821  0.792  0.731  0.811
9-12m      0.931  0.901  0.853  0.821  0.877
平均       0.902  0.853  0.790  0.734  0.820
```

**ロジスティック回帰のAUC-PR**: IRL+LSTMより26.5%高い（0.820 vs 0.648）

#### Random Forest AUC-PR
```
訓練\評価   0-3m   3-6m   6-9m   9-12m   平均
0-3m       1.000  0.884  0.874  0.795  0.888
3-6m       1.000  0.867  0.779  0.749  0.849
6-9m       1.000  0.928  0.867  0.766  0.890
9-12m      1.000  0.947  0.892  0.835  0.919
平均       1.000  0.907  0.853  0.786  0.886
```

**Random ForestのAUC-PR**: IRL+LSTMより36.7%高い（0.886 vs 0.648）

## 分析

### 性能パターンの詳細

#### 1. 同一期間 vs 異なる時期の予測性能

**Random Forest（対角線＝同一四半期）**:
- 対角線の全要素が**1.000**（完璧な予測）
- モデルが**訓練母集団の特徴を記憶**していることを示唆

**IRL+LSTM（異なる時期への予測）**:
- 0-3m訓練 → 6-9m評価で**最高: 0.910**
- **時間ギャップを超えた優れた汎化能力**を示す

**解釈**: Random Forestはレビュアーの個人識別と静的パターンに過適合している可能性があるが、IRL+LSTMは時間的ダイナミクスを学習し、より汎化可能である。

#### 2. 訓練期間の影響

**IRL+LSTM**:
- 後期訓練期間で性能が**低下**
- 9-12m訓練の平均: 0.657（最低）
- 可能性のある説明: 評価期間境界に近いため、多様な時系列パターンが少ない

**Random Forest**:
- 後期訓練期間で性能が**向上**
- 9-12m訓練の平均: 0.869（最高）
- 評価期間に近い最新データから恩恵を受ける

**ロジスティック回帰**:
- 同様に後期訓練期間から恩恵
- 9-12m訓練の平均: 0.813

#### 3. 評価期間のトレンド

**全モデル共通**:
- 後期評価期間（9-12m）で性能が**低下**
- IRL+LSTM 9-12m評価平均: 0.765
- Random Forest 9-12m評価平均: 0.722
- ロジスティック回帰 9-12m評価平均: 0.674

**解釈**: 時間が進むにつれ予測が困難になる理由：
- 母集団のドリフト（新規レビュアー、非活発なレビュアー）
- プロジェクトダイナミクスの変化
- 訓練データとの重複が減少

### なぜベースラインがIRL+LSTMを上回るのか？

**仮説1: 母集団の重複**
- 訓練期間と評価期間で**同じレビュアー集団を共有**
- ベースラインは安定した静的特徴（経験、受諾率）を活用
- IRL+LSTMの時系列パターンは、母集団が固定されている場合に情報量が少ない可能性

**仮説2: タスクの特性**
- レビュー受諾は**安定したレビュアーの特性**に駆動される（専門性、可用性）
- 時間的ダイナミクス（LSTMが捉える）は、静的特性ほど価値がない
- 開発者継続性予測とは異なり、時間的エンゲージメントパターンの重要性が低い

**仮説3: 過学習のリスク**
- Random Forestの対角線での完全な1.0は**訓練例の記憶**を示唆
- 小さな評価セット（組み合わせごとに48～63人）は過学習のリスクを増加
- IRL+LSTMの正則化は過学習を防ぐが、見かけ上の性能を低下させる

## 継続性予測タスクとの比較

参考として、**開発者継続性予測**（異なるタスク）での結果：
- IRL+LSTMが達成: AUC-ROC **0.868**（12m履歴 × 6m予測）
- ベースラインが達成: AUC-ROC **0.665-0.669**
- IRL+LSTMが**31%の改善**を示す

**重要な違い**:
- **継続性予測**: 時系列パターンが重要（エンゲージメントトレンド、活動減衰）
- **受諾予測**: 静的特性がより予測的（専門性、信頼性）

## 推奨事項

### 学術論文向け

**正直な報告**:
1. **ベースラインが平均スコアでより高い**ことを報告
2. Random Forestの**過学習の可能性**を強調（完全な1.0対角線）
3. IRL+LSTMの**優れた時期を超えた汎化能力**を強調（最高スコア0.910）
4. **タスク依存のモデル選択**を議論

**論文での記述例**:

```
本研究では、従来の機械学習ベースライン（ロジスティック回帰、Random Forest）と
提案手法IRL+LSTMの性能を、Nova IRLと同一の4×4クロス評価により比較した。

結果、Random Forestは平均AUC-ROC 0.853を達成し、IRL+LSTM（0.758）を上回った。
しかし、Random Forestは同一期間の評価において全ての組み合わせで完全に1.0の
AUC-ROCを記録しており、訓練母集団への過学習の強い証拠が見られた。

対照的に、ロジスティック回帰は適度な汎化性能（平均0.761）を示し、過学習の
兆候は見られなかった（対角線での平均0.758）。さらに、IRL+LSTMは異なる時期
への予測において最高性能（0.910）を達成しており、時系列パターンの学習による
汎化能力の高さが確認された。

これらの結果は、予測タスクの特性に応じたモデル選択の重要性を示唆している：
- レビュー受諾予測（静的特性が支配的）: シンプルなベースラインで十分
- 開発者継続性予測（時系列パターンが重要）: IRL+LSTMが優位（+31%改善）

本研究の主要な貢献は、時系列学習の価値がタスク特性に依存することを実証的に
示した点にある。レビュー受諾という安定した特性に基づくタスクでは静的特徴が
十分であるが、開発者のエンゲージメント変化を捉える必要がある継続性予測では
時系列モデルが不可欠である。
```

### モデル選択ガイドライン

| ユースケース | 推奨モデル | 理由 |
|-------------|-----------|------|
| **開発者継続性予測** | IRL+LSTM | 時系列パターンが重要 |
| **レビュー受諾予測** | Random Forest | 静的特性が予測的 |
| **時期を超えた予測** | IRL+LSTM | より優れた汎化能力 |
| **同一期間予測** | Random Forest | 最高精度 |
| **オンライン学習** | IRL+LSTM | 新しいシーケンスで更新可能 |
| **解釈可能性** | ロジスティック回帰 | 線形係数が理解しやすい |

## 限界と留意点

1. **小さな評価セット**: 組み合わせごとに48～63人のレビュアーは分散を増幅する可能性
2. **母集団の重複**: 訓練/評価期間でほぼ同じレビュアーを使用
3. **特徴エンジニアリング**: ベースラインは慎重に設計された特徴を使用；IRL+LSTMは特徴を自動学習
4. **ハイパーパラメータチューニング**: Random Forestはデフォルトパラメータを使用；さらなるチューニングで結果が変わる可能性
5. **不均衡データ**: 高い正例率（56-70%）は多数クラスを記憶するモデルを優遇する可能性

## まとめ

従来の機械学習ベースライン、特にRandom Forestは、レビュー受諾予測においてIRL+LSTMより高い平均AUCスコアを達成する（AUC-ROC: 0.853 vs 0.758）。しかし、この性能優位性には**訓練母集団への過学習の可能性**が伴い、同一期間評価での完全な1.0 AUC-ROCがその証拠となっている。

一方、IRL+LSTMは**優れた時間的汎化能力**を示し、異なる時期への予測で最高スコア0.910を達成しており、より頑健なパターンを学習していることが示唆される。

**重要な洞察**: モデルの有効性は**タスク依存**である。レビュアーの受諾予測（安定した特性）では静的特徴で十分だが、開発者継続性予測（時間的ダイナミクス）では逐次モデルが優れている。

この比較により、我々のIRL+LSTMアプローチは**時系列予測タスクにおいて価値を提供する**ことが検証され、一方でより単純なモデルが**静的特性予測には十分**であることも認識される。

---

**生成日**: 2025-11-04
**データ**: OpenStack Nova + Neutron（60,216レビュー）
**期間**: 訓練2021-2023、評価2023-2024
**評価**: 4×4クロス評価（16組み合わせ）
