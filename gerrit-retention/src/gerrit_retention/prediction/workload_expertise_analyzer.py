"""
ä½œæ¥­è² è·ãƒ»å°‚é–€æ€§ä¸€è‡´ç‡åˆ†æã‚·ã‚¹ãƒ†ãƒ 

é–‹ç™ºè€…ã®ä½œæ¥­è² è·ã€å°‚é–€æ€§ã®ä¸€è‡´ç‡ã€ã‚¹ãƒˆãƒ¬ã‚¹æŒ‡æ¨™ã‚’è€ƒæ…®ã—ãŸ
é«˜åº¦ãªç¶™ç¶šç‡äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import logging
import re
import warnings
from collections import Counter, defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

warnings.filterwarnings('ignore')

class WorkloadExpertiseAnalyzer:
    """ä½œæ¥­è² è·ãƒ»å°‚é–€æ€§ä¸€è‡´ç‡åˆ†æã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = self._setup_logger()
        self.project_expertise_profiles = {}
        self.developer_expertise_profiles = {}
        self.workload_metrics = {}
        self.expertise_similarity_cache = {}
        
    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚¬ãƒ¼ã®è¨­å®š"""
        logger = logging.getLogger('WorkloadExpertiseAnalyzer')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def analyze_workload_features(self, developer_data: Dict[str, Any]) -> Dict[str, float]:
        """ä½œæ¥­è² è·ç‰¹å¾´é‡ã®åˆ†æ"""
        features = {}
        
        # åŸºæœ¬æ´»å‹•é‡
        changes_authored = developer_data.get('changes_authored', 0)
        changes_reviewed = developer_data.get('changes_reviewed', 0)
        total_insertions = developer_data.get('total_insertions', 0)
        total_deletions = developer_data.get('total_deletions', 0)
        
        # æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®è² è·è¨ˆç®—
        try:
            first_seen = datetime.fromisoformat(
                developer_data.get('first_seen', '').replace(' ', 'T')
            )
            last_activity = datetime.fromisoformat(
                developer_data.get('last_activity', '').replace(' ', 'T')
            )
            
            activity_duration = (last_activity - first_seen).days
            if activity_duration > 0:
                # æ—¥æ¬¡ä½œæ¥­è² è·
                features['daily_changes_load'] = (changes_authored + changes_reviewed) / activity_duration
                features['daily_code_load'] = (total_insertions + total_deletions) / activity_duration
                
                # ä½œæ¥­å¼·åº¦ï¼ˆã‚³ãƒ¼ãƒ‰è¡Œæ•°/ãƒã‚§ãƒ³ã‚¸æ•°ï¼‰
                total_changes = changes_authored + changes_reviewed
                if total_changes > 0:
                    features['code_intensity'] = (total_insertions + total_deletions) / total_changes
                else:
                    features['code_intensity'] = 0.0
            else:
                features['daily_changes_load'] = 0.0
                features['daily_code_load'] = 0.0
                features['code_intensity'] = 0.0
        except:
            features['daily_changes_load'] = 0.0
            features['daily_code_load'] = 0.0
            features['code_intensity'] = 0.0
        
        # ä½œæ¥­ãƒãƒ©ãƒ³ã‚¹æŒ‡æ¨™
        if changes_authored + changes_reviewed > 0:
            features['authoring_ratio'] = changes_authored / (changes_authored + changes_reviewed)
            features['reviewing_ratio'] = changes_reviewed / (changes_authored + changes_reviewed)
        else:
            features['authoring_ratio'] = 0.0
            features['reviewing_ratio'] = 0.0
        
        # ä½œæ¥­è² è·ãƒ¬ãƒ™ãƒ«ã®åˆ†é¡
        total_workload = features['daily_changes_load'] + features['daily_code_load'] / 1000
        
        if total_workload > 5.0:
            features['workload_level'] = 4.0  # éè² è·
            features['workload_stress'] = 1.0
        elif total_workload > 2.0:
            features['workload_level'] = 3.0  # é«˜è² è·
            features['workload_stress'] = 0.7
        elif total_workload > 0.5:
            features['workload_level'] = 2.0  # ä¸­è² è·
            features['workload_stress'] = 0.3
        elif total_workload > 0.1:
            features['workload_level'] = 1.0  # ä½è² è·
            features['workload_stress'] = 0.1
        else:
            features['workload_level'] = 0.0  # ç„¡è² è·
            features['workload_stress'] = 0.0
        
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼è² è·ã‚¹ãƒˆãƒ¬ã‚¹
        review_scores = developer_data.get('review_scores', [])
        if review_scores:
            negative_reviews = sum(1 for score in review_scores if score < 0)
            review_stress_ratio = negative_reviews / len(review_scores)
            features['review_stress'] = review_stress_ratio
            
            # ãƒ¬ãƒ“ãƒ¥ãƒ¼è² è·ã®å¤‰å‹•æ€§ï¼ˆã‚¹ãƒˆãƒ¬ã‚¹æŒ‡æ¨™ï¼‰
            features['review_volatility'] = np.std(review_scores) if len(review_scores) > 1 else 0.0
        else:
            features['review_stress'] = 0.0
            features['review_volatility'] = 0.0
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æ•£è² è·
        projects = developer_data.get('projects', [])
        if projects:
            features['project_fragmentation'] = len(projects)
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–“ã®è² è·åˆ†æ•£åº¦ï¼ˆå¤šã™ãã‚‹ã¨åˆ†æ•£è² è·ï¼‰
            if len(projects) > 5:
                features['fragmentation_stress'] = min(1.0, (len(projects) - 5) * 0.2)
            else:
                features['fragmentation_stress'] = 0.0
        else:
            features['project_fragmentation'] = 0.0
            features['fragmentation_stress'] = 0.0
        
        return features
    
    def analyze_expertise_match(self, developer_data: Dict[str, Any]) -> Dict[str, float]:
        """å°‚é–€æ€§ä¸€è‡´ç‡ã®åˆ†æ"""
        features = {}
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå°‚é–€æ€§ã®åˆ†æ
        projects = developer_data.get('projects', [])
        developer_id = developer_data.get('developer_id', '')
        
        if not projects:
            return {
                'expertise_match_score': 0.0,
                'domain_consistency': 0.0,
                'skill_alignment': 0.0,
                'expertise_confidence': 0.0,
                'cross_domain_penalty': 0.0
            }
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‹ã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³æ¨å®š
        domain_keywords = self._extract_domain_keywords(projects)
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ä¸€è²«æ€§
        if domain_keywords:
            domain_counts = Counter(domain_keywords)
            total_domains = len(domain_keywords)
            max_domain_count = max(domain_counts.values())
            features['domain_consistency'] = max_domain_count / total_domains
            
            # ä¸»è¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ç‰¹å®š
            primary_domain = domain_counts.most_common(1)[0][0]
            features['primary_domain_ratio'] = max_domain_count / total_domains
        else:
            features['domain_consistency'] = 0.0
            features['primary_domain_ratio'] = 0.0
        
        # æ´»å‹•é‡ã¨å°‚é–€æ€§ã®é–¢ä¿‚
        changes_authored = developer_data.get('changes_authored', 0)
        changes_reviewed = developer_data.get('changes_reviewed', 0)
        
        # å°‚é–€æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        expertise_indicators = []
        
        # 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé›†ä¸­åº¦ï¼ˆå°‚é–€æ€§ã®æŒ‡æ¨™ï¼‰
        if len(projects) <= 3:
            expertise_indicators.append(0.8)  # é«˜ã„å°‚é–€æ€§
        elif len(projects) <= 6:
            expertise_indicators.append(0.6)  # ä¸­ç¨‹åº¦ã®å°‚é–€æ€§
        else:
            expertise_indicators.append(0.3)  # åˆ†æ•£ã—ãŸæ´»å‹•
        
        # 2. æ´»å‹•ã®æ·±ã•ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼æ¯”ç‡ãŒé«˜ã„ = å°‚é–€æ€§ï¼‰
        total_activity = changes_authored + changes_reviewed
        if total_activity > 0:
            review_ratio = changes_reviewed / total_activity
            if review_ratio > 0.7:
                expertise_indicators.append(0.9)  # é«˜ã„å°‚é–€æ€§ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­å¿ƒï¼‰
            elif review_ratio > 0.3:
                expertise_indicators.append(0.7)  # ãƒãƒ©ãƒ³ã‚¹å‹
            else:
                expertise_indicators.append(0.5)  # ä½œæˆä¸­å¿ƒ
        else:
            expertise_indicators.append(0.0)
        
        # 3. ã‚³ãƒ¼ãƒ‰å“è³ªæŒ‡æ¨™ï¼ˆå°‚é–€æ€§ã®é–“æ¥æŒ‡æ¨™ï¼‰
        review_scores = developer_data.get('review_scores', [])
        if review_scores:
            avg_score = np.mean(review_scores)
            positive_ratio = sum(1 for s in review_scores if s > 0) / len(review_scores)
            quality_score = (avg_score + 2) / 4 * positive_ratio  # -2~2ã‚’0~1ã«æ­£è¦åŒ–
            expertise_indicators.append(min(1.0, max(0.0, quality_score)))
        else:
            expertise_indicators.append(0.5)
        
        # å°‚é–€æ€§ãƒãƒƒãƒã‚¹ã‚³ã‚¢ã®çµ±åˆ
        if expertise_indicators:
            features['expertise_match_score'] = np.mean(expertise_indicators)
            features['expertise_confidence'] = 1.0 - np.std(expertise_indicators)
        else:
            features['expertise_match_score'] = 0.0
            features['expertise_confidence'] = 0.0
        
        # ã‚¹ã‚­ãƒ«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆæ´»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¸€è²«æ€§ï¼‰
        features['skill_alignment'] = self._calculate_skill_alignment(developer_data)
        
        # ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒšãƒŠãƒ«ãƒ†ã‚£
        unique_domains = len(set(domain_keywords)) if domain_keywords else 0
        if unique_domains > 3:
            features['cross_domain_penalty'] = min(1.0, (unique_domains - 3) * 0.2)
        else:
            features['cross_domain_penalty'] = 0.0
        
        return features
    
    def _extract_domain_keywords(self, projects: List[str]) -> List[str]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‹ã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        domain_keywords = []
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ†é¡è¾æ›¸
        domain_mapping = {
            'web': ['web', 'http', 'html', 'css', 'js', 'frontend', 'backend'],
            'database': ['db', 'sql', 'mysql', 'postgres', 'mongo', 'redis'],
            'cloud': ['aws', 'gcp', 'azure', 'cloud', 'docker', 'k8s', 'kubernetes'],
            'mobile': ['android', 'ios', 'mobile', 'app'],
            'ai_ml': ['ml', 'ai', 'tensorflow', 'pytorch', 'data', 'analytics'],
            'security': ['security', 'auth', 'crypto', 'ssl', 'tls'],
            'devops': ['ci', 'cd', 'deploy', 'build', 'test', 'jenkins'],
            'ui_ux': ['ui', 'ux', 'design', 'theme', 'style'],
            'api': ['api', 'rest', 'graphql', 'grpc'],
            'system': ['system', 'kernel', 'driver', 'os'],
            'network': ['network', 'tcp', 'udp', 'socket', 'protocol'],
            'office': ['office', 'document', 'word', 'excel', 'calc', 'writer'],
            'translation': ['l10n', 'i18n', 'translation', 'locale', 'lang'],
            'openstack': ['openstack', 'nova', 'neutron', 'cinder', 'keystone', 'glance', 'heat'],
            'libreoffice': ['libreoffice', 'core', 'writer', 'calc', 'impress', 'draw'],
            'chromium': ['chromium', 'chrome', 'blink', 'v8'],
            'wikimedia': ['wikimedia', 'wikipedia', 'mediawiki']
        }
        
        for project in projects:
            project_lower = project.lower()
            
            # ç›´æ¥ãƒãƒƒãƒãƒ³ã‚°
            for domain, keywords in domain_mapping.items():
                if any(keyword in project_lower for keyword in keywords):
                    domain_keywords.append(domain)
                    break
            else:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
                if 'openstack/' in project_lower:
                    domain_keywords.append('openstack')
                elif any(x in project_lower for x in ['core', 'main', 'base']):
                    domain_keywords.append('core')
                else:
                    domain_keywords.append('other')
        
        return domain_keywords
    
    def _calculate_skill_alignment(self, developer_data: Dict[str, Any]) -> float:
        """ã‚¹ã‚­ãƒ«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®è¨ˆç®—"""
        changes_authored = developer_data.get('changes_authored', 0)
        changes_reviewed = developer_data.get('changes_reviewed', 0)
        total_insertions = developer_data.get('total_insertions', 0)
        total_deletions = developer_data.get('total_deletions', 0)
        
        alignment_factors = []
        
        # 1. ä½œæˆ/ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒãƒ©ãƒ³ã‚¹
        total_changes = changes_authored + changes_reviewed
        if total_changes > 0:
            balance_score = 1.0 - abs(0.5 - (changes_authored / total_changes))
            alignment_factors.append(balance_score)
        
        # 2. ã‚³ãƒ¼ãƒ‰å¤‰æ›´ã®ä¸€è²«æ€§
        if changes_authored > 0:
            avg_lines_per_change = (total_insertions + total_deletions) / changes_authored
            # é©åº¦ãªã‚µã‚¤ã‚ºã®å¤‰æ›´ãŒä¸€è²«æ€§ã‚’ç¤ºã™
            if 10 <= avg_lines_per_change <= 500:
                consistency_score = 1.0
            elif avg_lines_per_change < 10:
                consistency_score = avg_lines_per_change / 10
            else:
                consistency_score = max(0.0, 1.0 - (avg_lines_per_change - 500) / 1000)
            alignment_factors.append(consistency_score)
        
        # 3. æŒ¿å…¥/å‰Šé™¤ãƒãƒ©ãƒ³ã‚¹
        total_lines = total_insertions + total_deletions
        if total_lines > 0:
            insertion_ratio = total_insertions / total_lines
            # é©åº¦ãªæŒ¿å…¥/å‰Šé™¤ãƒãƒ©ãƒ³ã‚¹
            balance_score = 1.0 - abs(0.6 - insertion_ratio)  # 60%æŒ¿å…¥ãŒç†æƒ³çš„
            alignment_factors.append(balance_score)
        
        return np.mean(alignment_factors) if alignment_factors else 0.0
    
    def calculate_burnout_risk(self, developer_data: Dict[str, Any], 
                              workload_features: Dict[str, float],
                              expertise_features: Dict[str, float]) -> Dict[str, float]:
        """ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯ã®è¨ˆç®—"""
        risk_factors = {}
        
        # 1. ä½œæ¥­è² è·ãƒªã‚¹ã‚¯
        workload_stress = workload_features.get('workload_stress', 0.0)
        review_stress = workload_features.get('review_stress', 0.0)
        fragmentation_stress = workload_features.get('fragmentation_stress', 0.0)
        
        workload_risk = (workload_stress * 0.4 + review_stress * 0.3 + 
                        fragmentation_stress * 0.3)
        risk_factors['workload_burnout_risk'] = workload_risk
        
        # 2. å°‚é–€æ€§ãƒŸã‚¹ãƒãƒƒãƒãƒªã‚¹ã‚¯
        expertise_match = expertise_features.get('expertise_match_score', 0.0)
        cross_domain_penalty = expertise_features.get('cross_domain_penalty', 0.0)
        
        mismatch_risk = (1.0 - expertise_match) * 0.7 + cross_domain_penalty * 0.3
        risk_factors['expertise_mismatch_risk'] = mismatch_risk
        
        # 3. ç¶™ç¶šæ€§ãƒªã‚¹ã‚¯
        try:
            last_activity = datetime.fromisoformat(
                developer_data.get('last_activity', '').replace(' ', 'T')
            )
            days_since_last = (datetime.now() - last_activity).days
            
            if days_since_last > 90:
                continuity_risk = min(1.0, days_since_last / 365)
            else:
                continuity_risk = 0.0
        except:
            continuity_risk = 1.0
        
        risk_factors['continuity_risk'] = continuity_risk
        
        # 4. ç·åˆãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯
        total_risk = (workload_risk * 0.35 + mismatch_risk * 0.35 + 
                     continuity_risk * 0.30)
        risk_factors['total_burnout_risk'] = total_risk
        
        # 5. ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®åˆ†é¡
        if total_risk > 0.7:
            risk_factors['burnout_level'] = 'critical'
            risk_factors['burnout_score'] = 4.0
        elif total_risk > 0.5:
            risk_factors['burnout_level'] = 'high'
            risk_factors['burnout_score'] = 3.0
        elif total_risk > 0.3:
            risk_factors['burnout_level'] = 'medium'
            risk_factors['burnout_score'] = 2.0
        elif total_risk > 0.1:
            risk_factors['burnout_level'] = 'low'
            risk_factors['burnout_score'] = 1.0
        else:
            risk_factors['burnout_level'] = 'minimal'
            risk_factors['burnout_score'] = 0.0
        
        return risk_factors
    
    def generate_workload_recommendations(self, developer_data: Dict[str, Any],
                                        workload_features: Dict[str, float],
                                        expertise_features: Dict[str, float],
                                        burnout_risk: Dict[str, float]) -> List[str]:
        """ä½œæ¥­è² è·ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
        recommendations = []
        
        # ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
        burnout_level = burnout_risk.get('burnout_level', 'minimal')
        
        if burnout_level == 'critical':
            recommendations.append("ğŸš¨ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯ã§ã™ã€‚å³åº§ã«ä½œæ¥­è² è·ã‚’è»½æ¸›ã—ã¦ãã ã•ã„")
            recommendations.append("ğŸ›‘ ä¸€æ™‚çš„ãªä½œæ¥­åœæ­¢ã¨ä¼‘æ¯ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™")
        elif burnout_level == 'high':
            recommendations.append("âš ï¸ é«˜ã„ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯ã§ã™ã€‚ä½œæ¥­è² è·ã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™")
            recommendations.append("ğŸ“‰ ä½œæ¥­é‡ã‚’30-50%å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        elif burnout_level == 'medium':
            recommendations.append("âš–ï¸ ä¸­ç¨‹åº¦ã®ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯ã§ã™ã€‚ä½œæ¥­ãƒãƒ©ãƒ³ã‚¹ã®èª¿æ•´ã‚’æ¨å¥¨ã—ã¾ã™")
        
        # ä½œæ¥­è² è·å›ºæœ‰ã®æ¨å¥¨
        workload_stress = workload_features.get('workload_stress', 0.0)
        if workload_stress > 0.7:
            recommendations.append("ğŸ“Š ä½œæ¥­è² è·ãŒéå¤§ã§ã™ã€‚ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆé †ä½ä»˜ã‘ã¨åˆ†æ•£ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        review_stress = workload_features.get('review_stress', 0.0)
        if review_stress > 0.5:
            recommendations.append("ğŸ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒå¤šã„ã§ã™ã€‚ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°ã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã—ã¦ãã ã•ã„")
        
        fragmentation_stress = workload_features.get('fragmentation_stress', 0.0)
        if fragmentation_stress > 0.3:
            recommendations.append("ğŸ”„ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒåˆ†æ•£ã—ã™ãã¦ã„ã¾ã™ã€‚ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’çµã£ã¦ãã ã•ã„")
        
        # å°‚é–€æ€§ãƒŸã‚¹ãƒãƒƒãƒã®æ¨å¥¨
        expertise_match = expertise_features.get('expertise_match_score', 0.0)
        if expertise_match < 0.4:
            recommendations.append("ğŸ¯ å°‚é–€æ€§ã¨ã‚¿ã‚¹ã‚¯ã®ãƒŸã‚¹ãƒãƒƒãƒãŒã‚ã‚Šã¾ã™ã€‚ã‚¹ã‚­ãƒ«ã«åˆã£ãŸä½œæ¥­ã®å‰²ã‚Šå½“ã¦ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
            recommendations.append("ğŸ“š å¿…è¦ãªã‚¹ã‚­ãƒ«ç¿’å¾—ã®ãŸã‚ã®ç ”ä¿®æ©Ÿä¼šã‚’æä¾›ã—ã¦ãã ã•ã„")
        
        cross_domain_penalty = expertise_features.get('cross_domain_penalty', 0.0)
        if cross_domain_penalty > 0.3:
            recommendations.append("ğŸŒ è¤‡æ•°ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã¾ãŸãŒã‚‹ä½œæ¥­ãŒè² æ‹…ã«ãªã£ã¦ã„ã¾ã™ã€‚å°‚é–€é ˜åŸŸã¸ã®é›†ä¸­ã‚’æ¨å¥¨ã—ã¾ã™")
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–ãªæ¨å¥¨
        if burnout_level in ['minimal', 'low']:
            if expertise_match > 0.7:
                recommendations.append("âœ¨ å°‚é–€æ€§ã¨ä½œæ¥­ãŒè‰¯ããƒãƒƒãƒã—ã¦ã„ã¾ã™ã€‚ç¾åœ¨ã®æ–¹å‘æ€§ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„")
            
            workload_level = workload_features.get('workload_level', 0.0)
            if workload_level == 2.0:  # é©åº¦ãªè² è·
                recommendations.append("âš–ï¸ é©åº¦ãªä½œæ¥­è² è·ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿ã£ã¦ãã ã•ã„")
        
        # æˆé•·æ©Ÿä¼šã®æ¨å¥¨
        skill_alignment = expertise_features.get('skill_alignment', 0.0)
        if skill_alignment > 0.6:
            recommendations.append("ğŸš€ ã‚¹ã‚­ãƒ«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãŒè‰¯å¥½ã§ã™ã€‚ã‚ˆã‚ŠæŒ‘æˆ¦çš„ãªã‚¿ã‚¹ã‚¯ã¸ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚¢ãƒƒãƒ—ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        return recommendations
    
    def analyze_comprehensive_features(self, developer_data: Dict[str, Any]) -> Dict[str, float]:
        """åŒ…æ‹¬çš„ãªç‰¹å¾´é‡åˆ†æ"""
        # æ—¢å­˜ã®ç‰¹å¾´é‡
        from .advanced_accuracy_improver import AdvancedAccuracyImprover
        config = {'output_path': 'temp'}
        improver = AdvancedAccuracyImprover(config)
        base_features = improver.extract_advanced_features(developer_data)
        
        # ä½œæ¥­è² è·ç‰¹å¾´é‡
        workload_features = self.analyze_workload_features(developer_data)
        
        # å°‚é–€æ€§ç‰¹å¾´é‡
        expertise_features = self.analyze_expertise_match(developer_data)
        
        # ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯
        burnout_risk = self.calculate_burnout_risk(developer_data, workload_features, expertise_features)
        
        # å…¨ç‰¹å¾´é‡ã®çµ±åˆ
        comprehensive_features = {}
        comprehensive_features.update(base_features)
        comprehensive_features.update(workload_features)
        comprehensive_features.update(expertise_features)
        comprehensive_features.update(burnout_risk)
        
        return comprehensive_features
    
    def generate_comprehensive_analysis(self, developer_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãªé–‹ç™ºè€…åˆ†æ"""
        # ç‰¹å¾´é‡ã®æŠ½å‡º
        workload_features = self.analyze_workload_features(developer_data)
        expertise_features = self.analyze_expertise_match(developer_data)
        burnout_risk = self.calculate_burnout_risk(developer_data, workload_features, expertise_features)
        
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ
        recommendations = self.generate_workload_recommendations(
            developer_data, workload_features, expertise_features, burnout_risk
        )
        
        # ç·åˆã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        workload_score = 1.0 - workload_features.get('workload_stress', 0.0)
        expertise_score = expertise_features.get('expertise_match_score', 0.0)
        burnout_score = 1.0 - burnout_risk.get('total_burnout_risk', 0.0)
        
        overall_wellness_score = (workload_score * 0.4 + expertise_score * 0.3 + 
                                burnout_score * 0.3)
        
        return {
            'workload_analysis': workload_features,
            'expertise_analysis': expertise_features,
            'burnout_risk': burnout_risk,
            'recommendations': recommendations,
            'wellness_scores': {
                'workload_score': workload_score,
                'expertise_score': expertise_score,
                'burnout_score': burnout_score,
                'overall_wellness': overall_wellness_score
            }
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    config = {
        'output_path': 'outputs/workload_expertise_analysis'
    }
    
    analyzer = WorkloadExpertiseAnalyzer(config)
    
    print("ğŸ”§ ä½œæ¥­è² è·ãƒ»å°‚é–€æ€§åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    return analyzer

if __name__ == "__main__":
    main()