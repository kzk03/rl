#!/usr/bin/env python3
"""
è¶…é‡è¦ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
ãƒ¬ãƒ“ãƒ¥ãƒ¼æ‰¿è«¾äºˆæ¸¬IRLå­¦ç¿’ï¼ˆæ­£ã—ã„ãƒ­ã‚¸ãƒƒã‚¯ç‰ˆï¼‰

ç›®çš„ï¼š
- ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ãŸé–‹ç™ºè€…ãŒã€ãã®ä¾é ¼ã‚’æ‰¿è«¾ã™ã‚‹ã‹ã©ã†ã‹ã‚’äºˆæ¸¬
- ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ã¦ã„ãªã„é–‹ç™ºè€…ã¯åˆ¤å®šå¯¾è±¡å¤–ã¨ã—ã¦é™¤å¤–

ç¶™ç¶šåˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼š
- è©•ä¾¡æœŸé–“å†…ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ã¦ã„ãªã„ â†’ é™¤å¤–
- è©•ä¾¡æœŸé–“å†…ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ã¦ã€å°‘ãªãã¨ã‚‚1ã¤æ‰¿è«¾ â†’ æ­£ä¾‹ï¼ˆç¶™ç¶šï¼‰
- è©•ä¾¡æœŸé–“å†…ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ãŸãŒã€å…¨ã¦æ‹’å¦ â†’ è² ä¾‹ï¼ˆé›¢è„±ï¼‰

ãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼š
- label = 1: ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã«å¿œç­”ï¼ˆæ‰¿è«¾ï¼‰
- label = 0: ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã«å¿œç­”ã›ãšï¼ˆæ‹’å¦/ç„¡è¦–ï¼‰
"""
from __future__ import annotations

import argparse
import json
import logging
import random
import sys
from pathlib import Path
from typing import Any, Dict, List

import numpy as np
import pandas as pd
import torch

# ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰å›ºå®š
RANDOM_SEED = 777
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed(RANDOM_SEED)
    torch.cuda.manual_seed_all(RANDOM_SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
from sklearn.metrics import (
    auc,
    f1_score,
    precision_recall_curve,
    precision_score,
    recall_score,
    roc_auc_score,
)

ROOT = Path(__file__).resolve().parents[3]
SRC = ROOT / "src"
if str(SRC) not in sys.path:
    sys.path.append(str(SRC))

from gerrit_retention.rl_prediction.retention_irl_network_with_attention import (
    RetentionIRLNetworkWithAttention,
)
from gerrit_retention.rl_prediction.retention_irl_system import RetentionIRLSystem

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_review_requests(csv_path: str) -> pd.DataFrame:
    """
    ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        csv_path: ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    logger.info(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿: {csv_path}")
    df = pd.read_csv(csv_path)
    df['request_time'] = pd.to_datetime(df['request_time'])
    logger.info(f"ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼æ•°: {len(df)}")
    logger.info(f"æ‰¿è«¾æ•°: {(df['label']==1).sum()} ({(df['label']==1).sum()/len(df)*100:.1f}%)")
    logger.info(f"æ‹’å¦æ•°: {(df['label']==0).sum()} ({(df['label']==0).sum()/len(df)*100:.1f}%)")
    return df


def extract_review_acceptance_trajectories(
    df: pd.DataFrame,
    train_start: pd.Timestamp,
    train_end: pd.Timestamp,
    future_window_start_months: int = 0,
    future_window_end_months: int = 3,
    min_history_requests: int = 3,
    reviewer_col: str = 'reviewer_email',
    date_col: str = 'request_time',
    label_col: str = 'label',
    project: str = None,
    extended_label_window_months: int = 12
) -> List[Dict[str, Any]]:
    """
    ãƒ¬ãƒ“ãƒ¥ãƒ¼æ‰¿è«¾äºˆæ¸¬ç”¨ã®è»Œè·¡ã‚’æŠ½å‡ºï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ãªã—ç‰ˆï¼‰

    é‡è¦ï¼šè¨“ç·´æœŸé–“å†…ã§å®Œçµã•ã›ã‚‹ãŸã‚ã€è¨“ç·´æœŸé–“ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«åˆ†å‰²ï¼š
    - **ç‰¹å¾´é‡è¨ˆç®—æœŸé–“**: train_start ï½ (train_end - future_window_end_months)
    - **ãƒ©ãƒ™ãƒ«è¨ˆç®—æœŸé–“**: ç‰¹å¾´é‡è¨ˆç®—æœŸé–“çµ‚äº†å¾Œ ï½ train_end

    ã“ã‚Œã«ã‚ˆã‚Šã€è¨“ç·´æœŸé–“ï¼ˆtrain_endï¼‰ã‚’è¶…ãˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã›ãšã«ãƒ©ãƒ™ãƒ«ä»˜ã‘ãŒå¯èƒ½ã€‚

    ç‰¹å¾´ï¼š
    - **è¨“ç·´**ï¼šç‰¹å¾´é‡è¨ˆç®—æœŸé–“å†…ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ãŸé–‹ç™ºè€…ã®ã¿ã‚’å¯¾è±¡
    - **æ­£ä¾‹**ï¼šãƒ©ãƒ™ãƒ«è¨ˆç®—æœŸé–“å†…ã«å°‘ãªãã¨ã‚‚1ã¤ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’æ‰¿è«¾ã—ãŸ
    - **è² ä¾‹**ï¼šãƒ©ãƒ™ãƒ«è¨ˆç®—æœŸé–“å†…ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ãŸãŒã€å…¨ã¦æ‹’å¦ã—ãŸ
    - **è² ä¾‹ï¼ˆæ‹¡å¼µï¼‰**ï¼šãƒ©ãƒ™ãƒ«è¨ˆç®—æœŸé–“ã«ä¾é ¼ãªã—ï¼ˆã“ã®æœŸé–“ã§ã¯æ´»å‹•ãªã—ï¼‰ã€æ‹¡å¼µæœŸé–“ã«ä¾é ¼ã‚ã‚Š
    - **é™¤å¤–**ï¼šæ‹¡å¼µæœŸé–“å†…ã«ã‚‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ã¦ã„ãªã„é–‹ç™ºè€…ï¼ˆæœ¬å½“ã«é›¢è„±ï¼‰

    Args:
        df: ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿
        train_start: å­¦ç¿’é–‹å§‹æ—¥
        train_end: å­¦ç¿’çµ‚äº†æ—¥
        future_window_start_months: å°†æ¥çª“é–‹å§‹ï¼ˆæœˆæ•°ï¼‰
        future_window_end_months: å°†æ¥çª“çµ‚äº†ï¼ˆæœˆæ•°ï¼‰
        min_history_requests: æœ€å°å±¥æ­´ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼æ•°
        reviewer_col: ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼åˆ—å
        date_col: æ—¥ä»˜åˆ—å
        label_col: ãƒ©ãƒ™ãƒ«åˆ—åï¼ˆ1=æ‰¿è«¾, 0=æ‹’å¦ï¼‰
        project: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆæŒ‡å®šæ™‚ã¯å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ï¼‰
        extended_label_window_months: æ‹¡å¼µãƒ©ãƒ™ãƒ«æœŸé–“ï¼ˆæœˆæ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ12ï¼‰

    Returns:
        å„ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®è»Œè·¡ã®ãƒªã‚¹ãƒˆï¼ˆ1ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼=1ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    """
    logger.info("=" * 80)
    logger.info("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ‰¿è«¾äºˆæ¸¬ç”¨è»Œè·¡æŠ½å‡ºã‚’é–‹å§‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ãªã—ç‰ˆï¼‰")
    logger.info(f"è¨“ç·´æœŸé–“å…¨ä½“: {train_start} ï½ {train_end}")
    logger.info(f"å°†æ¥çª“: {future_window_start_months}ï½{future_window_end_months}ãƒ¶æœˆ")
    logger.info(f"æ‹¡å¼µãƒ©ãƒ™ãƒ«æœŸé–“: {future_window_start_months}ï½{extended_label_window_months}ãƒ¶æœˆ")
    if project:
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project} (å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ)")
    else:
        logger.info("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
    logger.info("ãƒ©ãƒ™ãƒ«å®šç¾©: ã“ã®æœŸé–“ã§æ‰¿è«¾=1ã€ã“ã®æœŸé–“ã§æ‹’å¦=0ã€ä¾é ¼ãªã—â†’æ‹¡å¼µæœŸé–“ãƒã‚§ãƒƒã‚¯ã€è¨“ç·´æ™‚ã¯æ‹¡å¼µæœŸé–“ã«ã‚‚ä¾é ¼ãªã—ã§é™¤å¤–")
    logger.info("ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢: è¨“ç·´æœŸé–“å†…ã§ãƒ©ãƒ™ãƒ«è¨ˆç®—")
    logger.info("=" * 80)
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨
    if project and 'project' in df.columns:
        df = df[df['project'] == project].copy()
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œ: {len(df)}ä»¶")
    
    trajectories = []
    
    # è¨“ç·´æœŸé–“å…¨ä½“ã‚’ç‰¹å¾´é‡è¨ˆç®—ã«ä½¿ç”¨ï¼ˆå›ºå®šï¼‰
    history_start = train_start
    history_end = train_end
    
    # ãƒ©ãƒ™ãƒ«è¨ˆç®—ã¯å„æœˆæœ«æ™‚ç‚¹ã‹ã‚‰å°†æ¥çª“ã‚’è¦‹ã‚‹ï¼ˆæœˆæ¬¡ãƒ©ãƒ™ãƒ«ç”¨ï¼‰
    # ã“ã“ã§ã¯å…¨ä½“ã®ãƒã‚¸ãƒ†ã‚£ãƒ–/ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ¤å®šç”¨ã«train_endæ™‚ç‚¹ã‹ã‚‰ã®ãƒ©ãƒ™ãƒ«ã‚’è¨ˆç®—
    label_start = train_end + pd.DateOffset(months=future_window_start_months)
    label_end = train_end + pd.DateOffset(months=future_window_end_months)
    
    logger.info(f"ç‰¹å¾´é‡è¨ˆç®—æœŸé–“ï¼ˆè¨“ç·´å…¨ä½“ï¼‰: {history_start} ï½ {history_end}")
    logger.info(f"å…¨ä½“ãƒ©ãƒ™ãƒ«æœŸé–“ï¼ˆtrain_endæ™‚ç‚¹ã‹ã‚‰ï¼‰: {label_start} ï½ {label_end}")
    
    # ç‰¹å¾´é‡è¨ˆç®—æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿
    history_df = df[
        (df[date_col] >= history_start) &
        (df[date_col] < history_end)
    ]
    
    # ãƒ©ãƒ™ãƒ«è¨ˆç®—æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿
    label_df = df[
        (df[date_col] >= label_start) &
        (df[date_col] < label_end)
    ]

    # æ‹¡å¼µãƒ©ãƒ™ãƒ«è¨ˆç®—æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿
    extended_label_start = train_end + pd.DateOffset(months=future_window_start_months)
    extended_label_end = train_end + pd.DateOffset(months=extended_label_window_months)
    extended_label_df = df[
        (df[date_col] >= extended_label_start) &
        (df[date_col] < extended_label_end)
    ]

    # ç‰¹å¾´é‡è¨ˆç®—æœŸé–“å†…ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ãŸãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’å¯¾è±¡
    active_reviewers = history_df[reviewer_col].unique()
    logger.info(f"ç‰¹å¾´é‡è¨ˆç®—æœŸé–“å†…ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æ•°: {len(active_reviewers)}")

    skipped_min_requests = 0
    skipped_no_requests_until_end = 0  # è¨“ç·´æœŸé–“æœ«å°¾ã¾ã§ä¾é ¼ãŒãªã„ï¼ˆé™¤å¤–ï¼‰
    positive_count = 0
    negative_count = 0
    negative_with_requests = 0  # ä¾é ¼ã‚ã‚Šâ†’æ‹’å¦
    negative_without_requests = 0  # ä¾é ¼ãªã—ï¼ˆæ‹¡å¼µæœŸé–“ã«ä¾é ¼ã‚ã‚Šï¼‰
    
    for reviewer in active_reviewers:
        # ç‰¹å¾´é‡è¨ˆç®—æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼
        reviewer_history = history_df[history_df[reviewer_col] == reviewer]
        
        # æœ€å°ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼æ•°ã‚’æº€ãŸã•ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if len(reviewer_history) < min_history_requests:
            skipped_min_requests += 1
            continue
        
        # ãƒ©ãƒ™ãƒ«è¨ˆç®—æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ï¼ˆè¨“ç·´æœŸé–“å†…ï¼‰
        reviewer_label = label_df[label_df[reviewer_col] == reviewer]

        # ãƒ©ãƒ™ãƒ«è¨ˆç®—æœŸé–“ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ã¦ã„ãªã„å ´åˆã€æ‹¡å¼µæœŸé–“ã‚’ãƒã‚§ãƒƒã‚¯
        if len(reviewer_label) == 0:
            # æ‹¡å¼µæœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’ãƒã‚§ãƒƒã‚¯
            reviewer_extended_label = extended_label_df[extended_label_df[reviewer_col] == reviewer]

            # è¨“ç·´æ™‚ã¯æ‹¡å¼µæœŸé–“ã¾ã§è¦‹ã¦é™¤å¤–åˆ¤å®š
            if len(reviewer_extended_label) == 0:
                # æ‹¡å¼µæœŸé–“ã«ã‚‚ä¾é ¼ãŒãªã„ â†’ è¨“ç·´æœŸé–“æœ«å°¾ã¾ã§ã‚¢ã‚µã‚¤ãƒ³ãŒãªã„ â†’ é™¤å¤–ï¼ˆå®Ÿè³ªé›¢è„±è€…ï¼‰
                skipped_no_requests_until_end += 1
                continue  # ã“ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
            
            # æ‹¡å¼µæœŸé–“ã«ä¾é ¼ãŒã‚ã‚‹ â†’ å†ã³ã‚¢ã‚µã‚¤ãƒ³ã•ã‚Œã‚‹å¯èƒ½æ€§ â†’ é‡ã¿ä»˜ãè² ä¾‹
            future_acceptance = False  # ã“ã®æœŸé–“ã§ã¯æ´»å‹•ãªã—
            accepted_requests = pd.DataFrame()  # ç©º
            rejected_requests = pd.DataFrame()  # ç©ºï¼ˆä¾é ¼è‡ªä½“ãŒãªã„ï¼‰
            had_requests = False  # ã“ã®æœŸé–“ã«ä¾é ¼ãŒãªã‹ã£ãŸ
            sample_weight = 0.1  # éå¸¸ã«ä½ã„é‡ã¿ï¼ˆä¾é ¼ãªã—ï¼‰

            # çµ±è¨ˆã‚«ã‚¦ãƒ³ãƒˆ
            negative_count += 1
            negative_without_requests += 1
        else:
            # é€šå¸¸ã®ãƒ©ãƒ™ãƒ«æœŸé–“ã«ä¾é ¼ãŒã‚ã‚‹å ´åˆ
            # ç¶™ç¶šåˆ¤å®šï¼šãƒ©ãƒ™ãƒ«è¨ˆç®—æœŸé–“å†…ã«å°‘ãªãã¨ã‚‚1ã¤ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’æ‰¿è«¾ã—ãŸã‹
            accepted_requests = reviewer_label[reviewer_label[label_col] == 1]
            rejected_requests = reviewer_label[reviewer_label[label_col] == 0]
            future_acceptance = len(accepted_requests) > 0
            had_requests = True  # ã“ã®æœŸé–“ã«ä¾é ¼ãŒã‚ã£ãŸ
            sample_weight = 1.0  # é€šå¸¸ã®é‡ã¿ï¼ˆä¾é ¼ã‚ã‚Šï¼‰

            if future_acceptance:
                positive_count += 1
            else:
                negative_count += 1
                negative_with_requests += 1
        
        # ç‰¹å¾´é‡è¨ˆç®—æœŸé–“ã®æœˆæ¬¡ãƒ©ãƒ™ãƒ«ã‚’è¨ˆç®—ï¼ˆè¨“ç·´ç”¨ã€ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ãªã—ï¼‰
        history_months = pd.date_range(
            start=history_start,
            end=history_end,
            freq='MS'  # æœˆåˆ
        )
        
        step_labels = []
        monthly_activity_histories = []  # å„æœˆæ™‚ç‚¹ã§ã®æ´»å‹•å±¥æ­´
        
        for month_start in history_months[:-1]:  # æœ€å¾Œã®æœˆã‚’é™¤ã
            month_end = month_start + pd.DateOffset(months=1)
            
            # ã“ã®æœˆã‹ã‚‰future_windowå¾Œã®ãƒ©ãƒ™ãƒ«è¨ˆç®—æœŸé–“
            future_start = month_end + pd.DateOffset(months=future_window_start_months)
            future_end = month_end + pd.DateOffset(months=future_window_end_months)
            
            # é‡è¦ï¼šfuture_endãŒtrain_endã‚’è¶…ãˆãªã„ã‚ˆã†ã«ã‚¯ãƒªãƒƒãƒ—ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
            if future_end > train_end:
                future_end = train_end
            
            # train_endã‚’è¶…ãˆã‚‹å ´åˆã¯ã“ã®æœˆã®ãƒ©ãƒ™ãƒ«ã¯ä½œæˆã—ãªã„
            if future_start >= train_end:
                continue
            
            # å°†æ¥æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ï¼ˆè¨“ç·´æœŸé–“å†…ã®ã¿ï¼‰
            month_future_df = df[
                (df[date_col] >= future_start) &
                (df[date_col] < future_end) &
                (df[reviewer_col] == reviewer)
            ]
            
            # ã“ã®æœˆã®ãƒ©ãƒ™ãƒ«ï¼šå°†æ¥æœŸé–“ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ã¦æ‰¿è«¾ã—ãŸã‹
            if len(month_future_df) == 0:
                # ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãªã— â†’ ãƒ©ãƒ™ãƒ«0
                month_label = 0
            else:
                # ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚ã‚Š â†’ æ‰¿è«¾ã®æœ‰ç„¡
                month_accepted = month_future_df[month_future_df[label_col] == 1]
                month_label = 1 if len(month_accepted) > 0 else 0
            
            step_labels.append(month_label)
            
            # ã“ã®æœˆæ™‚ç‚¹ï¼ˆmonth_endï¼‰ã¾ã§ã®æ´»å‹•å±¥æ­´ã‚’ä¿å­˜ï¼ˆLSTMç”¨ï¼‰
            month_history = reviewer_history[reviewer_history[date_col] < month_end]
            monthly_activities = []
            for _, row in month_history.iterrows():
                activity = {
                    'timestamp': row[date_col],  # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯å¸¸ã«date_col
                    'action_type': 'review',
                    'project': row.get('project', 'unknown'),
                    'request_time': row.get('request_time', row[date_col]),
                    'response_time': row.get('first_response_time'),  # response_timeè¨ˆç®—ç”¨
                    'accepted': row.get(label_col, 0) == 1,
                }
                monthly_activities.append(activity)
            monthly_activity_histories.append(monthly_activities)
        
        # å…¨æœŸé–“ã®æ´»å‹•å±¥æ­´ã‚‚ä¿æŒï¼ˆè©•ä¾¡ç”¨ï¼‰
        activity_history = []
        for _, row in reviewer_history.iterrows():
            activity = {
                'timestamp': row[date_col],  # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯å¸¸ã«date_col
                'action_type': 'review',
                'project': row.get('project', 'unknown'),
                'request_time': row.get('request_time', row[date_col]),
                'response_time': row.get('first_response_time'),  # response_timeè¨ˆç®—ç”¨
                'accepted': row.get(label_col, 0) == 1,
            }
            activity_history.append(activity)
        
        # é–‹ç™ºè€…æƒ…å ±
        developer_info = {
            'developer_email': reviewer,
            'first_seen': reviewer_history[date_col].min(),
            'changes_authored': 0,
            'changes_reviewed': len(reviewer_history[reviewer_history[label_col] == 1]),
            'requests_received': len(reviewer_history),
            'requests_accepted': len(reviewer_history[reviewer_history[label_col] == 1]),
            'requests_rejected': len(reviewer_history[reviewer_history[label_col] == 0]),
            'acceptance_rate': len(reviewer_history[reviewer_history[label_col] == 1]) / len(reviewer_history),
            'projects': reviewer_history['project'].unique().tolist() if 'project' in reviewer_history.columns else []
        }
        
        # è»Œè·¡ã‚’ä½œæˆï¼ˆLSTMç”¨ã«æœˆæ¬¡æ´»å‹•å±¥æ­´ã‚’è¿½åŠ ï¼‰
        trajectory = {
            'developer_info': developer_info,
            'activity_history': activity_history,  # å…¨æœŸé–“ã®æ´»å‹•å±¥æ­´ï¼ˆè©•ä¾¡ç”¨ï¼‰
            'monthly_activity_histories': monthly_activity_histories,  # å„æœˆæ™‚ç‚¹ã®æ´»å‹•å±¥æ­´ï¼ˆLSTMè¨“ç·´ç”¨ï¼‰
            'context_date': train_end,
            'step_labels': step_labels,
            'seq_len': len(step_labels),
            'reviewer': reviewer,
            'history_request_count': len(reviewer_history),
            'history_accepted_count': len(reviewer_history[reviewer_history[label_col] == 1]),
            'history_rejected_count': len(reviewer_history[reviewer_history[label_col] == 0]),
            'label_request_count': len(reviewer_label),
            'label_accepted_count': len(accepted_requests),
            'label_rejected_count': len(rejected_requests),
            'future_acceptance': future_acceptance,
            'had_requests': had_requests,  # ã“ã®æœŸé–“ã«ä¾é ¼ãŒã‚ã£ãŸã‹
            'sample_weight': sample_weight  # ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ï¼ˆä¾é ¼ãªã—=0.3ã€ä¾é ¼ã‚ã‚Š=1.0ï¼‰
        }
        
        trajectories.append(trajectory)
    
    logger.info("=" * 80)
    logger.info(f"è»Œè·¡æŠ½å‡ºå®Œäº†: {len(trajectories)}ã‚µãƒ³ãƒ—ãƒ«ï¼ˆãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ï¼‰")
    logger.info(f"  ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœ€å°ä¾é ¼æ•°æœªæº€ï¼‰: {skipped_min_requests}")
    logger.info(f"  ã‚¹ã‚­ãƒƒãƒ—ï¼ˆè¨“ç·´æœŸé–“æœ«å°¾ã¾ã§ä¾é ¼ãªã—ï¼‰: {skipped_no_requests_until_end}")
    if trajectories:
        logger.info(f"  æ­£ä¾‹ï¼ˆã“ã®æœŸé–“ã§æ‰¿è«¾ã‚ã‚Šï¼‰: {positive_count} ({positive_count/len(trajectories)*100:.1f}%)")
        logger.info(f"  è² ä¾‹ï¼ˆã“ã®æœŸé–“ã§æ‰¿è«¾ãªã—ï¼‰: {negative_count} ({negative_count/len(trajectories)*100:.1f}%)")
        if negative_with_requests > 0:
            logger.info(f"    - ä¾é ¼ã‚ã‚Šâ†’æ‹’å¦ï¼ˆé‡ã¿=1.0ï¼‰: {negative_with_requests}")
        if negative_without_requests > 0:
            logger.info(f"    - ä¾é ¼ãªã—ï¼ˆæ‹¡å¼µæœŸé–“ã«ä¾é ¼ã‚ã‚Šã€é‡ã¿=0.1ï¼‰: {negative_without_requests}")
        total_steps = sum(t['seq_len'] for t in trajectories)
        continued_steps = sum(sum(t['step_labels']) for t in trajectories)
        logger.info(f"  ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps}")
        if total_steps > 0:
            logger.info(f"  ç¶™ç¶šã‚¹ãƒ†ãƒƒãƒ—ç‡: {continued_steps/total_steps*100:.1f}% ({continued_steps}/{total_steps})")
    logger.info("=" * 80)
    
    return trajectories


def extract_evaluation_trajectories(
    df: pd.DataFrame,
    cutoff_date: pd.Timestamp,
    history_window_months: int = 12,
    future_window_start_months: int = 0,
    future_window_end_months: int = 3,
    min_history_requests: int = 3,
    reviewer_col: str = 'reviewer_email',
    date_col: str = 'request_time',
    label_col: str = 'label',
    project: str = None,
    extended_label_window_months: int = 12
) -> List[Dict[str, Any]]:
    """
    è©•ä¾¡ç”¨è»Œè·¡ã‚’æŠ½å‡ºï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ç”¨ï¼‰

    Args:
        df: ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿
        cutoff_date: Cutoffæ—¥ï¼ˆé€šå¸¸ã¯è¨“ç·´çµ‚äº†æ—¥ï¼‰
        history_window_months: å±¥æ­´ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆãƒ¶æœˆï¼‰
        future_window_start_months: å°†æ¥çª“ã®é–‹å§‹ï¼ˆãƒ¶æœˆï¼‰
        future_window_end_months: å°†æ¥çª“ã®çµ‚äº†ï¼ˆãƒ¶æœˆï¼‰
        min_history_requests: æœ€å°å±¥æ­´ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼æ•°
        reviewer_col: ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼åˆ—å
        date_col: æ—¥ä»˜åˆ—å
        label_col: ãƒ©ãƒ™ãƒ«åˆ—å
        project: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆæŒ‡å®šæ™‚ã¯å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ï¼‰
        extended_label_window_months: æ‹¡å¼µãƒ©ãƒ™ãƒ«æœŸé–“ï¼ˆæœˆæ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ12ï¼‰

    Returns:
        è»Œè·¡ãƒªã‚¹ãƒˆ
    """
    logger.info("=" * 80)
    logger.info("è©•ä¾¡ç”¨è»Œè·¡æŠ½å‡ºã‚’é–‹å§‹ï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ç”¨ï¼‰")
    logger.info(f"Cutoffæ—¥: {cutoff_date}")
    logger.info(f"å±¥æ­´ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: {history_window_months}ãƒ¶æœˆ")
    logger.info(f"å°†æ¥çª“: {future_window_start_months}ï½{future_window_end_months}ãƒ¶æœˆ")
    logger.info(f"æ‹¡å¼µãƒ©ãƒ™ãƒ«æœŸé–“: {future_window_start_months}ï½{extended_label_window_months}ãƒ¶æœˆ")
    if project:
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project} (å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ)")
    else:
        logger.info("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
    logger.info("ç¶™ç¶šåˆ¤å®š: ã“ã®æœŸé–“ã§æ‰¿è«¾=1ã€ã“ã®æœŸé–“ã§æ‹’å¦=0ã€ä¾é ¼ãªã—â†’æ‹¡å¼µæœŸé–“ãƒã‚§ãƒƒã‚¯ã€è©•ä¾¡æ™‚ã¯æ‹¡å¼µæœŸé–“ã«ã‚‚ä¾é ¼ãªã—ã§é™¤å¤–ï¼ˆäºˆæ¸¬ã®æ¯é›†å›£ã«å…¥ã‚Œãªã„ï¼‰")
    logger.info("=" * 80)
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨
    if project and 'project' in df.columns:
        df = df[df['project'] == project].copy()
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œ: {len(df)}ä»¶")
    
    trajectories = []
    
    # å±¥æ­´æœŸé–“
    history_start = cutoff_date - pd.DateOffset(months=history_window_months)
    history_end = cutoff_date
    
    # è©•ä¾¡æœŸé–“
    eval_start = cutoff_date + pd.DateOffset(months=future_window_start_months)
    eval_end = cutoff_date + pd.DateOffset(months=future_window_end_months)
    
    logger.info(f"å±¥æ­´æœŸé–“: {history_start} ï½ {history_end}")
    logger.info(f"è©•ä¾¡æœŸé–“: {eval_start} ï½ {eval_end}")
    
    # å±¥æ­´æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿
    history_df = df[
        (df[date_col] >= history_start) &
        (df[date_col] < history_end)
    ]
    
    # è©•ä¾¡æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿
    eval_df = df[
        (df[date_col] >= eval_start) &
        (df[date_col] < eval_end)
    ]

    # æ‹¡å¼µè©•ä¾¡æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿
    extended_eval_start = cutoff_date + pd.DateOffset(months=future_window_start_months)
    extended_eval_end = cutoff_date + pd.DateOffset(months=extended_label_window_months)
    extended_eval_df = df[
        (df[date_col] >= extended_eval_start) &
        (df[date_col] < extended_eval_end)
    ]

    # å±¥æ­´æœŸé–“å†…ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ãŸãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’å¯¾è±¡
    active_reviewers = history_df[reviewer_col].unique()
    logger.info(f"å±¥æ­´æœŸé–“å†…ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æ•°: {len(active_reviewers)}")

    skipped_min_requests = 0
    skipped_no_requests_until_end = 0  # è¨“ç·´æœŸé–“æœ«å°¾ã¾ã§ä¾é ¼ãŒãªã„ï¼ˆé™¤å¤–ï¼‰
    positive_count = 0
    negative_count = 0
    negative_with_requests = 0  # ä¾é ¼ã‚ã‚Šâ†’æ‹’å¦
    negative_without_requests = 0  # ä¾é ¼ãªã—ï¼ˆæ‹¡å¼µæœŸé–“ã«ä¾é ¼ã‚ã‚Šï¼‰
    
    for reviewer in active_reviewers:
        # å±¥æ­´æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼
        reviewer_history = history_df[history_df[reviewer_col] == reviewer]
        
        # æœ€å°ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼æ•°ã‚’æº€ãŸã•ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if len(reviewer_history) < min_history_requests:
            skipped_min_requests += 1
            continue
        
        # è©•ä¾¡æœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼
        reviewer_eval = eval_df[eval_df[reviewer_col] == reviewer]

        # è©•ä¾¡æœŸé–“ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’å—ã‘ã¦ã„ãªã„å ´åˆã€æ‹¡å¼µæœŸé–“ã‚’ãƒã‚§ãƒƒã‚¯
        if len(reviewer_eval) == 0:
            # æ‹¡å¼µæœŸé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’ãƒã‚§ãƒƒã‚¯
            reviewer_extended_eval = extended_eval_df[extended_eval_df[reviewer_col] == reviewer]

            if len(reviewer_extended_eval) == 0:
                # æ‹¡å¼µæœŸé–“ã«ã‚‚ä¾é ¼ãŒãªã„ â†’ è¨“ç·´æœŸé–“æœ«å°¾ã¾ã§ã‚¢ã‚µã‚¤ãƒ³ãŒãªã„ â†’ é™¤å¤–ï¼ˆå®Ÿè³ªé›¢è„±è€…ï¼‰
                skipped_no_requests_until_end += 1
                continue  # ã“ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
            
            # æ‹¡å¼µæœŸé–“ã«ä¾é ¼ãŒã‚ã‚‹ â†’ è¨“ç·´æœŸé–“ä¸­ã«æŒ‡å®šæœŸé–“ã‚’è¶…ãˆã¦å†ã³ã‚¢ã‚µã‚¤ãƒ³ã•ã‚Œã‚‹å¯èƒ½æ€§ â†’ é‡ã¿ä»˜ãè² ä¾‹
            future_acceptance = False  # ã“ã®æœŸé–“ã§ã¯æ´»å‹•ãªã—
            accepted_requests = pd.DataFrame()  # ç©º
            rejected_requests = pd.DataFrame()  # ç©ºï¼ˆä¾é ¼è‡ªä½“ãŒãªã„ï¼‰
            had_requests = False  # ã“ã®æœŸé–“ã«ä¾é ¼ãŒãªã‹ã£ãŸ
            sample_weight = 0.1  # éå¸¸ã«ä½ã„é‡ã¿ï¼ˆä¾é ¼ãªã—ï¼‰

            # çµ±è¨ˆã‚«ã‚¦ãƒ³ãƒˆ
            negative_count += 1
            negative_without_requests += 1
        else:
            # é€šå¸¸ã®è©•ä¾¡æœŸé–“ã«ä¾é ¼ãŒã‚ã‚‹å ´åˆ
            # ç¶™ç¶šåˆ¤å®šï¼šè©•ä¾¡æœŸé–“å†…ã«å°‘ãªãã¨ã‚‚1ã¤ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ã‚’æ‰¿è«¾ã—ãŸã‹
            accepted_requests = reviewer_eval[reviewer_eval[label_col] == 1]
            rejected_requests = reviewer_eval[reviewer_eval[label_col] == 0]
            future_acceptance = len(accepted_requests) > 0
            had_requests = True  # ã“ã®æœŸé–“ã«ä¾é ¼ãŒã‚ã£ãŸ
            sample_weight = 1.0  # é€šå¸¸ã®é‡ã¿ï¼ˆä¾é ¼ã‚ã‚Šï¼‰

            if future_acceptance:
                positive_count += 1
            else:
                negative_count += 1
                negative_with_requests += 1

        # æ´»å‹•å±¥æ­´ã‚’æ§‹ç¯‰
        activity_history = []
        for _, row in reviewer_history.iterrows():
            activity = {
                'timestamp': row[date_col],  # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯å¸¸ã«date_col
                'action_type': 'review',
                'project': row.get('project', 'unknown'),
                'request_time': row.get('request_time', row[date_col]),
                'response_time': row.get('first_response_time'),  # response_timeè¨ˆç®—ç”¨
                'accepted': row.get(label_col, 0) == 1,
                # IRLç‰¹å¾´é‡è¨ˆç®—ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                'files_changed': row.get('change_files_count', 0),  # å¼·åº¦è¨ˆç®—ç”¨
                'change_files_count': row.get('change_files_count', 0),  # å¼·åº¦è¨ˆç®—ç”¨
                'lines_added': row.get('change_insertions', 0),  # è¦æ¨¡è¨ˆç®—ç”¨
                'lines_deleted': row.get('change_deletions', 0),  # è¦æ¨¡è¨ˆç®—ç”¨
                'change_insertions': row.get('change_insertions', 0),  # è¦æ¨¡è¨ˆç®—ç”¨
                'change_deletions': row.get('change_deletions', 0),  # è¦æ¨¡è¨ˆç®—ç”¨
            }
            activity_history.append(activity)
        
        # é–‹ç™ºè€…æƒ…å ±
        developer_info = {
            'developer_email': reviewer,
            'first_seen': reviewer_history[date_col].min(),
            'changes_authored': 0,
            'changes_reviewed': len(reviewer_history[reviewer_history[label_col] == 1]),
            'requests_received': len(reviewer_history),
            'requests_accepted': len(reviewer_history[reviewer_history[label_col] == 1]),
            'requests_rejected': len(reviewer_history[reviewer_history[label_col] == 0]),
            'acceptance_rate': len(reviewer_history[reviewer_history[label_col] == 1]) / len(reviewer_history),
            'projects': reviewer_history['project'].unique().tolist() if 'project' in reviewer_history.columns else []
        }
        
        # è»Œè·¡ã‚’ä½œæˆ
        trajectory = {
            'developer': developer_info,
            'activity_history': activity_history,
            'context_date': cutoff_date,
            'future_acceptance': future_acceptance,
            'reviewer': reviewer,
            'history_request_count': len(reviewer_history),
            'history_accepted_count': len(reviewer_history[reviewer_history[label_col] == 1]),
            'history_rejected_count': len(reviewer_history[reviewer_history[label_col] == 0]),
            'eval_request_count': len(reviewer_eval),
            'eval_accepted_count': len(accepted_requests),
            'eval_rejected_count': len(rejected_requests),
            'had_requests': had_requests,  # ã“ã®æœŸé–“ã«ä¾é ¼ãŒã‚ã£ãŸã‹
            'sample_weight': sample_weight  # ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ï¼ˆä¾é ¼ãªã—=0.3ã€ä¾é ¼ã‚ã‚Š=1.0ï¼‰
        }
        
        trajectories.append(trajectory)
    
    logger.info("=" * 80)
    logger.info(f"è©•ä¾¡ç”¨è»Œè·¡æŠ½å‡ºå®Œäº†: {len(trajectories)}ã‚µãƒ³ãƒ—ãƒ«")
    logger.info(f"  ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœ€å°ä¾é ¼æ•°æœªæº€ï¼‰: {skipped_min_requests}")
    logger.info(f"  ã‚¹ã‚­ãƒƒãƒ—ï¼ˆè¨“ç·´æœŸé–“æœ«å°¾ã¾ã§ä¾é ¼ãªã—ï¼‰: {skipped_no_requests_until_end}")
    if trajectories:
        logger.info(f"  æ­£ä¾‹ï¼ˆã“ã®æœŸé–“ã§æ‰¿è«¾ã‚ã‚Šï¼‰: {positive_count} ({positive_count/len(trajectories)*100:.1f}%)")
        logger.info(f"  è² ä¾‹ï¼ˆã“ã®æœŸé–“ã§æ‰¿è«¾ãªã—ï¼‰: {negative_count} ({negative_count/len(trajectories)*100:.1f}%)")
        if negative_with_requests > 0:
            logger.info(f"    - ä¾é ¼ã‚ã‚Šâ†’æ‹’å¦ï¼ˆé‡ã¿=1.0ï¼‰: {negative_with_requests}")
        if negative_without_requests > 0:
            logger.info(f"    - ä¾é ¼ãªã—ï¼ˆæ‹¡å¼µæœŸé–“ã«ä¾é ¼ã‚ã‚Šã€é‡ã¿=0.1ï¼‰: {negative_without_requests}")
    logger.info("=" * 80)
    
    return trajectories


def find_optimal_threshold(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
    """
    æœ€é©ãªé–¾å€¤ã‚’æ¢ç´¢
    
    Args:
        y_true: çœŸã®ãƒ©ãƒ™ãƒ«
        y_pred: äºˆæ¸¬ç¢ºç‡
        
    Returns:
        æœ€é©é–¾å€¤ã¨å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    """
    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)
    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)
    
    best_idx = np.argmax(f1_scores)
    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5
    
    return {
        'threshold': float(best_threshold),
        'precision': float(precision[best_idx]),
        'recall': float(recall[best_idx]),
        'f1': float(f1_scores[best_idx])
    }


def main():
    parser = argparse.ArgumentParser(
        description="ãƒ¬ãƒ“ãƒ¥ãƒ¼æ‰¿è«¾äºˆæ¸¬IRLå­¦ç¿’ï¼ˆæ­£ã—ã„ãƒ­ã‚¸ãƒƒã‚¯ç‰ˆï¼‰"
    )
    parser.add_argument(
        "--reviews",
        type=str,
        default="data/review_requests_openstack_multi_5y_detail.csv",
        help="ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--train-start",
        type=str,
        default="2021-01-01",
        help="è¨“ç·´é–‹å§‹æ—¥ (YYYY-MM-DD)"
    )
    parser.add_argument(
        "--train-end",
        type=str,
        default="2023-01-01",
        help="è¨“ç·´çµ‚äº†æ—¥ (YYYY-MM-DD)"
    )
    parser.add_argument(
        "--eval-start",
        type=str,
        default="2023-01-01",
        help="è©•ä¾¡é–‹å§‹æ—¥ (YYYY-MM-DD)"
    )
    parser.add_argument(
        "--eval-end",
        type=str,
        default="2024-01-01",
        help="è©•ä¾¡çµ‚äº†æ—¥ (YYYY-MM-DD)"
    )
    parser.add_argument(
        "--future-window-start",
        type=int,
        default=0,
        help="å°†æ¥çª“é–‹å§‹ï¼ˆæœˆæ•°ï¼‰"
    )
    parser.add_argument(
        "--future-window-end",
        type=int,
        default=3,
        help="å°†æ¥çª“çµ‚äº†ï¼ˆæœˆæ•°ï¼‰"
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=20,
        help="è¨“ç·´ã‚¨ãƒãƒƒã‚¯æ•°"
    )
    parser.add_argument(
        "--min-history-events",
        type=int,
        default=3,
        help="æœ€å°å±¥æ­´ã‚¤ãƒ™ãƒ³ãƒˆæ•°"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="outputs/review_acceptance_irl",
        help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
    )
    parser.add_argument(
        "--project",
        type=str,
        default=None,
        help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆå˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ï¼‰"
    )
    parser.add_argument(
        "--model",
        type=str,
        default=None,
        help="æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ï¼ˆè©•ä¾¡ã®ã¿ã®å ´åˆï¼‰"
    )
    
    args = parser.parse_args()
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    df = load_review_requests(args.reviews)
    
    # æ—¥ä»˜ã‚’ãƒ‘ãƒ¼ã‚¹
    train_start = pd.Timestamp(args.train_start)
    train_end = pd.Timestamp(args.train_end)
    eval_start = pd.Timestamp(args.eval_start)
    eval_end = pd.Timestamp(args.eval_end)
    
    logger.info(f"å°†æ¥çª“: {args.future_window_start}ï½{args.future_window_end}ãƒ¶æœˆ")
    
    # è¨“ç·´ç”¨è»Œè·¡ã‚’æŠ½å‡º
    if args.model is None:
        logger.info("è¨“ç·´ç”¨è»Œè·¡ã‚’æŠ½å‡º...")
        train_trajectories = extract_review_acceptance_trajectories(
            df,
            train_start=train_start,
            train_end=train_end,
            future_window_start_months=args.future_window_start,
            future_window_end_months=args.future_window_end,
            min_history_requests=args.min_history_events,
            project=args.project
        )
        
        if not train_trajectories:
            logger.error("è¨“ç·´ç”¨è»Œè·¡ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # IRLã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ï¼ˆAttentionä»˜ãï¼‰
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®è¨­å®š + Attentionæ©Ÿæ§‹
        # - hidden_dim=128: é©åº¦ãªè¡¨ç¾åŠ›ï¼ˆ256ã ã¨éå‰°ï¼‰
        # - dropout=0.2: é©åº¦ãªæ­£å‰‡åŒ–ï¼ˆ0.0ã ã¨éå­¦ç¿’ã€0.1ã ã¨ä¸ååˆ†ï¼‰
        # - learning_rate=0.0001: ã‚„ã‚„é«˜ã‚ã§å±€æ‰€æœ€é©ã‚’å›é¿
        # - use_attention=True: Multi-Head Self-Attentionæ©Ÿæ§‹ã‚’è¿½åŠ 
        # - num_attention_heads=4: Attention headsæ•°
        config = {
            'state_dim': 10,  # æœ€è¿‘ã®å—è«¾ç‡+ãƒ¬ãƒ“ãƒ¥ãƒ¼è² è·ã‚’è¿½åŠ 
            'action_dim': 4,
            'hidden_dim': 128,  # å®‰å®šã—ãŸè¡¨ç¾åŠ›
            'sequence': True,
            'seq_len': 0,
            'learning_rate': 0.0001,  # å±€æ‰€æœ€é©å›é¿
            'dropout': 0.2,  # é©åº¦ãªæ­£å‰‡åŒ–
            'use_attention': True,  # ğŸ†• Attentionæ©Ÿæ§‹ã‚’æœ‰åŠ¹åŒ–
            'num_attention_heads': 4,  # ğŸ†• Attention headsæ•°
        }
        
        # Attentionä»˜ããƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§åˆæœŸåŒ–
        irl_system = RetentionIRLSystem(config)
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’Attentionä»˜ãã«ç½®ãæ›ãˆ
        logger.info("ğŸ”¥ Attentionä»˜ãIRLãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨")
        irl_system.network = RetentionIRLNetworkWithAttention(
            state_dim=config['state_dim'],
            action_dim=config['action_dim'],
            hidden_dim=config['hidden_dim'],
            sequence=config['sequence'],
            seq_len=config['seq_len'],
            dropout=config['dropout']
        )
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’å†åˆæœŸåŒ–ï¼ˆæ–°ã—ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”¨ï¼‰
        irl_system.optimizer = torch.optim.Adam(
            irl_system.network.parameters(), 
            lr=config['learning_rate']
        )
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ­£ä¾‹ç‡ã‚’è¨ˆç®—ã—ã¦ Focal Loss ã‚’è‡ªå‹•èª¿æ•´
        positive_count = sum(1 for t in train_trajectories if t['future_acceptance'])
        positive_rate = positive_count / len(train_trajectories)
        logger.info(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ­£ä¾‹ç‡: {positive_rate:.1%} ({positive_count}/{len(train_trajectories)})")
        
        irl_system.auto_tune_focal_loss(positive_rate)
        
        # è¨“ç·´
        logger.info("IRLãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´...")
        irl_system.train_irl_temporal_trajectories(
            train_trajectories,
            epochs=args.epochs
        )
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸Šã§æœ€é©é–¾å€¤ã‚’æ±ºå®š
        logger.info("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸Šã§æœ€é©é–¾å€¤ã‚’æ±ºå®š...")
        train_y_true = []
        train_y_pred = []
        
        for traj in train_trajectories:
            # ã‚­ãƒ¼åã‚’ç¢ºèªã—ã¦é©åˆ‡ã«å‡¦ç†
            developer = traj.get('developer', traj.get('developer_info', {}))
            result = irl_system.predict_continuation_probability_snapshot(
                developer,
                traj['activity_history'],
                traj['context_date']
            )
            train_y_true.append(1 if traj['future_acceptance'] else 0)
            train_y_pred.append(result['continuation_probability'])
        
        train_y_true = np.array(train_y_true)
        train_y_pred = np.array(train_y_pred)

        # F1ã‚¹ã‚³ã‚¢ã‚’æœ€å¤§åŒ–ã™ã‚‹é–¾å€¤ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æ±ºå®š
        positive_rate = train_y_true.mean()
        logger.info(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ­£ä¾‹ç‡: {positive_rate:.1%}")

        # find_optimal_threshold ã‚’ä½¿ç”¨ã—ã¦F1ã‚¹ã‚³ã‚¢ã‚’æœ€å¤§åŒ–ã™ã‚‹é–¾å€¤ã‚’æ¢ç´¢
        train_optimal_threshold_info = find_optimal_threshold(train_y_true, train_y_pred)
        train_optimal_threshold = train_optimal_threshold_info['threshold']
        train_optimal_threshold_info['positive_rate'] = float(positive_rate)
        train_optimal_threshold_info['method'] = 'f1_maximization_on_train_data'

        logger.info(f"F1æœ€å¤§åŒ–é–¾å€¤ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼‰: {train_optimal_threshold:.4f}")
        logger.info(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ€§èƒ½: Precision={train_optimal_threshold_info['precision']:.3f}, Recall={train_optimal_threshold_info['recall']:.3f}, F1={train_optimal_threshold_info['f1']:.3f}")
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ç¢ºç‡åˆ†å¸ƒã‚‚ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        train_optimal_threshold_info['train_prediction_stats'] = {
            'min': float(train_y_pred.min()),
            'max': float(train_y_pred.max()),
            'mean': float(train_y_pred.mean()),
            'std': float(train_y_pred.std()),
            'median': float(np.median(train_y_pred))
        }
        logger.info(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ç¢ºç‡: [{train_optimal_threshold_info['train_prediction_stats']['min']:.4f}, {train_optimal_threshold_info['train_prediction_stats']['max']:.4f}]")
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        model_path = output_dir / "irl_model.pt"
        torch.save(irl_system.network.state_dict(), model_path)
        logger.info(f"ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: {model_path}")
        
        # é–¾å€¤ã‚’ä¿å­˜
        threshold_path = output_dir / "optimal_threshold.json"
        with open(threshold_path, 'w') as f:
            json.dump(train_optimal_threshold_info, f, indent=2)
        logger.info(f"æœ€é©é–¾å€¤ã‚’ä¿å­˜: {threshold_path}")
    else:
        # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆAttentionä»˜ãï¼‰
        logger.info(f"æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿: {args.model}")
        config = {
            'state_dim': 10,  # æœ€è¿‘ã®å—è«¾ç‡+ãƒ¬ãƒ“ãƒ¥ãƒ¼è² è·ã‚’è¿½åŠ 
            'action_dim': 4,
            'hidden_dim': 128,  # è¨“ç·´æ™‚ã¨åŒã˜è¨­å®š
            'sequence': True,
            'seq_len': 0,
            'dropout': 0.2,
            'use_attention': True,  # ğŸ†• Attentionæ©Ÿæ§‹ã‚’æœ‰åŠ¹åŒ–
            'num_attention_heads': 4,  # ğŸ†• Attention headsæ•°
        }
        irl_system = RetentionIRLSystem(config)
        
        # Attentionä»˜ããƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ç½®ãæ›ãˆ
        logger.info("ğŸ”¥ Attentionä»˜ãIRLãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ï¼ˆè©•ä¾¡ï¼‰")
        irl_system.network = RetentionIRLNetworkWithAttention(
            state_dim=config['state_dim'],
            action_dim=config['action_dim'],
            hidden_dim=config['hidden_dim'],
            sequence=config['sequence'],
            seq_len=config['seq_len'],
            dropout=config['dropout']
        )
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
        irl_system.network.load_state_dict(torch.load(args.model))
        irl_system.network.eval()
        
        # ä¿å­˜ã•ã‚ŒãŸé–¾å€¤ã‚’èª­ã¿è¾¼ã¿
        threshold_path = Path(args.model).parent / "optimal_threshold.json"
        if threshold_path.exists():
            with open(threshold_path) as f:
                train_optimal_threshold_info = json.load(f)
                train_optimal_threshold = train_optimal_threshold_info['threshold']
            logger.info(f"ä¿å­˜ã•ã‚ŒãŸé–¾å€¤ã‚’èª­ã¿è¾¼ã¿: {train_optimal_threshold:.4f}")
        else:
            train_optimal_threshold = 0.5
            logger.warning(f"é–¾å€¤ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ {train_optimal_threshold:.4f} ã‚’ä½¿ç”¨")
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦é–¾å€¤ã‚’è¨­å®š
    global optimal_threshold_from_training
    if 'train_optimal_threshold' in locals():
        optimal_threshold_from_training = train_optimal_threshold
    else:
        optimal_threshold_from_training = 0.5
    
    # è©•ä¾¡ç”¨è»Œè·¡ã‚’æŠ½å‡º
    logger.info("è©•ä¾¡ç”¨è»Œè·¡ã‚’æŠ½å‡º...")
    history_window_months = int((train_end - train_start).days / 30)
    
    # future_window_start_monthsã¨future_window_end_monthsã‚’ä½¿ç”¨
    # ã“ã‚Œã‚‰ã¯--future-window-startã¨--future-window-endã‹ã‚‰æ¥ã‚‹
    eval_trajectories = extract_evaluation_trajectories(
        df,
        cutoff_date=train_end,
        history_window_months=history_window_months,
        future_window_start_months=args.future_window_start,
        future_window_end_months=args.future_window_end,
        min_history_requests=args.min_history_events,
        project=args.project
    )
    
    if not eval_trajectories:
        logger.error("è©•ä¾¡ç”¨è»Œè·¡ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # äºˆæ¸¬
    logger.info("äºˆæ¸¬ã‚’å®Ÿè¡Œ...")
    y_true = []
    y_pred = []
    predictions = []
    
    for traj in eval_trajectories:
        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ã§äºˆæ¸¬
        result = irl_system.predict_continuation_probability_snapshot(
            traj['developer'],
            traj['activity_history'],
            traj['context_date']
        )
        prob = result['continuation_probability']
        true_label = 1 if traj['future_acceptance'] else 0
        
        y_true.append(true_label)
        y_pred.append(prob)
        
        predictions.append({
            'reviewer_email': traj['reviewer'],
            'predicted_prob': float(prob),
            'true_label': true_label,
            'history_request_count': traj['history_request_count'],
            'history_acceptance_rate': traj['developer']['acceptance_rate'],
            'eval_request_count': traj['eval_request_count'],
            'eval_accepted_count': traj['eval_accepted_count'],
            'eval_rejected_count': traj['eval_rejected_count']
        })
    
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
    logger.info("ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—...")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æ±ºå®šã—ãŸé–¾å€¤ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
    optimal_threshold = train_optimal_threshold
    logger.info(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æ±ºå®šã—ãŸé–¾å€¤ã‚’ä½¿ç”¨: {optimal_threshold:.4f}")

    # å‚è€ƒï¼šè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ä¸Šã§ã®æœ€é©é–¾å€¤ã‚‚è¨ˆç®—ï¼ˆæ¯”è¼ƒç”¨ï¼‰
    eval_optimal_threshold_info = find_optimal_threshold(y_true, y_pred)
    logger.info(f"å‚è€ƒï¼šè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ä¸Šã§ã®æœ€é©é–¾å€¤: {eval_optimal_threshold_info['threshold']:.4f} (F1={eval_optimal_threshold_info['f1']:.3f})")

    y_pred_binary = (y_pred >= optimal_threshold).astype(int)
    
    auc_roc = roc_auc_score(y_true, y_pred)
    precision, recall, _ = precision_recall_curve(y_true, y_pred)
    auc_pr = auc(recall, precision)
    
    precision_at_threshold = precision_score(y_true, y_pred_binary)
    recall_at_threshold = recall_score(y_true, y_pred_binary)
    f1_at_threshold = f1_score(y_true, y_pred_binary)
    
    metrics = {
        'auc_roc': float(auc_roc),
        'auc_pr': float(auc_pr),
        'optimal_threshold': float(optimal_threshold),
        'threshold_source': 'train_data',  # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æ±ºå®šã—ãŸé–¾å€¤ã‚’ä½¿ç”¨
        'precision': float(precision_at_threshold),
        'recall': float(recall_at_threshold),
        'f1_score': float(f1_at_threshold),
        'positive_count': int(y_true.sum()),
        'negative_count': int((1 - y_true).sum()),
        'total_count': int(len(y_true)),
        # å‚è€ƒæƒ…å ±ï¼šè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã§ã®æœ€é©é–¾å€¤
        'eval_optimal_threshold': float(eval_optimal_threshold_info['threshold']),
        'eval_optimal_f1': float(eval_optimal_threshold_info['f1']),
        # äºˆæ¸¬ç¢ºç‡ã®åˆ†å¸ƒçµ±è¨ˆ
        'prediction_stats': {
            'min': float(y_pred.min()),
            'max': float(y_pred.max()),
            'mean': float(y_pred.mean()),
            'std': float(y_pred.std()),
            'median': float(np.median(y_pred))
        }
    }
    
    logger.info("=" * 80)
    logger.info("è©•ä¾¡çµæœ:")
    logger.info(f"  AUC-ROC: {metrics['auc_roc']:.4f}")
    logger.info(f"  AUC-PR: {metrics['auc_pr']:.4f}")
    logger.info(f"  æœ€é©é–¾å€¤ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿æ±ºå®šï¼‰: {metrics['optimal_threshold']:.4f}")
    logger.info(f"  Precision: {metrics['precision']:.4f}")
    logger.info(f"  Recall: {metrics['recall']:.4f}")
    logger.info(f"  F1 Score: {metrics['f1_score']:.4f}")
    logger.info(f"  æ­£ä¾‹æ•°: {metrics['positive_count']}")
    logger.info(f"  è² ä¾‹æ•°: {metrics['negative_count']}")
    logger.info("---")
    logger.info("äºˆæ¸¬ç¢ºç‡ã®åˆ†å¸ƒ:")
    logger.info(f"  ç¯„å›²: [{metrics['prediction_stats']['min']:.4f}, {metrics['prediction_stats']['max']:.4f}]")
    logger.info(f"  å¹³å‡: {metrics['prediction_stats']['mean']:.4f}")
    logger.info(f"  æ¨™æº–åå·®: {metrics['prediction_stats']['std']:.4f}")
    logger.info(f"  ä¸­å¤®å€¤: {metrics['prediction_stats']['median']:.4f}")
    logger.info("=" * 80)
    
    # çµæœã‚’ä¿å­˜
    with open(output_dir / "metrics.json", "w") as f:
        json.dump(metrics, f, indent=2)
    
    predictions_df = pd.DataFrame(predictions)
    predictions_df['predicted_binary'] = y_pred_binary
    predictions_df.to_csv(output_dir / "predictions.csv", index=False)
    
    # è©•ä¾¡è»Œè·¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆç‰¹å¾´é‡é‡è¦åº¦åˆ†æç”¨ï¼‰
    import pickle
    trajectories_path = output_dir / "eval_trajectories.pkl"
    with open(trajectories_path, 'wb') as f:
        pickle.dump(eval_trajectories, f)
    logger.info(f"è©•ä¾¡è»Œè·¡ã‚’ä¿å­˜: {trajectories_path}")
    
    logger.info(f"çµæœã‚’ä¿å­˜: {output_dir}")


if __name__ == "__main__":
    main()

