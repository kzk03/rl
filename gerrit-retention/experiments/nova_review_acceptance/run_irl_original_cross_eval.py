#!/usr/bin/env python3
"""
ã‚ªãƒªã‚¸ãƒŠãƒ«IRL - Future Windowåˆ¥è©•ä¾¡å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Attentionãªã—ã®ã‚ªãƒªã‚¸ãƒŠãƒ«å®Ÿè£…ã§4ã¤ã®Future Windowã‚’è©•ä¾¡
"""
import logging
import subprocess
import sys
from pathlib import Path

import numpy as np
import pandas as pd

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
ROOT = Path(__file__).resolve().parents[2]

# å­¦ç¿’æœŸé–“: 2021-01-01 ï½ 2023-01-01ï¼ˆ24ãƒ¶æœˆã€å›ºå®šï¼‰
# è©•ä¾¡ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ: 2023-01-01ï¼ˆå›ºå®šï¼‰
# Future Window: ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰0-3m, 3-6m, 6-9m, 9-12må¾Œã®è²¢çŒ®ã‚’äºˆæ¸¬
FUTURE_WINDOWS = [
    {"name": "0-3m", "fw_start": 0, "fw_end": 3},
    {"name": "3-6m", "fw_start": 3, "fw_end": 6},
    {"name": "6-9m", "fw_start": 6, "fw_end": 9},
    {"name": "9-12m", "fw_start": 9, "fw_end": 12},
]

# å›ºå®šæœŸé–“
TRAIN_START = "2021-01-01"
TRAIN_END = "2023-01-01"
EVAL_SNAPSHOT = "2023-01-01"

DATA_PATH = "data/review_requests_openstack_multi_5y_detail.csv"
PROJECT = "openstack/nova"
EPOCHS = 50
OUTPUT_BASE = ROOT / "experiments/nova_review_acceptance/outputs_irl_original_cross_eval"


def run_training(fw_window, output_dir):
    """è¨“ç·´ã‚’å®Ÿè¡Œï¼ˆç‰¹å®šã®Future Windowã§ï¼‰"""
    cmd = [
        "uv", "run", "python",
        str(ROOT / "scripts/training/irl/train_irl_review_acceptance.py"),  # ã‚ªãƒªã‚¸ãƒŠãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        "--reviews", DATA_PATH,
        "--train-start", TRAIN_START,
        "--train-end", TRAIN_END,
        "--eval-start", EVAL_SNAPSHOT,
        "--eval-end", "2024-01-01",  # è©•ä¾¡æœŸé–“å…¨ä½“
        "--future-window-start", str(fw_window["fw_start"]),
        "--future-window-end", str(fw_window["fw_end"]),
        "--epochs", str(EPOCHS),
        "--min-history-events", "3",
        "--project", PROJECT,
        "--output", str(output_dir),
    ]
    
    logger.info(f"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
    result = subprocess.run(cmd, cwd=str(ROOT), capture_output=False)
    
    if result.returncode != 0:
        logger.error(f"è¨“ç·´å¤±æ•—: {fw_window['name']}")
        return False
    
    return True


def evaluate_with_model(model_path, threshold_path, fw_window, output_dir):
    """æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ï¼ˆç•°ãªã‚‹Future Windowã§ï¼‰"""
    cmd = [
        "uv", "run", "python",
        str(ROOT / "scripts/training/irl/train_irl_review_acceptance.py"),  # ã‚ªãƒªã‚¸ãƒŠãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        "--reviews", DATA_PATH,
        "--train-start", TRAIN_START,
        "--train-end", TRAIN_END,
        "--eval-start", EVAL_SNAPSHOT,
        "--eval-end", "2024-01-01",
        "--future-window-start", str(fw_window["fw_start"]),
        "--future-window-end", str(fw_window["fw_end"]),
        "--min-history-events", "3",
        "--project", PROJECT,
        "--model", str(model_path),  # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆè¨“ç·´ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        "--output", str(output_dir),
    ]
    
    logger.info(f"è©•ä¾¡ã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
    result = subprocess.run(cmd, cwd=str(ROOT), capture_output=False)
    
    if result.returncode != 0:
        logger.error(f"è©•ä¾¡å¤±æ•—: {fw_window['name']}")
        return False
    
    return True


def collect_cross_eval_results(cross_eval_results):
    """4Ã—4ã‚¯ãƒ­ã‚¹è©•ä¾¡çµæœã‚’ãƒãƒˆãƒªã‚¯ã‚¹å½¢å¼ã§ä¿å­˜"""
    if not cross_eval_results:
        logger.warning("ã‚¯ãƒ­ã‚¹è©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # DataFrameä½œæˆ
    results_df = pd.DataFrame(cross_eval_results)
    results_df.to_csv(OUTPUT_BASE / "cross_eval_results.csv", index=False)
    logger.info(f"çµæœä¿å­˜: {OUTPUT_BASE / 'cross_eval_results.csv'}")
    
    # AUC-ROCãƒãƒˆãƒªã‚¯ã‚¹ä½œæˆ
    matrix_auc = results_df.pivot(
        index="train_fw",
        columns="eval_fw",
        values="auc_roc"
    )
    
    # åˆ—ã®é †åºã‚’å›ºå®š
    fw_order = ["0-3m", "3-6m", "6-9m", "9-12m"]
    matrix_auc = matrix_auc.reindex(index=fw_order, columns=fw_order)
    
    matrix_auc.to_csv(OUTPUT_BASE / "matrix_AUC_ROC.csv")
    logger.info(f"AUC-ROCãƒãƒˆãƒªã‚¯ã‚¹ä¿å­˜: {OUTPUT_BASE / 'matrix_AUC_ROC.csv'}")
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ”¥ ã‚ªãƒªã‚¸ãƒŠãƒ«IRL - 4Ã—4ã‚¯ãƒ­ã‚¹è©•ä¾¡ AUC-ROCãƒãƒˆãƒªã‚¯ã‚¹")
    logger.info("=" * 80)
    logger.info("\n" + matrix_auc.to_string())
    
    # å¯¾è§’ç·šï¼ˆåŒã˜FWï¼‰ã®å¹³å‡
    diagonal_values = [matrix_auc.iloc[i, i] for i in range(len(fw_order)) if not pd.isna(matrix_auc.iloc[i, i])]
    if diagonal_values:
        logger.info(f"\nğŸ“Š å¯¾è§’ç·šå¹³å‡ï¼ˆè¨“ç·´FW = è©•ä¾¡FWï¼‰: {np.mean(diagonal_values):.4f}")
    
    # éå¯¾è§’ç·šï¼ˆç•°ãªã‚‹FWï¼‰ã®å¹³å‡
    off_diagonal_values = []
    for i in range(len(fw_order)):
        for j in range(len(fw_order)):
            if i != j and not pd.isna(matrix_auc.iloc[i, j]):
                off_diagonal_values.append(matrix_auc.iloc[i, j])
    
    if off_diagonal_values:
        logger.info(f"ğŸ“Š éå¯¾è§’ç·šå¹³å‡ï¼ˆè¨“ç·´FW â‰  è©•ä¾¡FWï¼‰: {np.mean(off_diagonal_values):.4f}")
    
    # å…¨ä½“å¹³å‡
    all_values = results_df["auc_roc"].dropna()
    if len(all_values) > 0:
        logger.info(f"ğŸ“Š å…¨ä½“å¹³å‡: {all_values.mean():.4f}")
        logger.info(f"ğŸ“Š æœ€é«˜AUC-ROC: {all_values.max():.4f}")
        logger.info(f"ğŸ“Š æœ€ä½AUC-ROC: {all_values.min():.4f}")


def main():
    logger.info("=" * 80)
    logger.info("ğŸ”¥ ã‚ªãƒªã‚¸ãƒŠãƒ«IRLï¼ˆAttentionãªã—ï¼‰ - 4Ã—4å®Œå…¨ã‚¯ãƒ­ã‚¹è©•ä¾¡ ğŸ”¥")
    logger.info("=" * 80)
    logger.info(f"å­¦ç¿’æœŸé–“: {TRAIN_START} ï½ {TRAIN_END}ï¼ˆå›ºå®šï¼‰")
    logger.info(f"è©•ä¾¡ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ: {EVAL_SNAPSHOT}ï¼ˆå›ºå®šï¼‰")
    logger.info(f"Future Window: 0-3m, 3-6m, 6-9m, 9-12m ã®4ãƒ‘ã‚¿ãƒ¼ãƒ³")
    logger.info(f"è©•ä¾¡ãƒ‘ã‚¿ãƒ¼ãƒ³: 4ãƒ¢ãƒ‡ãƒ« Ã— 4FW = 16é€šã‚Š")
    logger.info("=" * 80)
    
    OUTPUT_BASE.mkdir(parents=True, exist_ok=True)
    
    # å„Future Windowã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘4ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´")
    logger.info("=" * 80)
    
    trained_models = {}
    
    for fw_window in FUTURE_WINDOWS:
        logger.info(f"\nè¨“ç·´é–‹å§‹: Future Window {fw_window['name']} ({fw_window['fw_start']}-{fw_window['fw_end']}ãƒ¶æœˆå¾Œ)")
        
        output_dir = OUTPUT_BASE / f"train_{fw_window['name']}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        if not run_training(fw_window, output_dir):
            logger.error(f"è¨“ç·´å¤±æ•—: {fw_window['name']}")
            continue
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’ä¿å­˜
        model_path = output_dir / "irl_model.pt"  # ã‚ªãƒªã‚¸ãƒŠãƒ«ã¯ .pt ã§ä¿å­˜
        threshold_path = output_dir / "optimal_threshold.json"  # ã‚ªãƒªã‚¸ãƒŠãƒ«ã¯ .json ã§ä¿å­˜
        
        if model_path.exists() and threshold_path.exists():
            trained_models[fw_window['name']] = {
                "model_path": model_path,
                "threshold_path": threshold_path,
                "fw_window": fw_window
            }
            logger.info(f"âœ… è¨“ç·´å®Œäº†: {fw_window['name']}")
        else:
            logger.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {fw_window['name']}")
    
    # 4Ã—4ã‚¯ãƒ­ã‚¹è©•ä¾¡
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘4Ã—4ã‚¯ãƒ­ã‚¹è©•ä¾¡ï¼ˆ16é€šã‚Šï¼‰")
    logger.info("=" * 80)
    
    cross_eval_results = []
    
    for train_fw_name, model_info in trained_models.items():
        for eval_fw in FUTURE_WINDOWS:
            logger.info(f"\nè©•ä¾¡: {train_fw_name}ãƒ¢ãƒ‡ãƒ« â†’ {eval_fw['name']}FW")
            
            eval_output_dir = OUTPUT_BASE / f"train_{train_fw_name}" / f"eval_{eval_fw['name']}"
            eval_output_dir.mkdir(parents=True, exist_ok=True)
            
            if not evaluate_with_model(
                model_info["model_path"],
                model_info["threshold_path"],
                eval_fw,
                eval_output_dir
            ):
                logger.error(f"è©•ä¾¡å¤±æ•—: {train_fw_name} â†’ {eval_fw['name']}")
                continue
            
            # çµæœã‚’åé›†
            metrics_path = eval_output_dir / "metrics.json"
            if metrics_path.exists():
                import json
                with open(metrics_path) as f:
                    metrics = json.load(f)
                
                cross_eval_results.append({
                    "train_fw": train_fw_name,
                    "eval_fw": eval_fw["name"],
                    "auc_roc": metrics.get("auc_roc", 0.0),
                    "auc_pr": metrics.get("auc_pr", 0.0),
                    "f1_score": metrics.get("f1_score", 0.0),
                    "precision": metrics.get("precision", 0.0),
                    "recall": metrics.get("recall", 0.0),
                })
                logger.info(f"âœ… AUC-ROC: {metrics.get('auc_roc', 0.0):.4f}")
    
    # çµæœåé›†
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘çµæœã‚’ãƒãƒˆãƒªã‚¯ã‚¹å½¢å¼ã§ä¿å­˜")
    collect_cross_eval_results(cross_eval_results)
    
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ‰ 4Ã—4å®Œå…¨ã‚¯ãƒ­ã‚¹è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    logger.info("=" * 80)




if __name__ == "__main__":
    main()
