#!/usr/bin/env python3
"""
ã‚ªãƒªã‚¸ãƒŠãƒ«IRL - ä¸‰è§’ã‚¯ãƒ­ã‚¹è©•ä¾¡ï¼ˆè¨“ç·´FWä»¥é™ã®ã¿è©•ä¾¡ï¼‰

å„ãƒ¢ãƒ‡ãƒ«ã¯è¨“ç·´ã—ãŸFWä»¥é™ã®æœŸé–“ã®ã¿ã§è©•ä¾¡
- 0-3mãƒ¢ãƒ‡ãƒ« â†’ 0-3m, 3-6m, 6-9m, 9-12m (4é€šã‚Š)
- 3-6mãƒ¢ãƒ‡ãƒ« â†’ 3-6m, 6-9m, 9-12m (3é€šã‚Š)
- 6-9mãƒ¢ãƒ‡ãƒ« â†’ 6-9m, 9-12m (2é€šã‚Š)
- 9-12mãƒ¢ãƒ‡ãƒ« â†’ 9-12m (1é€šã‚Š)
åˆè¨ˆ: 10é€šã‚Š
"""
import logging
import subprocess
import sys
from pathlib import Path

import numpy as np
import pandas as pd

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
ROOT = Path(__file__).resolve().parents[2]

# å­¦ç¿’æœŸé–“: 2021-01-01 ï½ 2023-01-01ï¼ˆ24ãƒ¶æœˆã€å›ºå®šï¼‰
# è©•ä¾¡ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ: 2023-01-01ï¼ˆå›ºå®šï¼‰
FUTURE_WINDOWS = [
    {"name": "0-3m", "fw_start": 0, "fw_end": 3},
    {"name": "3-6m", "fw_start": 3, "fw_end": 6},
    {"name": "6-9m", "fw_start": 6, "fw_end": 9},
    {"name": "9-12m", "fw_start": 9, "fw_end": 12},
]

# å›ºå®šæœŸé–“
TRAIN_START = "2021-01-01"
TRAIN_END = "2023-01-01"
EVAL_SNAPSHOT = "2023-01-01"

DATA_PATH = "data/review_requests_openstack_multi_5y_detail.csv"
PROJECT = "openstack/nova"
EPOCHS = 50
OUTPUT_BASE = ROOT / "experiments/nova_review_acceptance/outputs_irl_original_triangular_eval"


def run_training(fw_window, output_dir):
    """è¨“ç·´ã‚’å®Ÿè¡Œï¼ˆç‰¹å®šã®Future Windowã§ï¼‰"""
    cmd = [
        "uv", "run", "python",
        str(ROOT / "scripts/training/irl/train_irl_review_acceptance.py"),
        "--reviews", DATA_PATH,
        "--train-start", TRAIN_START,
        "--train-end", TRAIN_END,
        "--eval-start", EVAL_SNAPSHOT,
        "--eval-end", "2024-01-01",
        "--future-window-start", str(fw_window["fw_start"]),
        "--future-window-end", str(fw_window["fw_end"]),
        "--epochs", str(EPOCHS),
        "--min-history-events", "3",
        "--project", PROJECT,
        "--output", str(output_dir),
    ]
    
    logger.info(f"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
    result = subprocess.run(cmd, cwd=str(ROOT), capture_output=False)
    
    if result.returncode != 0:
        logger.error(f"è¨“ç·´å¤±æ•—: {fw_window['name']}")
        return False
    
    return True


def evaluate_with_model(model_path, threshold_path, fw_window, output_dir):
    """æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ï¼ˆç•°ãªã‚‹Future Windowã§ï¼‰"""
    cmd = [
        "uv", "run", "python",
        str(ROOT / "scripts/training/irl/train_irl_review_acceptance.py"),
        "--reviews", DATA_PATH,
        "--train-start", TRAIN_START,
        "--train-end", TRAIN_END,
        "--eval-start", EVAL_SNAPSHOT,
        "--eval-end", "2024-01-01",
        "--future-window-start", str(fw_window["fw_start"]),
        "--future-window-end", str(fw_window["fw_end"]),
        "--min-history-events", "3",
        "--project", PROJECT,
        "--model", str(model_path),
        "--output", str(output_dir),
    ]
    
    logger.info(f"è©•ä¾¡ã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
    result = subprocess.run(cmd, cwd=str(ROOT), capture_output=False)
    
    if result.returncode != 0:
        logger.error(f"è©•ä¾¡å¤±æ•—: {fw_window['name']}")
        return False
    
    return True


def collect_triangular_eval_results(cross_eval_results):
    """ä¸‰è§’ã‚¯ãƒ­ã‚¹è©•ä¾¡çµæœã‚’ãƒãƒˆãƒªã‚¯ã‚¹å½¢å¼ã§ä¿å­˜"""
    if not cross_eval_results:
        logger.warning("ã‚¯ãƒ­ã‚¹è©•ä¾¡çµæœãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # DataFrameä½œæˆ
    results_df = pd.DataFrame(cross_eval_results)
    results_df.to_csv(OUTPUT_BASE / "triangular_eval_results.csv", index=False)
    logger.info(f"çµæœä¿å­˜: {OUTPUT_BASE / 'triangular_eval_results.csv'}")
    
    # AUC-ROCãƒãƒˆãƒªã‚¯ã‚¹ä½œæˆï¼ˆä¸‰è§’è¡Œåˆ—ï¼‰
    matrix_auc = results_df.pivot(
        index="train_fw",
        columns="eval_fw",
        values="auc_roc"
    )
    
    # åˆ—ã®é †åºã‚’å›ºå®š
    fw_order = ["0-3m", "3-6m", "6-9m", "9-12m"]
    matrix_auc = matrix_auc.reindex(index=fw_order, columns=fw_order)
    
    matrix_auc.to_csv(OUTPUT_BASE / "matrix_AUC_ROC_triangular.csv")
    logger.info(f"AUC-ROCãƒãƒˆãƒªã‚¯ã‚¹ä¿å­˜: {OUTPUT_BASE / 'matrix_AUC_ROC_triangular.csv'}")
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ”¥ ã‚ªãƒªã‚¸ãƒŠãƒ«IRL - ä¸‰è§’ã‚¯ãƒ­ã‚¹è©•ä¾¡ AUC-ROCãƒãƒˆãƒªã‚¯ã‚¹")
    logger.info("=" * 80)
    logger.info("\n" + matrix_auc.to_string())
    
    # å¯¾è§’ç·šï¼ˆåŒã˜FWï¼‰ã®å¹³å‡
    diagonal_values = [matrix_auc.iloc[i, i] for i in range(len(fw_order)) if not pd.isna(matrix_auc.iloc[i, i])]
    if diagonal_values:
        logger.info(f"\nğŸ“Š å¯¾è§’ç·šå¹³å‡ï¼ˆè¨“ç·´FW = è©•ä¾¡FWï¼‰: {np.mean(diagonal_values):.4f}")
    
    # ä¸Šä¸‰è§’ï¼ˆè¨“ç·´FW < è©•ä¾¡FW: å°†æ¥äºˆæ¸¬ï¼‰
    upper_triangle_values = []
    for i in range(len(fw_order)):
        for j in range(i+1, len(fw_order)):
            if not pd.isna(matrix_auc.iloc[i, j]):
                upper_triangle_values.append(matrix_auc.iloc[i, j])
    
    if upper_triangle_values:
        logger.info(f"ğŸ“Š ä¸Šä¸‰è§’å¹³å‡ï¼ˆè¨“ç·´FW < è©•ä¾¡FW: å°†æ¥äºˆæ¸¬ï¼‰: {np.mean(upper_triangle_values):.4f}")
        logger.info(f"   ä»¶æ•°: {len(upper_triangle_values)}é€šã‚Š")
    
    # å…¨ä½“å¹³å‡ï¼ˆä¸‰è§’éƒ¨åˆ†ã®ã¿ï¼‰
    all_values = results_df["auc_roc"].dropna()
    if len(all_values) > 0:
        logger.info(f"ğŸ“Š å…¨ä½“å¹³å‡ï¼ˆ10é€šã‚Šï¼‰: {all_values.mean():.4f}")
        logger.info(f"ğŸ“Š æœ€é«˜AUC-ROC: {all_values.max():.4f}")
        logger.info(f"ğŸ“Š æœ€ä½AUC-ROC: {all_values.min():.4f}")
    
    # FWåˆ¥ã®å¹³å‡æ€§èƒ½
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š è¨“ç·´FWåˆ¥ã®å¹³å‡æ€§èƒ½ï¼ˆãã®FWä»¥é™ã®è©•ä¾¡ï¼‰")
    logger.info("=" * 80)
    for train_fw in fw_order:
        fw_results = results_df[results_df["train_fw"] == train_fw]
        if len(fw_results) > 0:
            avg_auc = fw_results["auc_roc"].mean()
            n_evals = len(fw_results)
            logger.info(f"{train_fw:10s}: å¹³å‡AUC-ROC {avg_auc:.4f} ({n_evals}å€‹ã®è©•ä¾¡FW)")


def main():
    logger.info("=" * 80)
    logger.info("ğŸ”¥ ã‚ªãƒªã‚¸ãƒŠãƒ«IRLï¼ˆAttentionãªã—ï¼‰ - ä¸‰è§’ã‚¯ãƒ­ã‚¹è©•ä¾¡ ğŸ”¥")
    logger.info("=" * 80)
    logger.info(f"å­¦ç¿’æœŸé–“: {TRAIN_START} ï½ {TRAIN_END}ï¼ˆå›ºå®šï¼‰")
    logger.info(f"è©•ä¾¡ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ: {EVAL_SNAPSHOT}ï¼ˆå›ºå®šï¼‰")
    logger.info(f"Future Window: 0-3m, 3-6m, 6-9m, 9-12m ã®4ãƒ‘ã‚¿ãƒ¼ãƒ³")
    logger.info(f"è©•ä¾¡ãƒ‘ã‚¿ãƒ¼ãƒ³: ä¸‰è§’è¡Œåˆ—ï¼ˆè¨“ç·´FWä»¥é™ã®ã¿ï¼‰= 10é€šã‚Š")
    logger.info("=" * 80)
    
    OUTPUT_BASE.mkdir(parents=True, exist_ok=True)
    
    # å„Future Windowã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘4ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´")
    logger.info("=" * 80)
    
    trained_models = {}
    
    for fw_window in FUTURE_WINDOWS:
        logger.info(f"\nè¨“ç·´é–‹å§‹: Future Window {fw_window['name']} ({fw_window['fw_start']}-{fw_window['fw_end']}ãƒ¶æœˆå¾Œ)")
        
        output_dir = OUTPUT_BASE / f"train_{fw_window['name']}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        if not run_training(fw_window, output_dir):
            logger.error(f"è¨“ç·´å¤±æ•—: {fw_window['name']}")
            continue
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’ä¿å­˜
        model_path = output_dir / "irl_model.pt"
        threshold_path = output_dir / "optimal_threshold.json"
        
        if model_path.exists() and threshold_path.exists():
            trained_models[fw_window['name']] = {
                "model_path": model_path,
                "threshold_path": threshold_path,
                "fw_window": fw_window,
                "fw_index": FUTURE_WINDOWS.index(fw_window)
            }
            logger.info(f"âœ… è¨“ç·´å®Œäº†: {fw_window['name']}")
        else:
            logger.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {fw_window['name']}")
    
    # ä¸‰è§’ã‚¯ãƒ­ã‚¹è©•ä¾¡ï¼ˆè¨“ç·´FWä»¥é™ã®ã¿ï¼‰
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ä¸‰è§’ã‚¯ãƒ­ã‚¹è©•ä¾¡ï¼ˆ10é€šã‚Šï¼‰")
    logger.info("=" * 80)
    
    cross_eval_results = []
    
    for train_fw_name, model_info in trained_models.items():
        train_fw_idx = model_info["fw_index"]
        
        # ã“ã®ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´FWä»¥é™ã®FWã§è©•ä¾¡
        for eval_fw_idx in range(train_fw_idx, len(FUTURE_WINDOWS)):
            eval_fw = FUTURE_WINDOWS[eval_fw_idx]
            
            logger.info(f"\nè©•ä¾¡: {train_fw_name}ãƒ¢ãƒ‡ãƒ« â†’ {eval_fw['name']}FW")
            
            eval_output_dir = OUTPUT_BASE / f"train_{train_fw_name}" / f"eval_{eval_fw['name']}"
            eval_output_dir.mkdir(parents=True, exist_ok=True)
            
            if not evaluate_with_model(
                model_info["model_path"],
                model_info["threshold_path"],
                eval_fw,
                eval_output_dir
            ):
                logger.error(f"è©•ä¾¡å¤±æ•—: {train_fw_name} â†’ {eval_fw['name']}")
                continue
            
            # çµæœã‚’åé›†
            metrics_path = eval_output_dir / "metrics.json"
            if metrics_path.exists():
                import json
                with open(metrics_path) as f:
                    metrics = json.load(f)
                
                cross_eval_results.append({
                    "train_fw": train_fw_name,
                    "eval_fw": eval_fw["name"],
                    "auc_roc": metrics.get("auc_roc", 0.0),
                    "auc_pr": metrics.get("auc_pr", 0.0),
                    "f1_score": metrics.get("f1_score", 0.0),
                    "precision": metrics.get("precision", 0.0),
                    "recall": metrics.get("recall", 0.0),
                })
                logger.info(f"âœ… AUC-ROC: {metrics.get('auc_roc', 0.0):.4f}")
    
    # çµæœåé›†
    logger.info("\nã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘çµæœã‚’ãƒãƒˆãƒªã‚¯ã‚¹å½¢å¼ã§ä¿å­˜")
    collect_triangular_eval_results(cross_eval_results)
    
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ‰ ä¸‰è§’ã‚¯ãƒ­ã‚¹è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    logger.info("=" * 80)


if __name__ == "__main__":
    main()
