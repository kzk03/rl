"""
Novaå˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³

Enhanced IRLãƒ»Attention-less IRL ã¨ã®æ¯”è¼ƒç”¨
ãƒ‡ãƒ¼ã‚¿: openstack/nova ã®ã¿
"""

import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

import warnings
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

warnings.filterwarnings('ignore')


def calculate_rf_features(df: pd.DataFrame, reviewer: str, context_date: datetime) -> np.ndarray:
    """RFç”¨ç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆ10æ¬¡å…ƒ - IRLçŠ¶æ…‹ç‰¹å¾´é‡ã¨åŒã˜ï¼‰"""
    reviewer_df = df[df['reviewer_email'] == reviewer].copy()
    
    if len(reviewer_df) == 0:
        return np.zeros(10)
    
    reviewer_df['timestamp'] = pd.to_datetime(reviewer_df['request_time'])
    reviewer_df = reviewer_df[reviewer_df['timestamp'] < context_date]
    
    if len(reviewer_df) == 0:
        return np.zeros(10)
    
    # çµŒé¨“æ—¥æ•°
    first_seen = reviewer_df['timestamp'].min()
    experience_days = (context_date - first_seen).days / 730.0
    
    # ç·å¤‰æ›´æ•°ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°
    total_changes = len(reviewer_df) / 500.0
    total_reviews = len(reviewer_df) / 500.0
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°ï¼ˆnovaå˜ä¸€ãªã®ã§å¸¸ã«1ï¼‰
    project_count = 1.0
    
    # æœ€è¿‘ã®æ´»å‹•é »åº¦
    recent_cutoff = context_date - timedelta(days=30)
    recent_df = reviewer_df[reviewer_df['timestamp'] >= recent_cutoff]
    recent_activity_frequency = len(recent_df) / 30.0
    
    # å¹³å‡æ´»å‹•é–“éš”
    if len(reviewer_df) > 1:
        sorted_times = reviewer_df['timestamp'].sort_values()
        time_diffs = sorted_times.diff().dt.total_seconds().dropna()
        avg_activity_gap = time_diffs.mean() / 86400.0 if len(time_diffs) > 0 else 1.0
        avg_activity_gap = min(avg_activity_gap, 60.0) / 60.0
    else:
        avg_activity_gap = 0.5
    
    # æ´»å‹•ãƒˆãƒ¬ãƒ³ãƒ‰
    if len(reviewer_df) > 1:
        midpoint = first_seen + (context_date - first_seen) / 2
        recent_half = reviewer_df[reviewer_df['timestamp'] >= midpoint]
        past_half = reviewer_df[reviewer_df['timestamp'] < midpoint]
        
        if len(past_half) > 0:
            activity_trend = len(recent_half) / len(past_half)
            if activity_trend > 1.5:
                activity_trend = 1.0
            elif activity_trend > 0.8:
                activity_trend = 0.5
            else:
                activity_trend = 0.0
        else:
            activity_trend = 0.5
    else:
        activity_trend = 0.5
    
    # æœ€çµ‚æ´»å‹•ã‹ã‚‰ã®çµŒéæ—¥æ•°
    last_activity = reviewer_df['timestamp'].max()
    days_since_last = (context_date - last_activity).days / 365.0
    
    # ãƒ¬ãƒ“ãƒ¥ãƒ¼å—ã‘å…¥ã‚Œç‡
    acceptance_rate = reviewer_df['label'].mean() if 'label' in reviewer_df.columns else 0.0
    
    # æœ€è¿‘30æ—¥ã®å—ã‘å…¥ã‚Œç‡
    if len(recent_df) > 0:
        recent_acceptance = recent_df['label'].mean() if 'label' in recent_df.columns else 0.0
    else:
        recent_acceptance = 0.0
    
    return np.array([
        experience_days,
        total_changes,
        total_reviews,
        project_count,
        recent_activity_frequency,
        avg_activity_gap,
        activity_trend,
        days_since_last,
        acceptance_rate,
        recent_acceptance
    ])


def prepare_data(df: pd.DataFrame, cutoff_date: datetime,
                 history_months: int = 6,
                 eval_future_start_months: int = 6,
                 eval_future_end_months: int = 9):
    """å­¦ç¿’ãƒ»è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™"""
    
    # å±¥æ­´æœŸé–“
    history_start = cutoff_date - pd.DateOffset(months=history_months)
    history_df = df[(df['request_time'] >= history_start) & (df['request_time'] < cutoff_date)]
    
    # å°†æ¥çª“
    future_start = cutoff_date + pd.DateOffset(months=eval_future_start_months)
    future_end = cutoff_date + pd.DateOffset(months=eval_future_end_months)
    
    # æ¯é›†å›£ï¼šå°†æ¥çª“ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãŒã‚ã£ãŸäººå…¨å“¡
    future_request_df = df[(df['request_time'] >= future_start) & (df['request_time'] < future_end)]
    eval_reviewers = set(future_request_df['reviewer_email'].unique())
    
    print(f"\nâœ… Evaläºˆæ¸¬å¯¾è±¡: å°†æ¥çª“ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼ãŒã‚ã£ãŸ {len(eval_reviewers)} äºº")
    
    # ç¶™ç¶šåˆ¤å®šï¼šå°†æ¥çª“ã§å°‘ãªãã¨ã‚‚1å›å—ã‘å…¥ã‚ŒãŸã‹ï¼ˆlabel=1ãŒ1ã¤ã§ã‚‚ã‚ã‚‹ï¼‰
    future_accepted = future_request_df[future_request_df['label'] == 1]['reviewer_email'].unique()
    future_active = set(future_accepted)
    
    eval_samples = []
    for reviewer in eval_reviewers:
        # å°†æ¥çª“ã§å°‘ãªãã¨ã‚‚1å›å—ã‘å…¥ã‚ŒãŸ = ç¶™ç¶š
        label = 1 if reviewer in future_active else 0
        eval_samples.append({
            'reviewer': reviewer,
            'cutoff_date': cutoff_date,
            'label': label
        })
    
    eval_df = pd.DataFrame(eval_samples)
    continuation_rate = eval_df['label'].mean()
    
    print(f"âœ… Eval: {len(eval_df)} ã‚µãƒ³ãƒ—ãƒ«, ç¶™ç¶šç‡={continuation_rate:.3f}")
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼šå±¥æ­´æœŸé–“å†…ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    train_df = history_df.copy()
    train_reviewers = train_df['reviewer_email'].unique()
    
    # æœˆæ¬¡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    train_df['year_month'] = pd.to_datetime(train_df['request_time']).dt.to_period('M')
    months = train_df['year_month'].unique()
    
    train_samples = []
    for month in months:
        month_df = train_df[train_df['year_month'] == month]
        month_end = pd.Timestamp(month.to_timestamp()) + pd.DateOffset(months=1)
        
        # ãã®æœˆã«æ´»å‹•ã—ãŸäººã‚’å¯¾è±¡
        month_reviewers = month_df['reviewer_email'].unique()
        
        for reviewer in month_reviewers:
            reviewer_month_df = month_df[month_df['reviewer_email'] == reviewer]
            # ãã®æœˆã«å—ã‘å…¥ã‚ŒãŸã‹
            label = 1 if (reviewer_month_df['label'] == 1).any() else 0
            
            train_samples.append({
                'reviewer': reviewer,
                'cutoff_date': month_end,
                'label': label
            })
    
    train_df = pd.DataFrame(train_samples)
    train_continuation_rate = train_df['label'].mean()
    
    print(f"âœ… Train: {len(train_df)} ã‚µãƒ³ãƒ—ãƒ«, ç¶™ç¶šç‡={train_continuation_rate:.3f}")
    
    return train_df, eval_df


def main():
    print("=" * 80)
    print("Novaå˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³")
    print("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data_path = project_root / "data" / "review_requests_openstack_multi_5y_detail.csv"
    print(f"\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {data_path}")
    
    df = pd.read_csv(data_path)
    df['request_time'] = pd.to_datetime(df['request_time'])
    
    # novaå˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã¿
    df = df[df['project'] == 'openstack/nova'].copy()
    print(f"âœ… Novaå˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {len(df)} ãƒ¬ã‚³ãƒ¼ãƒ‰, {df['reviewer_email'].nunique()} ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼")
    
    # å®Ÿé¨“è¨­å®šï¼ˆEnhanced IRLã¨åŒã˜ï¼‰
    seed = 42
    np.random.seed(seed)
    
    # 2023å¹´1æœˆ1æ—¥ã‚’åŸºæº–ã«ã—ãŸå®Ÿé¨“
    cutoff_date = datetime(2023, 1, 1)
    history_months = 6
    eval_future_start = 6
    eval_future_end = 9
    
    print(f"\nğŸ“… å®Ÿé¨“è¨­å®š:")
    print(f"  ã‚«ãƒƒãƒˆã‚ªãƒ•æ—¥: {cutoff_date.date()}")
    print(f"  å±¥æ­´æœŸé–“: {history_months}ãƒ¶æœˆ")
    print(f"  è©•ä¾¡å°†æ¥çª“: +{eval_future_start}ã€œ+{eval_future_end}ãƒ¶æœˆ")
    print(f"  Seed: {seed}")
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    print("\n" + "=" * 80)
    print("ãƒ‡ãƒ¼ã‚¿æº–å‚™")
    print("=" * 80)
    
    train_df, eval_df = prepare_data(
        df, cutoff_date,
        history_months=history_months,
        eval_future_start_months=eval_future_start,
        eval_future_end_months=eval_future_end
    )
    
    # ç‰¹å¾´é‡è¨ˆç®—
    print("\n" + "=" * 80)
    print("ç‰¹å¾´é‡è¨ˆç®—")
    print("=" * 80)
    
    print("Trainç‰¹å¾´é‡è¨ˆç®—ä¸­...")
    X_train = []
    y_train = []
    for _, row in train_df.iterrows():
        features = calculate_rf_features(df, row['reviewer'], row['cutoff_date'])
        X_train.append(features)
        y_train.append(row['label'])
    
    X_train = np.array(X_train)
    y_train = np.array(y_train)
    
    print(f"âœ… Train: {X_train.shape}")
    
    print("Evalç‰¹å¾´é‡è¨ˆç®—ä¸­...")
    X_eval = []
    y_eval = []
    for _, row in eval_df.iterrows():
        features = calculate_rf_features(df, row['reviewer'], row['cutoff_date'])
        X_eval.append(features)
        y_eval.append(row['label'])
    
    X_eval = np.array(X_eval)
    y_eval = np.array(y_eval)
    
    print(f"âœ… Eval: {X_eval.shape}")
    
    # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå­¦ç¿’
    print("\n" + "=" * 80)
    print("ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå­¦ç¿’")
    print("=" * 80)
    
    rf = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=10,
        min_samples_leaf=5,
        random_state=seed,
        n_jobs=-1
    )
    
    rf.fit(X_train, y_train)
    print("âœ… å­¦ç¿’å®Œäº†")
    
    # è©•ä¾¡
    print("\n" + "=" * 80)
    print("è©•ä¾¡")
    print("=" * 80)
    
    # Train AUC
    train_probs = rf.predict_proba(X_train)[:, 1]
    train_auc = roc_auc_score(y_train, train_probs)
    print(f"Train AUC: {train_auc:.4f}")
    
    # Eval AUC
    eval_probs = rf.predict_proba(X_eval)[:, 1]
    eval_auc = roc_auc_score(y_eval, eval_probs)
    print(f"Eval AUC: {eval_auc:.4f}")
    
    # çµæœä¿å­˜
    print("\n" + "=" * 80)
    print("çµæœä¿å­˜")
    print("=" * 80)
    
    result_dir = Path(__file__).parent.parent / "results"
    result_dir.mkdir(exist_ok=True)
    
    result = {
        'model': 'RandomForest',
        'project': 'nova',
        'seed': seed,
        'cutoff_date': cutoff_date.strftime('%Y-%m-%d'),
        'history_months': history_months,
        'eval_future_start': eval_future_start,
        'eval_future_end': eval_future_end,
        'train_samples': len(train_df),
        'eval_samples': len(eval_df),
        'train_continuation_rate': float(train_df['label'].mean()),
        'eval_continuation_rate': float(eval_df['label'].mean()),
        'train_auc': float(train_auc),
        'eval_auc': float(eval_auc),
        'n_estimators': 100,
        'max_depth': 10
    }
    
    result_file = result_dir / "rf_baseline_result.json"
    import json
    with open(result_file, 'w') as f:
        json.dump(result, f, indent=2)
    
    print(f"âœ… çµæœä¿å­˜: {result_file}")
    
    # ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("å®Ÿé¨“ã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    print(f"ãƒ¢ãƒ‡ãƒ«: RandomForest")
    print(f"Train AUC: {train_auc:.4f}")
    print(f"Eval AUC: {eval_auc:.4f}")
    print(f"")
    print(f"æ¯”è¼ƒ:")
    print(f"  Enhanced IRL (Attention): 0.8033")
    print(f"  Attention-less IRL: 0.7536")
    print(f"  RandomForest (baseline): {eval_auc:.4f}")
    print("=" * 80)


if __name__ == "__main__":
    main()
