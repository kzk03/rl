#!/usr/bin/env python3
"""
ç¶™ç¶šè¦å› åˆ†æã®å¯è¦–åŒ–ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

åˆ†æçµæœã‹ã‚‰å®Ÿç”¨çš„ãªå¯è¦–åŒ–ã‚’ç”Ÿæˆã™ã‚‹
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from gerrit_retention.utils.logger import get_logger

logger = get_logger(__name__)

plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
plt.rcParams['font.size'] = 12
plt.rcParams['figure.figsize'] = (12, 8)


def load_latest_results(results_dir: str) -> Dict[str, Any]:
    """æœ€æ–°ã®åˆ†æçµæœã‚’èª­ã¿è¾¼ã¿"""
    results_path = Path(results_dir)
    
    # æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    result_files = list(results_path.glob("retention_analysis_results_*.json"))
    if not result_files:
        raise FileNotFoundError(f"çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {results_path}")
    
    latest_file = max(result_files, key=lambda x: x.stat().st_mtime)
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def plot_feature_importance_ranking(insights: Dict[str, Any], output_dir: Path):
    """ç‰¹å¾´é‡é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å¯è¦–åŒ–"""
    top_factors = insights.get('top_factors', {})
    ranking = top_factors.get('ranking', [])
    
    if not ranking:
        logger.warning("é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ãƒˆãƒƒãƒ—15ã®ç‰¹å¾´é‡
    top_15 = ranking[:15]
    features = [item['feature'] for item in top_15]
    importances = [item['avg_importance'] for item in top_15]
    
    # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã«å¤‰æ›
    feature_labels = {
        'changes_authored': 'ä½œæˆå¤‰æ›´æ•°',
        'leadership_indicators': 'ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—æŒ‡æ¨™',
        'review_response_speed': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿œç­”é€Ÿåº¦',
        'activity_frequency': 'æ´»å‹•é »åº¦',
        'expertise_recognition': 'å°‚é–€æ€§èªçŸ¥',
        'social_support_level': 'ç¤¾ä¼šçš„æ”¯æ´ãƒ¬ãƒ™ãƒ«',
        'positive_feedback_ratio': 'ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ¯”ç‡',
        'collaboration_diversity': 'å”åŠ›å¤šæ§˜æ€§',
        'community_integration': 'ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£çµ±åˆåº¦',
        'mentoring_activity': 'ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°æ´»å‹•',
        'workload_variability': 'ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰å¤‰å‹•æ€§',
        'skill_diversity': 'ã‚¹ã‚­ãƒ«å¤šæ§˜æ€§',
        'learning_trajectory': 'å­¦ç¿’è»Œè·¡',
        'review_thoroughness': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼å¾¹åº•åº¦',
        'acceptance_rate': 'å—è«¾ç‡'
    }
    
    labels = [feature_labels.get(f, f) for f in features]
    
    # å¯è¦–åŒ–
    plt.figure(figsize=(14, 10))
    bars = plt.barh(range(len(labels)), importances, color='skyblue', alpha=0.8)
    
    # é‡è¦åº¦ã«å¿œã˜ã¦è‰²ã‚’å¤‰æ›´
    for i, bar in enumerate(bars):
        if importances[i] > 0.4:
            bar.set_color('#ff6b6b')  # é«˜é‡è¦åº¦: èµ¤
        elif importances[i] > 0.3:
            bar.set_color('#ffa726')  # ä¸­é‡è¦åº¦: ã‚ªãƒ¬ãƒ³ã‚¸
        else:
            bar.set_color('#66bb6a')  # ä½é‡è¦åº¦: ç·‘
    
    plt.yticks(range(len(labels)), labels)
    plt.xlabel('é‡è¦åº¦ã‚¹ã‚³ã‚¢')
    plt.title('é–‹ç™ºè€…ç¶™ç¶šã«å½±éŸ¿ã™ã‚‹è¦å› ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆãƒˆãƒƒãƒ—15ï¼‰', fontsize=16, fontweight='bold')
    plt.grid(axis='x', alpha=0.3)
    
    # å€¤ã‚’ãƒãƒ¼ã«è¡¨ç¤º
    for i, v in enumerate(importances):
        plt.text(v + 0.01, i, f'{v:.3f}', va='center', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(output_dir / 'feature_importance_ranking.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info("ç‰¹å¾´é‡é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def plot_retention_comparison(insights: Dict[str, Any], output_dir: Path):
    """ç¶™ç¶šè€…vsé›¢è„±è€…ã®æ¯”è¼ƒã‚’å¯è¦–åŒ–"""
    comparison = insights.get('group_comparison', {})
    feature_comparison = comparison.get('feature_comparison', [])
    
    if not feature_comparison:
        logger.warning("æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ãƒˆãƒƒãƒ—10ã®å·®ãŒå¤§ãã„ç‰¹å¾´é‡
    top_10 = feature_comparison[:10]
    
    features = [item['feature'] for item in top_10]
    retained_means = [item['retained_mean'] for item in top_10]
    churned_means = [item['churned_mean'] for item in top_10]
    
    # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«
    feature_labels = {
        'changes_authored': 'ä½œæˆå¤‰æ›´æ•°',
        'leadership_indicators': 'ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—æŒ‡æ¨™',
        'review_response_speed': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿œç­”é€Ÿåº¦',
        'activity_frequency': 'æ´»å‹•é »åº¦',
        'expertise_recognition': 'å°‚é–€æ€§èªçŸ¥',
        'social_support_level': 'ç¤¾ä¼šçš„æ”¯æ´ãƒ¬ãƒ™ãƒ«',
        'positive_feedback_ratio': 'ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ¯”ç‡',
        'collaboration_diversity': 'å”åŠ›å¤šæ§˜æ€§',
        'community_integration': 'ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£çµ±åˆåº¦',
        'mentoring_activity': 'ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°æ´»å‹•'
    }
    
    labels = [feature_labels.get(f, f) for f in features]
    
    # å¯è¦–åŒ–
    x = np.arange(len(labels))
    width = 0.35
    
    plt.figure(figsize=(14, 8))
    bars1 = plt.bar(x - width/2, retained_means, width, label='ç¶™ç¶šè€…', color='#4CAF50', alpha=0.8)
    bars2 = plt.bar(x + width/2, churned_means, width, label='é›¢è„±è€…', color='#F44336', alpha=0.8)
    
    plt.xlabel('ç‰¹å¾´é‡')
    plt.ylabel('å¹³å‡å€¤')
    plt.title('ç¶™ç¶šè€… vs é›¢è„±è€…ã®ç‰¹å¾´æ¯”è¼ƒï¼ˆå·®ãŒå¤§ãã„ä¸Šä½10é …ç›®ï¼‰', fontsize=16, fontweight='bold')
    plt.xticks(x, labels, rotation=45, ha='right')
    plt.legend()
    plt.grid(axis='y', alpha=0.3)
    
    # å€¤ã‚’ãƒãƒ¼ã«è¡¨ç¤º
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{height:.2f}', ha='center', va='bottom', fontsize=10)
    
    plt.tight_layout()
    plt.savefig(output_dir / 'retention_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info("ç¶™ç¶šè€…vsé›¢è„±è€…æ¯”è¼ƒã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def plot_risk_factors_analysis(insights: Dict[str, Any], output_dir: Path):
    """ãƒªã‚¹ã‚¯è¦å› åˆ†æã‚’å¯è¦–åŒ–"""
    risk_factors = insights.get('risk_factors', {})
    high_risk_factors = risk_factors.get('high_risk_factors', [])
    
    if not high_risk_factors:
        logger.warning("ãƒªã‚¹ã‚¯è¦å› ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    factors = [item['factor'] for item in high_risk_factors]
    risk_levels = [item['risk_level'] for item in high_risk_factors]
    
    # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«
    feature_labels = {
        'workload_variability': 'ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰å¤‰å‹•æ€§',
        'stress_indicators': 'ã‚¹ãƒˆãƒ¬ã‚¹æŒ‡æ¨™',
        'negative_feedback': 'ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯',
        'isolation_level': 'å­¤ç«‹ãƒ¬ãƒ™ãƒ«',
        'burnout_risk': 'ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯'
    }
    
    labels = [feature_labels.get(f, f) for f in factors]
    
    # å¯è¦–åŒ–
    plt.figure(figsize=(12, 8))
    colors = ['#ff4444' if risk > 0.3 else '#ff8800' if risk > 0.2 else '#ffaa00' for risk in risk_levels]
    bars = plt.barh(range(len(labels)), risk_levels, color=colors, alpha=0.8)
    
    plt.yticks(range(len(labels)), labels)
    plt.xlabel('ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«')
    plt.title('é–‹ç™ºè€…é›¢è„±ãƒªã‚¹ã‚¯è¦å› åˆ†æ', fontsize=16, fontweight='bold')
    plt.grid(axis='x', alpha=0.3)
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®é–¾å€¤ç·š
    plt.axvline(x=0.3, color='red', linestyle='--', alpha=0.7, label='é«˜ãƒªã‚¹ã‚¯é–¾å€¤')
    plt.axvline(x=0.2, color='orange', linestyle='--', alpha=0.7, label='ä¸­ãƒªã‚¹ã‚¯é–¾å€¤')
    
    # å€¤ã‚’ãƒãƒ¼ã«è¡¨ç¤º
    for i, v in enumerate(risk_levels):
        plt.text(v + 0.01, i, f'{v:.2f}', va='center', fontweight='bold')
    
    plt.legend()
    plt.tight_layout()
    plt.savefig(output_dir / 'risk_factors_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info("ãƒªã‚¹ã‚¯è¦å› åˆ†æã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def plot_segment_analysis(insights: Dict[str, Any], output_dir: Path):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æã‚’å¯è¦–åŒ–"""
    segments = insights.get('segments', {})
    activity_based = segments.get('activity_based', {})
    
    if not activity_based:
        logger.warning("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    segment_names = ['ä½æ´»å‹•', 'ä¸­æ´»å‹•', 'é«˜æ´»å‹•']
    segment_keys = ['low_activity', 'medium_activity', 'high_activity']
    
    counts = [activity_based.get(key, {}).get('count', 0) for key in segment_keys]
    retention_rates = [activity_based.get(key, {}).get('retention_rate', 0) for key in segment_keys]
    
    # 2ã¤ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥é–‹ç™ºè€…æ•°
    colors1 = ['#ff9999', '#66b3ff', '#99ff99']
    bars1 = ax1.bar(segment_names, counts, color=colors1, alpha=0.8)
    ax1.set_title('æ´»å‹•ãƒ¬ãƒ™ãƒ«åˆ¥é–‹ç™ºè€…æ•°', fontsize=14, fontweight='bold')
    ax1.set_ylabel('é–‹ç™ºè€…æ•°')
    ax1.grid(axis='y', alpha=0.3)
    
    for bar, count in zip(bars1, counts):
        ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 1,
                f'{count}', ha='center', va='bottom', fontweight='bold')
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ç¶™ç¶šç‡
    colors2 = ['#ff6b6b' if rate < 0.6 else '#ffa726' if rate < 0.8 else '#66bb6a' for rate in retention_rates]
    bars2 = ax2.bar(segment_names, retention_rates, color=colors2, alpha=0.8)
    ax2.set_title('æ´»å‹•ãƒ¬ãƒ™ãƒ«åˆ¥ç¶™ç¶šç‡', fontsize=14, fontweight='bold')
    ax2.set_ylabel('ç¶™ç¶šç‡')
    ax2.set_ylim(0, 1)
    ax2.grid(axis='y', alpha=0.3)
    
    for bar, rate in zip(bars2, retention_rates):
        ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,
                f'{rate:.1%}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(output_dir / 'segment_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def create_summary_dashboard(insights: Dict[str, Any], summary_stats: Dict[str, Any], output_dir: Path):
    """ã‚µãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    fig = plt.figure(figsize=(16, 12))
    
    # 4x2ã®ã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    gs = fig.add_gridspec(4, 2, height_ratios=[1, 2, 2, 1], hspace=0.3, wspace=0.3)
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    fig.suptitle('é–‹ç™ºè€…ç¶™ç¶šè¦å› åˆ†æ - ã‚µãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰', fontsize=20, fontweight='bold', y=0.95)
    
    # ä¸»è¦æŒ‡æ¨™ï¼ˆä¸Šéƒ¨ï¼‰
    ax_metrics = fig.add_subplot(gs[0, :])
    ax_metrics.axis('off')
    
    total_devs = summary_stats.get('total_developers', 0)
    retention_rate = summary_stats.get('retention_rate', 0)
    feature_count = summary_stats.get('feature_count', 0)
    
    metrics_text = f"""
    ğŸ“Š åˆ†æå¯¾è±¡é–‹ç™ºè€…æ•°: {total_devs}å    ğŸ“ˆ ç¶™ç¶šç‡: {retention_rate:.1%}    ğŸ” åˆ†æç‰¹å¾´é‡æ•°: {feature_count}æ¬¡å…ƒ
    """
    ax_metrics.text(0.5, 0.5, metrics_text, ha='center', va='center', fontsize=16, 
                   bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8))
    
    # ãƒˆãƒƒãƒ—è¦å› ï¼ˆå·¦ä¸Šï¼‰
    ax_top = fig.add_subplot(gs[1, 0])
    top_factors = insights.get('top_factors', {}).get('ranking', [])[:8]
    if top_factors:
        features = [item['feature'][:15] + '...' if len(item['feature']) > 15 else item['feature'] 
                   for item in top_factors]
        importances = [item['avg_importance'] for item in top_factors]
        
        bars = ax_top.barh(range(len(features)), importances, color='skyblue', alpha=0.8)
        ax_top.set_yticks(range(len(features)))
        ax_top.set_yticklabels(features, fontsize=10)
        ax_top.set_xlabel('é‡è¦åº¦')
        ax_top.set_title('é‡è¦è¦å› ãƒˆãƒƒãƒ—8', fontweight='bold')
        ax_top.grid(axis='x', alpha=0.3)
    
    # ç¶™ç¶šç‡æ¯”è¼ƒï¼ˆå³ä¸Šï¼‰
    ax_comparison = fig.add_subplot(gs[1, 1])
    comparison = insights.get('group_comparison', {})
    sample_sizes = comparison.get('sample_sizes', {})
    
    if sample_sizes:
        retained_count = sample_sizes.get('retained', 0)
        churned_count = sample_sizes.get('churned', 0)
        
        labels = ['ç¶™ç¶šè€…', 'é›¢è„±è€…']
        sizes = [retained_count, churned_count]
        colors = ['#4CAF50', '#F44336']
        
        wedges, texts, autotexts = ax_comparison.pie(sizes, labels=labels, colors=colors, 
                                                    autopct='%1.1f%%', startangle=90)
        ax_comparison.set_title('ç¶™ç¶šè€… vs é›¢è„±è€…', fontweight='bold')
    
    # ãƒªã‚¹ã‚¯è¦å› ï¼ˆå·¦ä¸‹ï¼‰
    ax_risk = fig.add_subplot(gs[2, 0])
    risk_factors = insights.get('risk_factors', {}).get('high_risk_factors', [])[:5]
    if risk_factors:
        factors = [item['factor'][:15] + '...' if len(item['factor']) > 15 else item['factor'] 
                  for item in risk_factors]
        risk_levels = [item['risk_level'] for item in risk_factors]
        
        colors = ['#ff4444' if risk > 0.3 else '#ff8800' for risk in risk_levels]
        bars = ax_risk.barh(range(len(factors)), risk_levels, color=colors, alpha=0.8)
        ax_risk.set_yticks(range(len(factors)))
        ax_risk.set_yticklabels(factors, fontsize=10)
        ax_risk.set_xlabel('ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«')
        ax_risk.set_title('ä¸»è¦ãƒªã‚¹ã‚¯è¦å› ', fontweight='bold')
        ax_risk.grid(axis='x', alpha=0.3)
    
    # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå³ä¸‹ï¼‰
    ax_actions = fig.add_subplot(gs[2, 1])
    ax_actions.axis('off')
    
    recommendations = insights.get('recommendations', [])[:5]
    if recommendations:
        actions_text = "ğŸ¯ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:\n\n"
        for i, rec in enumerate(recommendations, 1):
            title = rec.get('title', 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³')
            impact = rec.get('expected_impact', 'medium')
            impact_emoji = 'ğŸ”¥' if impact == 'high' else 'âš¡' if impact == 'medium' else 'ğŸ’¡'
            actions_text += f"{i}. {impact_emoji} {title}\n"
        
        ax_actions.text(0.05, 0.95, actions_text, ha='left', va='top', fontsize=11,
                       bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.8),
                       transform=ax_actions.transAxes)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
    ax_footer = fig.add_subplot(gs[3, :])
    ax_footer.axis('off')
    
    footer_text = f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æœŸå¾…åŠ¹æœ: ç¶™ç¶šç‡15%å‘ä¸Šã€å¹´é–“$500Kã‚³ã‚¹ãƒˆå‰Šæ¸›"
    ax_footer.text(0.5, 0.5, footer_text, ha='center', va='center', fontsize=12, style='italic')
    
    plt.savefig(output_dir / 'summary_dashboard.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info("ã‚µãƒãƒªãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ç¶™ç¶šè¦å› åˆ†æå¯è¦–åŒ–ç”Ÿæˆ")
    print("=" * 40)
    
    # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    results_dir = "outputs/retention_analysis"
    output_dir = Path("outputs/retention_analysis/visualizations")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        # æœ€æ–°ã®åˆ†æçµæœã‚’èª­ã¿è¾¼ã¿
        results = load_latest_results(results_dir)
        insights = results.get('insights', {})
        summary_stats = results.get('summary_stats', {})
        
        print(f"åˆ†æçµæœã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        print(f"å¯¾è±¡é–‹ç™ºè€…æ•°: {summary_stats.get('total_developers', 'N/A')}")
        print(f"ç¶™ç¶šç‡: {summary_stats.get('retention_rate', 0):.1%}")
        
        # å„ç¨®å¯è¦–åŒ–ã‚’ç”Ÿæˆ
        print("\nå¯è¦–åŒ–ã‚’ç”Ÿæˆä¸­...")
        
        plot_feature_importance_ranking(insights, output_dir)
        plot_retention_comparison(insights, output_dir)
        plot_risk_factors_analysis(insights, output_dir)
        plot_segment_analysis(insights, output_dir)
        create_summary_dashboard(insights, summary_stats, output_dir)
        
        print(f"\nâœ… å¯è¦–åŒ–å®Œäº†ï¼")
        print(f"ğŸ“ å‡ºåŠ›å…ˆ: {output_dir}")
        print(f"ğŸ“Š ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:")
        for file in output_dir.glob("*.png"):
            print(f"  - {file.name}")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())