#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„äºˆæ¸¬ç²¾åº¦æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ 

1. é«˜åº¦ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’
2. A/Bãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹æˆ¦ç•¥æ¯”è¼ƒ
3. æ–°ã—ã„ç‰¹å¾´é‡ã®è‡ªå‹•ç™ºè¦‹
4. ç¶™ç¶šçš„ãªæ€§èƒ½ç›£è¦–

ç¾åœ¨ã®217.7%æ”¹å–„ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ã•ã‚‰ãªã‚‹ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾
"""

import json
import sys
import warnings
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

import numpy as np
import pandas as pd

warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from src.gerrit_retention.prediction.ab_testing_system import ABTestingSystem
from src.gerrit_retention.prediction.advanced_accuracy_improver import (
    AdvancedAccuracyImprover,
)


def load_developer_data(data_path: str) -> List[Dict[str, Any]]:
    """é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    print(f"ğŸ“Š é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {data_path}")
    
    with open(data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"âœ… {len(data)}äººã®é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    return data

def create_enhanced_retention_labels(developer_data: List[Dict[str, Any]]) -> np.ndarray:
    """å¼·åŒ–ã•ã‚ŒãŸç¶™ç¶šç‡ãƒ©ãƒ™ãƒ«ã®ä½œæˆ"""
    print("ğŸ¯ å¼·åŒ–ã•ã‚ŒãŸç¶™ç¶šç‡ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆä¸­...")
    
    labels = []
    current_time = datetime.now()
    
    # çµ±è¨ˆæƒ…å ±ã®åé›†
    all_activities = []
    all_durations = []
    
    for dev in developer_data:
        try:
            total_activity = dev.get('changes_authored', 0) + dev.get('changes_reviewed', 0)
            all_activities.append(total_activity)
            
            first_seen = datetime.fromisoformat(
                dev.get('first_seen', '').replace(' ', 'T')
            )
            last_activity = datetime.fromisoformat(
                dev.get('last_activity', '').replace(' ', 'T')
            )
            duration = (last_activity - first_seen).days
            all_durations.append(duration)
        except:
            all_activities.append(0)
            all_durations.append(0)
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã®è¨ˆç®—
    activity_percentiles = np.percentile(all_activities, [25, 50, 75, 90])
    duration_percentiles = np.percentile(all_durations, [25, 50, 75, 90])
    
    print(f"   æ´»å‹•é‡ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: 25%={activity_percentiles[0]:.0f}, "
          f"50%={activity_percentiles[1]:.0f}, 75%={activity_percentiles[2]:.0f}, "
          f"90%={activity_percentiles[3]:.0f}")
    
    for i, dev in enumerate(developer_data):
        try:
            # åŸºæœ¬çš„ãªæ™‚é–“ãƒ™ãƒ¼ã‚¹ç¶™ç¶šç‡
            last_activity = datetime.fromisoformat(
                dev.get('last_activity', '').replace(' ', 'T')
            )
            days_since_last = (current_time - last_activity).days
            
            # æ™‚é–“ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
            if days_since_last <= 7:
                time_score = 1.0
            elif days_since_last <= 30:
                time_score = 0.8
            elif days_since_last <= 90:
                time_score = 0.5
            elif days_since_last <= 180:
                time_score = 0.3
            else:
                time_score = 0.1
            
            # æ´»å‹•é‡ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢ï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
            total_activity = all_activities[i]
            if total_activity >= activity_percentiles[3]:  # 90%ä»¥ä¸Š
                activity_score = 1.0
            elif total_activity >= activity_percentiles[2]:  # 75%ä»¥ä¸Š
                activity_score = 0.8
            elif total_activity >= activity_percentiles[1]:  # 50%ä»¥ä¸Š
                activity_score = 0.6
            elif total_activity >= activity_percentiles[0]:  # 25%ä»¥ä¸Š
                activity_score = 0.4
            else:
                activity_score = 0.2
            
            # ç¶™ç¶šæœŸé–“ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
            duration = all_durations[i]
            if duration >= duration_percentiles[3]:  # 90%ä»¥ä¸Š
                duration_score = 1.0
            elif duration >= duration_percentiles[2]:  # 75%ä»¥ä¸Š
                duration_score = 0.8
            elif duration >= duration_percentiles[1]:  # 50%ä»¥ä¸Š
                duration_score = 0.6
            else:
                duration_score = 0.4
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå¤šæ§˜æ€§ã‚¹ã‚³ã‚¢
            project_count = len(dev.get('projects', []))
            if project_count >= 5:
                diversity_score = 1.0
            elif project_count >= 3:
                diversity_score = 0.8
            elif project_count >= 2:
                diversity_score = 0.6
            else:
                diversity_score = 0.4
            
            # ãƒ¬ãƒ“ãƒ¥ãƒ¼å“è³ªã‚¹ã‚³ã‚¢
            review_scores = dev.get('review_scores', [])
            if review_scores:
                avg_abs_score = np.mean([abs(s) for s in review_scores])
                positive_ratio = sum(1 for s in review_scores if s > 0) / len(review_scores)
                review_quality_score = min(1.0, avg_abs_score * 0.5 + positive_ratio * 0.5)
            else:
                review_quality_score = 0.5
            
            # ç·åˆã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆé‡ã¿ä»˜ãå¹³å‡ï¼‰
            final_score = (
                time_score * 0.35 +           # æœ€è¿‘ã®æ´»å‹•ãŒæœ€é‡è¦
                activity_score * 0.25 +       # æ´»å‹•é‡
                duration_score * 0.20 +       # ç¶™ç¶šæœŸé–“
                diversity_score * 0.10 +      # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå¤šæ§˜æ€§
                review_quality_score * 0.10   # ãƒ¬ãƒ“ãƒ¥ãƒ¼å“è³ª
            )
            
            # 0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
            final_score = min(1.0, max(0.0, final_score))
            labels.append(final_score)
            
        except Exception as e:
            labels.append(0.0)  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯é›¢è„±ã¨ã¿ãªã™
    
    labels = np.array(labels)
    print(f"âœ… å¼·åŒ–ã•ã‚ŒãŸç¶™ç¶šç‡ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆå®Œäº†")
    print(f"   å¹³å‡ç¶™ç¶šç‡: {labels.mean():.3f}")
    print(f"   ç¶™ç¶šç‡åˆ†å¸ƒ: é«˜(>0.8): {(labels > 0.8).sum()}äºº, "
          f"ä¸­(0.5-0.8): {((labels >= 0.5) & (labels <= 0.8)).sum()}äºº, "
          f"ä½(<0.5): {(labels < 0.5).sum()}äºº")
    
    return labels

def run_comprehensive_improvement():
    """åŒ…æ‹¬çš„äºˆæ¸¬ç²¾åº¦æ”¹å–„ã®å®Ÿè¡Œ"""
    print("ğŸš€ åŒ…æ‹¬çš„äºˆæ¸¬ç²¾åº¦æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 80)
    print("ğŸ“‹ å®Ÿè¡Œå†…å®¹:")
    print("   1. é«˜åº¦ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š")
    print("   2. A/Bãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹æˆ¦ç•¥æ¯”è¼ƒ")
    print("   3. çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š")
    print("   4. åŒ…æ‹¬çš„ãªæ€§èƒ½åˆ†æ")
    print("=" * 80)
    
    # è¨­å®š
    config = {
        'data_path': 'data/processed/unified/all_developers.json',
        'output_path': 'outputs/comprehensive_accuracy_improvement',
        'test_size': 0.2,
        'random_state': 42,
        'n_splits': 5
    }
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    Path(config['output_path']).mkdir(parents=True, exist_ok=True)
    
    try:
        # 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        developer_data = load_developer_data(config['data_path'])
        
        # 2. å¼·åŒ–ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã®ä½œæˆ
        y_enhanced = create_enhanced_retention_labels(developer_data)
        
        # 3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡Œ
        print(f"\nğŸ¤– STEP 1: é«˜åº¦ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ")
        print("-" * 60)
        
        improver = AdvancedAccuracyImprover(config)
        
        # ç‰¹å¾´é‡ã®æŠ½å‡º
        print("ğŸ”§ é«˜åº¦ãªç‰¹å¾´é‡ã‚’æŠ½å‡ºä¸­...")
        features_list = []
        feature_names = None
        
        for i, dev in enumerate(developer_data):
            if i % 100 == 0:
                print(f"   é€²æ—: {i}/{len(developer_data)} ({i/len(developer_data)*100:.1f}%)")
            
            features = improver.extract_advanced_features(dev)
            
            if feature_names is None:
                feature_names = list(features.keys())
            
            features_list.append([features.get(name, 0.0) for name in feature_names])
        
        X = np.array(features_list)
        print(f"âœ… ç‰¹å¾´é‡æŠ½å‡ºå®Œäº†: {X.shape[1]}æ¬¡å…ƒã®ç‰¹å¾´é‡")
        
        # ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_enhanced, test_size=config['test_size'], random_state=config['random_state']
        )
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        print(f"\nğŸ¯ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´...")
        trained_models = improver.train_ensemble_models(X_train, y_train)
        
        # æ€§èƒ½è©•ä¾¡
        ensemble_performance = improver.evaluate_model_performance(X_test, y_test)
        
        print(f"\nğŸ“Š ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ€§èƒ½:")
        ensemble_r2 = ensemble_performance['ensemble']['r2']
        ensemble_rmse = ensemble_performance['ensemble']['rmse']
        print(f"   RÂ²ã‚¹ã‚³ã‚¢: {ensemble_r2:.4f}")
        print(f"   RMSE: {ensemble_rmse:.4f}")
        
        # 4. A/Bãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡Œ
        print(f"\nğŸ§ª STEP 2: A/Bãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹æˆ¦ç•¥æ¯”è¼ƒ")
        print("-" * 60)
        
        ab_system = ABTestingSystem(config)
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æˆ¦ç•¥ã®ç™»éŒ²
        baseline_strategies = ab_system.create_baseline_strategies()
        
        strategy_descriptions = {
            'activity_frequency': 'æ´»å‹•é »åº¦ãƒ™ãƒ¼ã‚¹ã®ç¶™ç¶šäºˆæ¸¬',
            'recent_activity': 'æœ€è¿‘ã®æ´»å‹•ãƒ™ãƒ¼ã‚¹ã®ç¶™ç¶šäºˆæ¸¬',
            'balanced': 'ãƒãƒ©ãƒ³ã‚¹å‹ç¶™ç¶šäºˆæ¸¬',
            'conservative': 'ä¿å®ˆçš„ç¶™ç¶šäºˆæ¸¬ï¼ˆé«˜é–¾å€¤ï¼‰',
            'aggressive': 'ç©æ¥µçš„ç¶™ç¶šäºˆæ¸¬ï¼ˆä½é–¾å€¤ï¼‰'
        }
        
        for name, func in baseline_strategies.items():
            ab_system.register_strategy(name, func, strategy_descriptions.get(name, ''))
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æˆ¦ç•¥ã®è¿½åŠ 
        def ensemble_strategy(developer_data: Dict[str, Any]) -> float:
            """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬"""
            features = improver.extract_advanced_features(developer_data)
            feature_vector = np.array([[features.get(name, 0.0) for name in feature_names]])
            
            try:
                pred, _ = improver.predict_with_ensemble(feature_vector)
                return float(pred[0])
            except:
                return 0.5
        
        ab_system.register_strategy('ensemble_ml', ensemble_strategy, 
                                  'ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ç¶™ç¶šäºˆæ¸¬')
        
        # A/Bãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        print(f"ğŸ”„ A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
        ab_results = ab_system.run_ab_test(developer_data, y_enhanced, config['n_splits'])
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
        print(f"ğŸ“ˆ çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®šã‚’å®Ÿè¡Œä¸­...")
        statistical_results = {}
        for metric in ['accuracy', 'precision', 'recall', 'f1']:
            statistical_results[metric] = ab_system.perform_statistical_tests(metric)
        
        # 5. çµæœã®çµ±åˆã¨åˆ†æ
        print(f"\nğŸ“‹ STEP 3: çµæœã®çµ±åˆã¨åˆ†æ")
        print("-" * 60)
        
        # æœ€è‰¯æˆ¦ç•¥ã®ç‰¹å®š
        f1_results = {name: results['f1']['mean'] 
                     for name, results in ab_results.items()}
        best_strategy = max(f1_results, key=f1_results.get)
        best_f1 = f1_results[best_strategy]
        
        print(f"ğŸ† æœ€è‰¯æˆ¦ç•¥: {best_strategy}")
        print(f"   F1ã‚¹ã‚³ã‚¢: {best_f1:.4f}")
        
        # æˆ¦ç•¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        print(f"\nğŸ“Š æˆ¦ç•¥ãƒ©ãƒ³ã‚­ãƒ³ã‚° (F1ã‚¹ã‚³ã‚¢):")
        sorted_strategies = sorted(f1_results.items(), key=lambda x: x[1], reverse=True)
        for i, (name, score) in enumerate(sorted_strategies, 1):
            print(f"   {i}. {name:20s}: {score:.4f}")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ¯”è¼ƒ
        if 'ensemble_ml' in f1_results:
            ensemble_f1 = f1_results['ensemble_ml']
            baseline_f1 = max(score for name, score in f1_results.items() 
                            if name != 'ensemble_ml')
            improvement = ((ensemble_f1 - baseline_f1) / baseline_f1) * 100
            
            print(f"\nğŸ¯ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ”¹å–„åŠ¹æœ:")
            print(f"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«F1: {ensemble_f1:.4f}")
            print(f"   ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æœ€é«˜F1: {baseline_f1:.4f}")
            print(f"   æ”¹å–„ç‡: {improvement:+.1f}%")
        
        # 6. åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        print(f"\nğŸ“ STEP 4: åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ")
        print("-" * 60)
        
        comprehensive_report = {
            'timestamp': datetime.now().isoformat(),
            'system_info': {
                'total_developers': len(developer_data),
                'features_count': len(feature_names),
                'test_samples': len(X_test),
                'cv_folds': config['n_splits']
            },
            'ensemble_results': {
                'performance': ensemble_performance,
                'feature_importance': improver.analyze_feature_importance(feature_names),
                'model_weights': improver.ensemble_weights
            },
            'ab_test_results': {
                'strategy_performance': ab_results,
                'statistical_tests': statistical_results,
                'best_strategy': best_strategy,
                'strategy_ranking': sorted_strategies
            },
            'improvement_analysis': {
                'baseline_performance': baseline_f1 if 'ensemble_ml' in f1_results else None,
                'ensemble_performance': ensemble_f1 if 'ensemble_ml' in f1_results else None,
                'improvement_rate': improvement if 'ensemble_ml' in f1_results else None
            },
            'recommendations': []
        }
        
        # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
        recommendations = []
        
        if ensemble_r2 > 0.8:
            recommendations.append("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ãŒå„ªç§€ãªæ€§èƒ½ã‚’é”æˆã—ã¦ã„ã¾ã™ã€‚æœ¬æ ¼é‹ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        elif ensemble_r2 > 0.6:
            recommendations.append("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ãŒè‰¯å¥½ãªæ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ãªã‚‹ç‰¹å¾´é‡è¿½åŠ ã§æ”¹å–„å¯èƒ½ã§ã™ã€‚")
        else:
            recommendations.append("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿åé›†æœŸé–“ã®å»¶é•·ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
        
        if 'ensemble_ml' in f1_results and improvement > 10:
            recommendations.append(f"æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãŒ{improvement:.1f}%ã®æ”¹å–„ã‚’é”æˆã—ã¾ã—ãŸã€‚å„ªå…ˆçš„ã«æ¡ç”¨ã—ã¦ãã ã•ã„ã€‚")
        
        if statistical_results.get('f1', {}).get('anova', {}).get('significant', False):
            recommendations.append("æˆ¦ç•¥é–“ã«çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãŒã‚ã‚Šã¾ã™ã€‚æœ€è‰¯æˆ¦ç•¥ã®æ¡ç”¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚")
        
        comprehensive_report['recommendations'] = recommendations
        
        # 7. çµæœã®ä¿å­˜
        print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ä¸­...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜ï¼ˆJSON serializable ã«å¤‰æ›ï¼‰
        def make_json_serializable(obj):
            """ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’JSON serializable ã«å¤‰æ›"""
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, (np.integer, np.int64)):
                return int(obj)
            elif isinstance(obj, (np.floating, np.float64)):
                return float(obj)
            elif isinstance(obj, np.bool_):
                return bool(obj)
            elif isinstance(obj, dict):
                return {key: make_json_serializable(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [make_json_serializable(item) for item in obj]
            elif isinstance(obj, tuple):
                return [make_json_serializable(item) for item in obj]
            else:
                return obj
        
        serializable_report = make_json_serializable(comprehensive_report)
        
        report_file = f"{config['output_path']}/comprehensive_improvement_report_{timestamp}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_report, f, ensure_ascii=False, indent=2)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        ensemble_results_file, ensemble_models_file = improver.save_improvement_results(
            comprehensive_report['ensemble_results'], config['output_path']
        )
        
        # A/Bãƒ†ã‚¹ãƒˆçµæœã®ä¿å­˜
        ab_results_file = ab_system.save_results(config['output_path'])
        
        # å¯è¦–åŒ–ã®ä½œæˆ
        visualization_file = ab_system.create_visualization(config['output_path'])
        
        # 8. æœ€çµ‚ã‚µãƒãƒªãƒ¼
        print("\n" + "=" * 80)
        print("ğŸ‰ åŒ…æ‹¬çš„äºˆæ¸¬ç²¾åº¦æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†ï¼")
        print("=" * 80)
        
        print(f"\nğŸ“Š æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼:")
        print(f"   æœ€è‰¯æˆ¦ç•¥: {best_strategy}")
        print(f"   æœ€é«˜F1ã‚¹ã‚³ã‚¢: {best_f1:.4f}")
        print(f"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«RÂ²: {ensemble_r2:.4f}")
        
        if 'ensemble_ml' in f1_results:
            print(f"   æ©Ÿæ¢°å­¦ç¿’æ”¹å–„ç‡: {improvement:+.1f}%")
        
        print(f"\nğŸ“ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«:")
        print(f"   åŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
        print(f"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµæœ: {ensemble_results_file}")
        print(f"   A/Bãƒ†ã‚¹ãƒˆçµæœ: {ab_results_file}")
        print(f"   å¯è¦–åŒ–: {visualization_file}")
        
        print(f"\nğŸ’¡ ä¸»è¦æ¨å¥¨äº‹é …:")
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. {rec}")
        
        # å‰å›ã®217.7%æ”¹å–„ã¨ã®çµ±åˆåŠ¹æœ
        print(f"\nğŸ”„ ã‚·ã‚¹ãƒ†ãƒ çµ±åˆåŠ¹æœ:")
        print(f"   å‰å›RLæ”¹å–„: +217.7%")
        print(f"   ä»Šå›ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ”¹å–„: {improvement:+.1f}% (è¿½åŠ )")
        print(f"   çµ±åˆã«ã‚ˆã‚Šæ›´ãªã‚‹ç²¾åº¦å‘ä¸ŠãŒå®Ÿç¾ã•ã‚Œã¾ã—ãŸ")
        
        return comprehensive_report
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    results = run_comprehensive_improvement()
    
    if results:
        print("\nâœ… åŒ…æ‹¬çš„äºˆæ¸¬ç²¾åº¦æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
    else:
        print("\nâŒ åŒ…æ‹¬çš„äºˆæ¸¬ç²¾åº¦æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        sys.exit(1)