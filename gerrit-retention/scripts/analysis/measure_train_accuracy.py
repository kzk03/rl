"""è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ­£è§£ç‡ã‚’æ¸¬å®š"""
import json
import sys
from pathlib import Path

import pandas as pd
import torch
from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score

sys.path.insert(0, 'scripts/training/irl')
sys.path.insert(0, 'src')

from train_irl_review_acceptance import extract_review_acceptance_trajectories

from gerrit_retention.rl_prediction.retention_irl_system import RetentionIRLSystem


def measure_train_accuracy():
    """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ­£è§£ç‡ã‚’æ¸¬å®š"""
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_csv('data/review_requests_openstack_multi_5y_detail.csv')
    df['request_time'] = pd.to_datetime(df['request_time'])
    
    cutoff = pd.Timestamp('2023-01-01')
    train_start = cutoff - pd.DateOffset(months=12)
    train_end = cutoff
    project = 'openstack/nova'
    
    periods = [
        ('0-3m', 0, 3),
        ('3-6m', 3, 6),
        ('6-9m', 6, 9),
        ('9-12m', 9, 12)
    ]
    
    print("## ğŸ“Š è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ­£è§£ç‡")
    print()
    print("| è¨“ç·´æœŸé–“ | è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•° | è¨“ç·´æ­£è§£ç‡ | è¨“ç·´AUC-ROC | è¨“ç·´AUC-PR | è©•ä¾¡æ­£è§£ç‡ | è©•ä¾¡AUC-PR | éå­¦ç¿’åº¦ |")
    print("|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|")
    
    for name, start_months, end_months in periods:
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        model_path = Path(f'outputs/review_acceptance_cross_eval_nova/train_{name}/irl_model.pt')
        if not model_path.exists():
            print(f"| {name} | - | - | - | - | - | - | - |")
            continue
        
        # Config ã‚’ä½œæˆã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ï¼ˆè¨“ç·´æ™‚ã¨åŒã˜è¨­å®šï¼‰
        config = {
            'state_dim': 9,
            'action_dim': 4,
            'hidden_dim': 128,  # è¨“ç·´æ™‚ã¨åŒã˜
            'sequence': True,
            'seq_len': 0,
            'use_temporal_features': False,
            'learning_rate': 0.001
        }
        irl = RetentionIRLSystem(config=config)
        irl.network.load_state_dict(torch.load(model_path))
        irl.network.eval()
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        train_trajectories = extract_review_acceptance_trajectories(
            df=df,
            train_start=train_start,
            train_end=train_end,
            future_window_start_months=start_months,
            future_window_end_months=end_months,
            project=project
        )
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
        train_predictions = []
        train_labels = []
        
        for traj in train_trajectories:
            result = irl.predict_continuation_probability_snapshot(
                developer=traj['developer_info'],
                activity_history=traj['activity_history'],
                context_date=train_end
            )
            # dict ã‹ã‚‰ç¢ºç‡ã‚’å–å¾—
            prob = result['continuation_probability']
            train_predictions.append(prob)
            train_labels.append(1.0 if traj['future_acceptance'] else 0.0)
        
        train_predictions = torch.tensor(train_predictions)
        train_labels = torch.tensor(train_labels)
        
        # é–¾å€¤èª­ã¿è¾¼ã¿
        metrics_file = Path(f'outputs/review_acceptance_cross_eval_nova/train_{name}/metrics.json')
        with open(metrics_file) as f:
            eval_metrics = json.load(f)
        
        threshold = eval_metrics['optimal_threshold']
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        train_pred_binary = (train_predictions >= threshold).float()
        train_accuracy = accuracy_score(train_labels, train_pred_binary)
        train_auc_roc = roc_auc_score(train_labels, train_predictions)
        train_auc_pr = average_precision_score(train_labels, train_predictions)
        
        # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        eval_accuracy = eval_metrics['precision']  # å®Ÿéš›ã¯ Precision ã‚’ä½¿ç”¨
        eval_auc_pr = eval_metrics['auc_pr']
        
        # éå­¦ç¿’åº¦ï¼ˆè¨“ç·´ã¨è©•ä¾¡ã®å·®ï¼‰
        overfit_degree = train_accuracy - eval_accuracy
        
        print(f"| {name} | {len(train_trajectories)}äºº | {train_accuracy:.3f} | {train_auc_roc:.3f} | {train_auc_pr:.3f} | {eval_accuracy:.3f} | {eval_auc_pr:.3f} | {overfit_degree:+.3f} |")
    
    print()
    print("### **éå­¦ç¿’åº¦ã®åˆ¤å®šåŸºæº–**")
    print("- **< 0.05**: é©åˆ‡ãªæ±åŒ–")
    print("- **0.05 ï½ 0.15**: è»½åº¦ã®éå­¦ç¿’")
    print("- **> 0.15**: æ·±åˆ»ãªéå­¦ç¿’")

if __name__ == '__main__':
    measure_train_accuracy()

