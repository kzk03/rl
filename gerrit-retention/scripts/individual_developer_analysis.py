#!/usr/bin/env python3
"""
å€‹åˆ¥é–‹ç™ºè€…åˆ†æã‚·ã‚¹ãƒ†ãƒ 

å„é–‹ç™ºè€…ã”ã¨ã®ç¶™ç¶šç‡äºˆæ¸¬ã€ç‰¹å¾´é‡åˆ†æã€æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’
è©³ç´°ã«è¡¨ç¤ºã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import pickle
import sys
import warnings
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from src.gerrit_retention.prediction.advanced_accuracy_improver import (
    AdvancedAccuracyImprover,
)


class IndividualDeveloperAnalyzer:
    """å€‹åˆ¥é–‹ç™ºè€…åˆ†æã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, models_path: str, data_path: str):
        self.models_path = models_path
        self.data_path = data_path
        self.developer_data = None
        self.improver = None
        self.feature_names = None
        self.predictions = {}
        self.feature_analysis = {}
        
    def load_data_and_models(self):
        """ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        with open(self.data_path, 'r', encoding='utf-8') as f:
            self.developer_data = json.load(f)
        
        # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        with open(self.models_path, 'rb') as f:
            model_data = pickle.load(f)
            
        # AdvancedAccuracyImproverã®åˆæœŸåŒ–
        config = {'output_path': 'outputs/individual_analysis'}
        self.improver = AdvancedAccuracyImprover(config)
        self.improver.models = model_data['models']
        self.improver.scalers = model_data['scalers']
        self.improver.ensemble_weights = model_data['ensemble_weights']
        self.improver.feature_importance = model_data['feature_importance']
        
        print(f"âœ… {len(self.developer_data)}äººã®é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿å®Œäº†")
        print(f"âœ… {len(self.improver.models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿å®Œäº†")
    
    def analyze_all_developers(self):
        """å…¨é–‹ç™ºè€…ã®åˆ†æ"""
        print("ğŸ” å…¨é–‹ç™ºè€…ã®åˆ†æã‚’é–‹å§‹...")
        
        for i, dev in enumerate(self.developer_data):
            if i % 100 == 0:
                print(f"   é€²æ—: {i}/{len(self.developer_data)} ({i/len(self.developer_data)*100:.1f}%)")
            
            dev_id = dev.get('developer_id', f'developer_{i}')
            analysis = self.analyze_single_developer(dev, dev_id)
            self.predictions[dev_id] = analysis
        
        print("âœ… å…¨é–‹ç™ºè€…ã®åˆ†æå®Œäº†")
    
    def analyze_single_developer(self, dev_data: Dict[str, Any], dev_id: str) -> Dict[str, Any]:
        """å˜ä¸€é–‹ç™ºè€…ã®è©³ç´°åˆ†æ"""
        # ç‰¹å¾´é‡ã®æŠ½å‡º
        features = self.improver.extract_advanced_features(dev_data)
        
        if self.feature_names is None:
            self.feature_names = list(features.keys())
        
        feature_vector = np.array([[features.get(name, 0.0) for name in self.feature_names]])
        
        # äºˆæ¸¬ã®å®Ÿè¡Œ
        try:
            prediction, uncertainty = self.improver.predict_with_ensemble(feature_vector)
            retention_score = float(prediction[0])
            confidence = 1.0 - float(uncertainty[0])
        except Exception as e:
            retention_score = 0.5
            confidence = 0.0
        
        # ç¶™ç¶šç‡ã‚«ãƒ†ã‚´ãƒªã®åˆ¤å®š
        if retention_score >= 0.8:
            category = "é«˜ç¶™ç¶šç‡"
            risk_level = "ä½ãƒªã‚¹ã‚¯"
            color = "ğŸŸ¢"
        elif retention_score >= 0.5:
            category = "ä¸­ç¶™ç¶šç‡"
            risk_level = "ä¸­ãƒªã‚¹ã‚¯"
            color = "ğŸŸ¡"
        else:
            category = "ä½ç¶™ç¶šç‡"
            risk_level = "é«˜ãƒªã‚¹ã‚¯"
            color = "ğŸ”´"
        
        # ç‰¹å¾´é‡ã®é‡è¦åº¦åˆ†æ
        feature_analysis = self._analyze_developer_features(features)
        
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ
        recommendations = self._generate_recommendations(dev_data, features, retention_score)
        
        # è©³ç´°æƒ…å ±ã®ä½œæˆ
        analysis = {
            'basic_info': {
                'developer_id': dev_id,
                'name': dev_data.get('name', 'Unknown'),
                'first_seen': dev_data.get('first_seen', ''),
                'last_activity': dev_data.get('last_activity', ''),
                'projects': dev_data.get('projects', []),
                'sources': dev_data.get('sources', [])
            },
            'prediction': {
                'retention_score': retention_score,
                'confidence': confidence,
                'category': category,
                'risk_level': risk_level,
                'color': color
            },
            'activity_stats': {
                'changes_authored': dev_data.get('changes_authored', 0),
                'changes_reviewed': dev_data.get('changes_reviewed', 0),
                'total_insertions': dev_data.get('total_insertions', 0),
                'total_deletions': dev_data.get('total_deletions', 0),
                'project_count': len(dev_data.get('projects', [])),
                'source_count': len(dev_data.get('sources', []))
            },
            'feature_analysis': feature_analysis,
            'recommendations': recommendations,
            'raw_features': features
        }
        
        return analysis
    
    def _analyze_developer_features(self, features: Dict[str, float]) -> Dict[str, Any]:
        """é–‹ç™ºè€…ã®ç‰¹å¾´é‡åˆ†æ"""
        # ç‰¹å¾´é‡ã‚’é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        if self.improver.feature_importance:
            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®é‡ã¿ä»˜ãé‡è¦åº¦ã‚’è¨ˆç®—
            weighted_importance = {}
            total_weight = 0
            
            for model_name, importance in self.improver.feature_importance.items():
                if model_name in self.improver.ensemble_weights:
                    weight = self.improver.ensemble_weights[model_name]
                    for i, feature_name in enumerate(self.feature_names):
                        if feature_name not in weighted_importance:
                            weighted_importance[feature_name] = 0
                        weighted_importance[feature_name] += importance[i] * weight
                    total_weight += weight
            
            # æ­£è¦åŒ–
            if total_weight > 0:
                for feature_name in weighted_importance:
                    weighted_importance[feature_name] /= total_weight
            
            # é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_features = sorted(
                [(name, features.get(name, 0), weighted_importance.get(name, 0)) 
                 for name in self.feature_names],
                key=lambda x: x[2], reverse=True
            )
        else:
            sorted_features = [(name, features.get(name, 0), 0) for name in self.feature_names]
        
        return {
            'top_features': sorted_features[:10],
            'all_features': sorted_features
        }
    
    def _generate_recommendations(self, dev_data: Dict[str, Any], 
                                features: Dict[str, float], 
                                retention_score: float) -> List[str]:
        """å€‹åˆ¥æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ"""
        recommendations = []
        
        # ç¶™ç¶šç‡ãƒ¬ãƒ™ãƒ«åˆ¥ã®åŸºæœ¬æ¨å¥¨
        if retention_score >= 0.8:
            recommendations.append("ğŸŒŸ å„ªç§€ãªé–‹ç™ºè€…ã§ã™ã€‚ç¾åœ¨ã®æ´»å‹•ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„")
            recommendations.append("ğŸ¯ ãƒ¡ãƒ³ã‚¿ãƒ¼ã‚„ãƒªãƒ¼ãƒ€ãƒ¼å½¹ã¸ã®æ˜‡æ ¼ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        elif retention_score >= 0.5:
            recommendations.append("âš ï¸ ç¶™ç¶šç‡ã«æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚ã‚µãƒãƒ¼ãƒˆã‚’å¼·åŒ–ã—ã¦ãã ã•ã„")
        else:
            recommendations.append("ğŸš¨ é›¢è„±ãƒªã‚¹ã‚¯ãŒé«˜ã„ã§ã™ã€‚ç·Šæ€¥ã®ä»‹å…¥ãŒå¿…è¦ã§ã™")
        
        # ç‰¹å¾´é‡ãƒ™ãƒ¼ã‚¹ã®å…·ä½“çš„æ¨å¥¨
        recent_activity_score = features.get('recent_activity_score', 0)
        if recent_activity_score < 0.3:
            recommendations.append("ğŸ“… æœ€è¿‘ã®æ´»å‹•ãŒå°‘ãªã„ã§ã™ã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®å†å‚åŠ ã‚’ä¿ƒã—ã¦ãã ã•ã„")
        
        activity_frequency = features.get('activity_frequency', 0)
        if activity_frequency < 0.1:
            recommendations.append("ğŸ“ˆ æ´»å‹•é »åº¦ãŒä½ã„ã§ã™ã€‚å®šæœŸçš„ãªã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        project_diversity = features.get('project_diversity', 0)
        if project_diversity < 2:
            recommendations.append("ğŸ”„ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™ã“ã¨ã§é–¢å¿ƒã‚’ç¶­æŒã—ã¦ãã ã•ã„")
        
        avg_review_score = features.get('avg_review_score', 0)
        if avg_review_score < 0:
            recommendations.append("ğŸ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¹ã‚³ã‚¢ãŒä½ã„ã§ã™ã€‚ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã—ã¦ãã ã•ã„")
        
        contribution_balance = features.get('contribution_balance', 0)
        if contribution_balance < 0.3:
            recommendations.append("âš–ï¸ ä½œæˆã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãƒãƒ©ãƒ³ã‚¹ã‚’æ”¹å–„ã—ã¦ãã ã•ã„")
        
        # æ´»å‹•é‡ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
        total_activity = dev_data.get('changes_authored', 0) + dev_data.get('changes_reviewed', 0)
        if total_activity < 10:
            recommendations.append("ğŸš€ æ´»å‹•é‡ã‚’å¢—ã‚„ã™ãŸã‚ã€å°ã•ãªã‚¿ã‚¹ã‚¯ã‹ã‚‰å§‹ã‚ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™")
        elif total_activity > 100:
            recommendations.append("ğŸ† é«˜ã„æ´»å‹•é‡ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚ä»–ã®é–‹ç™ºè€…ã®ãƒ¡ãƒ³ã‚¿ãƒ¼ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        return recommendations
    
    def get_developer_by_id(self, dev_id: str) -> Optional[Dict[str, Any]]:
        """IDã«ã‚ˆã‚‹é–‹ç™ºè€…æƒ…å ±ã®å–å¾—"""
        return self.predictions.get(dev_id)
    
    def get_developers_by_category(self, category: str) -> List[Dict[str, Any]]:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥é–‹ç™ºè€…ãƒªã‚¹ãƒˆã®å–å¾—"""
        return [analysis for analysis in self.predictions.values() 
                if analysis['prediction']['category'] == category]
    
    def get_top_risk_developers(self, n: int = 10) -> List[Dict[str, Any]]:
        """é«˜ãƒªã‚¹ã‚¯é–‹ç™ºè€…ãƒˆãƒƒãƒ—N"""
        sorted_devs = sorted(
            self.predictions.values(),
            key=lambda x: x['prediction']['retention_score']
        )
        return sorted_devs[:n]
    
    def get_top_performers(self, n: int = 10) -> List[Dict[str, Any]]:
        """ãƒˆãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ¼é–‹ç™ºè€…"""
        sorted_devs = sorted(
            self.predictions.values(),
            key=lambda x: x['prediction']['retention_score'],
            reverse=True
        )
        return sorted_devs[:n]
    
    def search_developers(self, query: str) -> List[Dict[str, Any]]:
        """é–‹ç™ºè€…æ¤œç´¢"""
        query = query.lower()
        results = []
        
        for analysis in self.predictions.values():
            basic_info = analysis['basic_info']
            if (query in basic_info['developer_id'].lower() or
                query in basic_info['name'].lower() or
                any(query in project.lower() for project in basic_info['projects'])):
                results.append(analysis)
        
        return results
    
    def generate_summary_report(self) -> Dict[str, Any]:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        if not self.predictions:
            return {}
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
        categories = {}
        risk_levels = {}
        total_devs = len(self.predictions)
        
        retention_scores = []
        confidence_scores = []
        
        for analysis in self.predictions.values():
            pred = analysis['prediction']
            category = pred['category']
            risk_level = pred['risk_level']
            
            categories[category] = categories.get(category, 0) + 1
            risk_levels[risk_level] = risk_levels.get(risk_level, 0) + 1
            
            retention_scores.append(pred['retention_score'])
            confidence_scores.append(pred['confidence'])
        
        # çµ±è¨ˆæƒ…å ±
        retention_stats = {
            'mean': np.mean(retention_scores),
            'std': np.std(retention_scores),
            'min': np.min(retention_scores),
            'max': np.max(retention_scores),
            'median': np.median(retention_scores)
        }
        
        confidence_stats = {
            'mean': np.mean(confidence_scores),
            'std': np.std(confidence_scores),
            'min': np.min(confidence_scores),
            'max': np.max(confidence_scores)
        }
        
        return {
            'total_developers': total_devs,
            'categories': categories,
            'risk_levels': risk_levels,
            'retention_stats': retention_stats,
            'confidence_stats': confidence_stats,
            'category_percentages': {k: (v/total_devs)*100 for k, v in categories.items()},
            'risk_percentages': {k: (v/total_devs)*100 for k, v in risk_levels.items()}
        }
    
    def display_developer_details(self, dev_id: str):
        """é–‹ç™ºè€…è©³ç´°ã®è¡¨ç¤º"""
        analysis = self.get_developer_by_id(dev_id)
        if not analysis:
            print(f"âŒ é–‹ç™ºè€… {dev_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        basic = analysis['basic_info']
        pred = analysis['prediction']
        stats = analysis['activity_stats']
        
        print(f"\n{pred['color']} é–‹ç™ºè€…è©³ç´°åˆ†æ: {basic['name']}")
        print("=" * 60)
        
        print(f"ğŸ“§ ID: {basic['developer_id']}")
        print(f"ğŸ‘¤ åå‰: {basic['name']}")
        print(f"ğŸ“… åˆå›å‚åŠ : {basic['first_seen']}")
        print(f"ğŸ•’ æœ€çµ‚æ´»å‹•: {basic['last_activity']}")
        
        print(f"\nğŸ¯ ç¶™ç¶šç‡äºˆæ¸¬:")
        print(f"   ã‚¹ã‚³ã‚¢: {pred['retention_score']:.4f} ({pred['retention_score']*100:.1f}%)")
        print(f"   ä¿¡é ¼åº¦: {pred['confidence']:.4f} ({pred['confidence']*100:.1f}%)")
        print(f"   ã‚«ãƒ†ã‚´ãƒª: {pred['category']}")
        print(f"   ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {pred['risk_level']}")
        
        print(f"\nğŸ“Š æ´»å‹•çµ±è¨ˆ:")
        print(f"   ä½œæˆã—ãŸãƒã‚§ãƒ³ã‚¸: {stats['changes_authored']:,}")
        print(f"   ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ãŸãƒã‚§ãƒ³ã‚¸: {stats['changes_reviewed']:,}")
        print(f"   ç·æŒ¿å…¥è¡Œæ•°: {stats['total_insertions']:,}")
        print(f"   ç·å‰Šé™¤è¡Œæ•°: {stats['total_deletions']:,}")
        print(f"   å‚åŠ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: {stats['project_count']}")
        print(f"   å‚åŠ ã‚½ãƒ¼ã‚¹æ•°: {stats['source_count']}")
        
        print(f"\nğŸ” é‡è¦ç‰¹å¾´é‡ãƒˆãƒƒãƒ—5:")
        for i, (name, value, importance) in enumerate(analysis['feature_analysis']['top_features'][:5], 1):
            print(f"   {i}. {name}: {value:.4f} (é‡è¦åº¦: {importance:.4f})")
        
        print(f"\nğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        for i, rec in enumerate(analysis['recommendations'], 1):
            print(f"   {i}. {rec}")
        
        print(f"\nğŸ¢ å‚åŠ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ:")
        for project in basic['projects'][:5]:  # æœ€åˆã®5ã¤ã‚’è¡¨ç¤º
            print(f"   â€¢ {project}")
        if len(basic['projects']) > 5:
            print(f"   ... ä»– {len(basic['projects']) - 5} ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” å€‹åˆ¥é–‹ç™ºè€…åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 60)
    
    # ãƒ‘ã‚¹ã®è¨­å®š
    models_path = "outputs/comprehensive_accuracy_improvement/improved_models_20250904_225449.pkl"
    data_path = "data/processed/unified/all_developers.json"
    
    # ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    analyzer = IndividualDeveloperAnalyzer(models_path, data_path)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        analyzer.load_data_and_models()
        
        # å…¨é–‹ç™ºè€…ã®åˆ†æ
        analyzer.analyze_all_developers()
        
        # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        summary = analyzer.generate_summary_report()
        
        print("\nğŸ“Š å…¨ä½“ã‚µãƒãƒªãƒ¼:")
        print("-" * 40)
        print(f"ç·é–‹ç™ºè€…æ•°: {summary['total_developers']:,}äºº")
        
        print(f"\nğŸ“ˆ ç¶™ç¶šç‡ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ:")
        for category, count in summary['categories'].items():
            percentage = summary['category_percentages'][category]
            print(f"   {category}: {count:,}äºº ({percentage:.1f}%)")
        
        print(f"\nâš ï¸ ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ:")
        for risk, count in summary['risk_levels'].items():
            percentage = summary['risk_percentages'][risk]
            print(f"   {risk}: {count:,}äºº ({percentage:.1f}%)")
        
        print(f"\nğŸ“Š ç¶™ç¶šç‡çµ±è¨ˆ:")
        stats = summary['retention_stats']
        print(f"   å¹³å‡: {stats['mean']:.4f}")
        print(f"   æ¨™æº–åå·®: {stats['std']:.4f}")
        print(f"   æœ€å°å€¤: {stats['min']:.4f}")
        print(f"   æœ€å¤§å€¤: {stats['max']:.4f}")
        print(f"   ä¸­å¤®å€¤: {stats['median']:.4f}")
        
        # é«˜ãƒªã‚¹ã‚¯é–‹ç™ºè€…ãƒˆãƒƒãƒ—5
        print(f"\nğŸš¨ é«˜ãƒªã‚¹ã‚¯é–‹ç™ºè€…ãƒˆãƒƒãƒ—5:")
        print("-" * 40)
        top_risk = analyzer.get_top_risk_developers(5)
        for i, analysis in enumerate(top_risk, 1):
            basic = analysis['basic_info']
            pred = analysis['prediction']
            print(f"{i}. {basic['name']} ({basic['developer_id']})")
            print(f"   ç¶™ç¶šç‡: {pred['retention_score']:.4f} ({pred['category']})")
        
        # ãƒˆãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ¼5
        print(f"\nğŸŒŸ ãƒˆãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ¼5:")
        print("-" * 40)
        top_performers = analyzer.get_top_performers(5)
        for i, analysis in enumerate(top_performers, 1):
            basic = analysis['basic_info']
            pred = analysis['prediction']
            print(f"{i}. {basic['name']} ({basic['developer_id']})")
            print(f"   ç¶™ç¶šç‡: {pred['retention_score']:.4f} ({pred['category']})")
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
        print(f"\nğŸ” å€‹åˆ¥é–‹ç™ºè€…è©³ç´°è¡¨ç¤º")
        print("=" * 60)
        print("é–‹ç™ºè€…IDã¾ãŸã¯åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ'quit'ã§çµ‚äº†ï¼‰:")
        
        while True:
            query = input("\næ¤œç´¢ > ").strip()
            if query.lower() in ['quit', 'exit', 'q']:
                break
            
            if not query:
                continue
            
            # æ¤œç´¢å®Ÿè¡Œ
            results = analyzer.search_developers(query)
            
            if not results:
                print(f"âŒ '{query}' ã«ä¸€è‡´ã™ã‚‹é–‹ç™ºè€…ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            
            if len(results) == 1:
                # 1äººã®å ´åˆã¯è©³ç´°è¡¨ç¤º
                analyzer.display_developer_details(results[0]['basic_info']['developer_id'])
            else:
                # è¤‡æ•°ã®å ´åˆã¯ãƒªã‚¹ãƒˆè¡¨ç¤º
                print(f"\nğŸ” æ¤œç´¢çµæœ: {len(results)}äºº")
                print("-" * 40)
                for i, analysis in enumerate(results[:10], 1):  # æœ€åˆã®10äºº
                    basic = analysis['basic_info']
                    pred = analysis['prediction']
                    print(f"{i}. {basic['name']} ({basic['developer_id']})")
                    print(f"   ç¶™ç¶šç‡: {pred['retention_score']:.4f} ({pred['category']})")
                
                if len(results) > 10:
                    print(f"... ä»– {len(results) - 10} äºº")
                
                # è©³ç´°è¡¨ç¤ºã®é¸æŠ
                try:
                    choice = input("\nè©³ç´°ã‚’è¦‹ãŸã„ç•ªå·ã‚’å…¥åŠ› (Enter ã§ã‚¹ã‚­ãƒƒãƒ—): ").strip()
                    if choice and choice.isdigit():
                        idx = int(choice) - 1
                        if 0 <= idx < min(len(results), 10):
                            analyzer.display_developer_details(results[idx]['basic_info']['developer_id'])
                except:
                    pass
        
        print("\nâœ… å€‹åˆ¥é–‹ç™ºè€…åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
        return analyzer
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    analyzer = main()