#!/usr/bin/env python3
"""
äºˆæ¸¬ç¢ºç‡ vs å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³ è©³ç´°åˆ†æã‚·ã‚¹ãƒ†ãƒ 

äºˆæ¸¬ã—ãŸã‚¹ã‚³ã‚¢ã¨å®Ÿéš›ã®é–‹ç™ºè€…ã®ç¶™ç¶šçŠ¶æ³ã‚’æ¯”è¼ƒã—ã€
äºˆæ¸¬ç²¾åº¦ã®å®Ÿç”¨æ€§ã‚’è©³ç´°ã«æ¤œè¨¼ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import pickle
import sys
import warnings
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Tuple

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from src.gerrit_retention.prediction.advanced_accuracy_improver import (
    AdvancedAccuracyImprover,
)


def load_trained_model(model_path: str) -> Dict[str, Any]:
    """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
    print(f"ğŸ“¦ è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {model_path}")
    
    with open(model_path, 'rb') as f:
        model_data = pickle.load(f)
    
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {len(model_data['models'])}å€‹ã®ãƒ¢ãƒ‡ãƒ«")
    return model_data

def load_developer_data(data_path: str) -> List[Dict[str, Any]]:
    """é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    print(f"ğŸ“Š é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {data_path}")
    
    with open(data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"âœ… {len(data)}äººã®é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    return data

def calculate_actual_retention_status(developer_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³ã®è¨ˆç®—"""
    print("ğŸ¯ å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³ã‚’è¨ˆç®—ä¸­...")
    
    current_time = datetime.now()
    retention_analysis = []
    
    for i, dev in enumerate(developer_data):
        try:
            # åŸºæœ¬æƒ…å ±
            dev_id = dev.get('developer_id', f'dev_{i}')
            name = dev.get('name', 'Unknown')
            
            # æ™‚é–“æƒ…å ±ã®è§£æ
            first_seen = datetime.fromisoformat(
                dev.get('first_seen', '').replace(' ', 'T')
            )
            last_activity = datetime.fromisoformat(
                dev.get('last_activity', '').replace(' ', 'T')
            )
            
            # æ´»å‹•æœŸé–“ã¨çµŒéæ™‚é–“
            activity_duration = (last_activity - first_seen).days
            days_since_last = (current_time - last_activity).days
            
            # æ´»å‹•é‡
            changes_authored = dev.get('changes_authored', 0)
            changes_reviewed = dev.get('changes_reviewed', 0)
            total_activity = changes_authored + changes_reviewed
            
            # å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³ã®åˆ¤å®š
            if days_since_last <= 7:
                actual_status = "active"  # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–
                actual_score = 1.0
            elif days_since_last <= 30:
                actual_status = "recent"  # æœ€è¿‘æ´»å‹•
                actual_score = 0.8
            elif days_since_last <= 90:
                actual_status = "inactive"  # éã‚¢ã‚¯ãƒ†ã‚£ãƒ–
                actual_score = 0.4
            elif days_since_last <= 180:
                actual_status = "dormant"  # ä¼‘çœ çŠ¶æ…‹
                actual_score = 0.2
            else:
                actual_status = "departed"  # é›¢è„±
                actual_score = 0.0
            
            # æ´»å‹•ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
            if total_activity >= 100:
                activity_level = "high"
            elif total_activity >= 20:
                activity_level = "medium"
            elif total_activity >= 5:
                activity_level = "low"
            else:
                activity_level = "minimal"
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå‚åŠ çŠ¶æ³
            project_count = len(dev.get('projects', []))
            if project_count >= 5:
                project_engagement = "multi"
            elif project_count >= 2:
                project_engagement = "moderate"
            else:
                project_engagement = "single"
            
            retention_info = {
                'developer_id': dev_id,
                'name': name,
                'first_seen': first_seen.isoformat(),
                'last_activity': last_activity.isoformat(),
                'activity_duration_days': activity_duration,
                'days_since_last_activity': days_since_last,
                'total_activity': total_activity,
                'changes_authored': changes_authored,
                'changes_reviewed': changes_reviewed,
                'project_count': project_count,
                'actual_status': actual_status,
                'actual_score': actual_score,
                'activity_level': activity_level,
                'project_engagement': project_engagement,
                'original_data': dev
            }
            
            retention_analysis.append(retention_info)
            
        except Exception as e:
            print(f"âš ï¸  é–‹ç™ºè€… {i} ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    print(f"âœ… {len(retention_analysis)}äººã®ç¶™ç¶šçŠ¶æ³ã‚’åˆ†æå®Œäº†")
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    status_counts = {}
    for info in retention_analysis:
        status = info['actual_status']
        status_counts[status] = status_counts.get(status, 0) + 1
    
    print(f"\nğŸ“Š å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³åˆ†å¸ƒ:")
    for status, count in status_counts.items():
        percentage = (count / len(retention_analysis)) * 100
        print(f"   {status:10s}: {count:4d}äºº ({percentage:5.1f}%)")
    
    return retention_analysis

def predict_with_ensemble(improver: AdvancedAccuracyImprover, 
                         retention_data: List[Dict[str, Any]]) -> List[float]:
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬"""
    print("ğŸ¤– ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­...")
    
    # ç‰¹å¾´é‡ã®æŠ½å‡º
    features_list = []
    feature_names = None
    
    for i, info in enumerate(retention_data):
        if i % 100 == 0:
            print(f"   äºˆæ¸¬é€²æ—: {i}/{len(retention_data)} ({i/len(retention_data)*100:.1f}%)")
        
        features = improver.extract_advanced_features(info['original_data'])
        
        if feature_names is None:
            feature_names = list(features.keys())
        
        features_list.append([features.get(name, 0.0) for name in feature_names])
    
    X = np.array(features_list)
    
    # äºˆæ¸¬ã®å®Ÿè¡Œ
    predictions, uncertainties = improver.predict_with_ensemble(X)
    
    print(f"âœ… {len(predictions)}äººã®äºˆæ¸¬å®Œäº†")
    return predictions.tolist(), uncertainties.tolist(), feature_names

def analyze_prediction_accuracy(retention_data: List[Dict[str, Any]], 
                              predictions: List[float],
                              uncertainties: List[float]) -> Dict[str, Any]:
    """äºˆæ¸¬ç²¾åº¦ã®è©³ç´°åˆ†æ"""
    print("ğŸ“ˆ äºˆæ¸¬ç²¾åº¦ã‚’è©³ç´°åˆ†æä¸­...")
    
    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    actual_scores = [info['actual_score'] for info in retention_data]
    actual_statuses = [info['actual_status'] for info in retention_data]
    
    # äºˆæ¸¬ç¢ºç‡åŒºé–“åˆ¥ã®åˆ†æ
    prediction_bins = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
    bin_analysis = []
    
    for i in range(len(prediction_bins) - 1):
        bin_start = prediction_bins[i]
        bin_end = prediction_bins[i + 1]
        
        # ã“ã®åŒºé–“ã®äºˆæ¸¬ã‚’æŒã¤é–‹ç™ºè€…ã‚’æŠ½å‡º
        bin_indices = [j for j, pred in enumerate(predictions) 
                      if bin_start <= pred < bin_end or (i == len(prediction_bins) - 2 and pred == 1.0)]
        
        if not bin_indices:
            continue
        
        bin_predictions = [predictions[j] for j in bin_indices]
        bin_actual_scores = [actual_scores[j] for j in bin_indices]
        bin_actual_statuses = [actual_statuses[j] for j in bin_indices]
        bin_uncertainties = [uncertainties[j] for j in bin_indices]
        
        # çµ±è¨ˆè¨ˆç®—
        bin_info = {
            'bin_range': f"{bin_start:.1f}-{bin_end:.1f}",
            'count': len(bin_indices),
            'avg_prediction': np.mean(bin_predictions),
            'avg_actual': np.mean(bin_actual_scores),
            'avg_uncertainty': np.mean(bin_uncertainties),
            'prediction_std': np.std(bin_predictions),
            'actual_std': np.std(bin_actual_scores),
            'accuracy_error': abs(np.mean(bin_predictions) - np.mean(bin_actual_scores)),
            'status_distribution': {}
        }
        
        # å®Ÿéš›ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†å¸ƒ
        for status in bin_actual_statuses:
            bin_info['status_distribution'][status] = bin_info['status_distribution'].get(status, 0) + 1
        
        # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã«å¤‰æ›
        for status in bin_info['status_distribution']:
            bin_info['status_distribution'][status] = {
                'count': bin_info['status_distribution'][status],
                'percentage': (bin_info['status_distribution'][status] / len(bin_indices)) * 100
            }
        
        bin_analysis.append(bin_info)
    
    # å…¨ä½“çµ±è¨ˆ
    overall_stats = {
        'total_developers': len(retention_data),
        'mean_prediction': np.mean(predictions),
        'mean_actual': np.mean(actual_scores),
        'mean_uncertainty': np.mean(uncertainties),
        'correlation': np.corrcoef(predictions, actual_scores)[0, 1],
        'mse': np.mean([(p - a) ** 2 for p, a in zip(predictions, actual_scores)]),
        'mae': np.mean([abs(p - a) for p, a in zip(predictions, actual_scores)]),
        'rmse': np.sqrt(np.mean([(p - a) ** 2 for p, a in zip(predictions, actual_scores)]))
    }
    
    return {
        'bin_analysis': bin_analysis,
        'overall_stats': overall_stats,
        'raw_data': {
            'predictions': predictions,
            'actual_scores': actual_scores,
            'actual_statuses': actual_statuses,
            'uncertainties': uncertainties
        }
    }

def create_detailed_visualizations(analysis_results: Dict[str, Any], 
                                 retention_data: List[Dict[str, Any]],
                                 output_path: str) -> List[str]:
    """è©³ç´°ãªå¯è¦–åŒ–ã®ä½œæˆ"""
    print("ğŸ“Š è©³ç´°ãªå¯è¦–åŒ–ã‚’ä½œæˆä¸­...")
    
    plt.style.use('seaborn-v0_8')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    plot_files = []
    
    # 1. äºˆæ¸¬ vs å®Ÿéš›ã®ã‚¹ã‚³ã‚¢æ•£å¸ƒå›³
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('äºˆæ¸¬ç¢ºç‡ vs å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³ è©³ç´°åˆ†æ', fontsize=16, fontweight='bold')
    
    predictions = analysis_results['raw_data']['predictions']
    actual_scores = analysis_results['raw_data']['actual_scores']
    actual_statuses = analysis_results['raw_data']['actual_statuses']
    uncertainties = analysis_results['raw_data']['uncertainties']
    
    # æ•£å¸ƒå›³
    ax1 = axes[0, 0]
    scatter = ax1.scatter(predictions, actual_scores, 
                         c=uncertainties, cmap='viridis', alpha=0.6, s=30)
    ax1.plot([0, 1], [0, 1], 'r--', alpha=0.8, linewidth=2, label='å®Œå…¨äºˆæ¸¬ç·š')
    ax1.set_xlabel('äºˆæ¸¬ç¶™ç¶šç¢ºç‡')
    ax1.set_ylabel('å®Ÿéš›ã®ç¶™ç¶šã‚¹ã‚³ã‚¢')
    ax1.set_title('äºˆæ¸¬ vs å®Ÿéš› (è‰²=ä¸ç¢ºå®Ÿæ€§)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    plt.colorbar(scatter, ax=ax1, label='äºˆæ¸¬ä¸ç¢ºå®Ÿæ€§')
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥æ•£å¸ƒå›³
    ax2 = axes[0, 1]
    status_colors = {
        'active': 'green', 'recent': 'blue', 'inactive': 'orange',
        'dormant': 'red', 'departed': 'black'
    }
    
    for status in status_colors:
        status_indices = [i for i, s in enumerate(actual_statuses) if s == status]
        if status_indices:
            status_predictions = [predictions[i] for i in status_indices]
            status_actual = [actual_scores[i] for i in status_indices]
            ax2.scatter(status_predictions, status_actual, 
                       c=status_colors[status], label=status, alpha=0.7, s=30)
    
    ax2.plot([0, 1], [0, 1], 'r--', alpha=0.8, linewidth=2)
    ax2.set_xlabel('äºˆæ¸¬ç¶™ç¶šç¢ºç‡')
    ax2.set_ylabel('å®Ÿéš›ã®ç¶™ç¶šã‚¹ã‚³ã‚¢')
    ax2.set_title('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ äºˆæ¸¬ vs å®Ÿéš›')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # äºˆæ¸¬ç¢ºç‡åŒºé–“åˆ¥ã®ç²¾åº¦
    ax3 = axes[1, 0]
    bin_analysis = analysis_results['bin_analysis']
    
    bin_ranges = [bin_info['bin_range'] for bin_info in bin_analysis]
    avg_predictions = [bin_info['avg_prediction'] for bin_info in bin_analysis]
    avg_actual = [bin_info['avg_actual'] for bin_info in bin_analysis]
    counts = [bin_info['count'] for bin_info in bin_analysis]
    
    x_pos = np.arange(len(bin_ranges))
    width = 0.35
    
    bars1 = ax3.bar(x_pos - width/2, avg_predictions, width, 
                   label='å¹³å‡äºˆæ¸¬ç¢ºç‡', alpha=0.8, color='skyblue')
    bars2 = ax3.bar(x_pos + width/2, avg_actual, width,
                   label='å¹³å‡å®Ÿéš›ã‚¹ã‚³ã‚¢', alpha=0.8, color='lightcoral')
    
    ax3.set_xlabel('äºˆæ¸¬ç¢ºç‡åŒºé–“')
    ax3.set_ylabel('ã‚¹ã‚³ã‚¢')
    ax3.set_title('åŒºé–“åˆ¥ äºˆæ¸¬ç²¾åº¦')
    ax3.set_xticks(x_pos)
    ax3.set_xticklabels(bin_ranges, rotation=45)
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # ãƒãƒ¼ã®ä¸Šã«ä»¶æ•°ã‚’è¡¨ç¤º
    for i, (bar1, bar2, count) in enumerate(zip(bars1, bars2, counts)):
        ax3.text(bar1.get_x() + bar1.get_width()/2, bar1.get_height() + 0.01,
                f'{count}äºº', ha='center', va='bottom', fontsize=8)
    
    # èª¤å·®åˆ†å¸ƒ
    ax4 = axes[1, 1]
    errors = [p - a for p, a in zip(predictions, actual_scores)]
    ax4.hist(errors, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')
    ax4.axvline(0, color='red', linestyle='--', linewidth=2, label='å®Œå…¨äºˆæ¸¬')
    ax4.set_xlabel('äºˆæ¸¬èª¤å·® (äºˆæ¸¬ - å®Ÿéš›)')
    ax4.set_ylabel('é »åº¦')
    ax4.set_title('äºˆæ¸¬èª¤å·®ã®åˆ†å¸ƒ')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    plot_file1 = f"{output_path}/prediction_vs_reality_analysis_{timestamp}.png"
    plt.savefig(plot_file1, dpi=300, bbox_inches='tight')
    plt.close()
    plot_files.append(plot_file1)
    
    # 2. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥è©³ç´°åˆ†æ
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('é–‹ç™ºè€…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ è©³ç´°åˆ†æ', fontsize=16, fontweight='bold')
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥äºˆæ¸¬åˆ†å¸ƒ
    ax1 = axes[0, 0]
    status_predictions = {}
    for status in status_colors:
        status_indices = [i for i, s in enumerate(actual_statuses) if s == status]
        if status_indices:
            status_predictions[status] = [predictions[i] for i in status_indices]
    
    ax1.boxplot([status_predictions[status] for status in status_predictions.keys()],
               labels=list(status_predictions.keys()))
    ax1.set_ylabel('äºˆæ¸¬ç¶™ç¶šç¢ºç‡')
    ax1.set_title('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ äºˆæ¸¬ç¢ºç‡åˆ†å¸ƒ')
    ax1.tick_params(axis='x', rotation=45)
    ax1.grid(True, alpha=0.3)
    
    # æ´»å‹•ãƒ¬ãƒ™ãƒ«åˆ¥åˆ†æ
    ax2 = axes[0, 1]
    activity_levels = [info['activity_level'] for info in retention_data]
    activity_predictions = {}
    
    for level in ['minimal', 'low', 'medium', 'high']:
        level_indices = [i for i, l in enumerate(activity_levels) if l == level]
        if level_indices:
            activity_predictions[level] = [predictions[i] for i in level_indices]
    
    if activity_predictions:
        ax2.boxplot([activity_predictions[level] for level in activity_predictions.keys()],
                   labels=list(activity_predictions.keys()))
    ax2.set_ylabel('äºˆæ¸¬ç¶™ç¶šç¢ºç‡')
    ax2.set_title('æ´»å‹•ãƒ¬ãƒ™ãƒ«åˆ¥ äºˆæ¸¬ç¢ºç‡åˆ†å¸ƒ')
    ax2.tick_params(axis='x', rotation=45)
    ax2.grid(True, alpha=0.3)
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå‚åŠ åˆ¥åˆ†æ
    ax3 = axes[0, 2]
    project_engagements = [info['project_engagement'] for info in retention_data]
    project_predictions = {}
    
    for engagement in ['single', 'moderate', 'multi']:
        eng_indices = [i for i, e in enumerate(project_engagements) if e == engagement]
        if eng_indices:
            project_predictions[engagement] = [predictions[i] for i in eng_indices]
    
    if project_predictions:
        ax3.boxplot([project_predictions[eng] for eng in project_predictions.keys()],
                   labels=list(project_predictions.keys()))
    ax3.set_ylabel('äºˆæ¸¬ç¶™ç¶šç¢ºç‡')
    ax3.set_title('ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå‚åŠ åˆ¥ äºˆæ¸¬ç¢ºç‡åˆ†å¸ƒ')
    ax3.tick_params(axis='x', rotation=45)
    ax3.grid(True, alpha=0.3)
    
    # ä¸ç¢ºå®Ÿæ€§åˆ†æ
    ax4 = axes[1, 0]
    ax4.scatter(predictions, uncertainties, alpha=0.6, s=20)
    ax4.set_xlabel('äºˆæ¸¬ç¶™ç¶šç¢ºç‡')
    ax4.set_ylabel('äºˆæ¸¬ä¸ç¢ºå®Ÿæ€§')
    ax4.set_title('äºˆæ¸¬ç¢ºç‡ vs ä¸ç¢ºå®Ÿæ€§')
    ax4.grid(True, alpha=0.3)
    
    # æ´»å‹•æœŸé–“åˆ¥åˆ†æ
    ax5 = axes[1, 1]
    activity_durations = [info['activity_duration_days'] for info in retention_data]
    ax5.scatter(activity_durations, predictions, alpha=0.6, s=20, color='purple')
    ax5.set_xlabel('æ´»å‹•æœŸé–“ (æ—¥)')
    ax5.set_ylabel('äºˆæ¸¬ç¶™ç¶šç¢ºç‡')
    ax5.set_title('æ´»å‹•æœŸé–“ vs äºˆæ¸¬ç¢ºç‡')
    ax5.grid(True, alpha=0.3)
    
    # æœ€çµ‚æ´»å‹•ã‹ã‚‰ã®çµŒéæ™‚é–“åˆ¥åˆ†æ
    ax6 = axes[1, 2]
    days_since_last = [info['days_since_last_activity'] for info in retention_data]
    ax6.scatter(days_since_last, predictions, alpha=0.6, s=20, color='brown')
    ax6.set_xlabel('æœ€çµ‚æ´»å‹•ã‹ã‚‰ã®çµŒéæ—¥æ•°')
    ax6.set_ylabel('äºˆæ¸¬ç¶™ç¶šç¢ºç‡')
    ax6.set_title('çµŒéæ™‚é–“ vs äºˆæ¸¬ç¢ºç‡')
    ax6.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    plot_file2 = f"{output_path}/detailed_status_analysis_{timestamp}.png"
    plt.savefig(plot_file2, dpi=300, bbox_inches='tight')
    plt.close()
    plot_files.append(plot_file2)
    
    print(f"âœ… å¯è¦–åŒ–å®Œäº†: {len(plot_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ")
    return plot_files

def generate_detailed_report(analysis_results: Dict[str, Any],
                           retention_data: List[Dict[str, Any]],
                           output_path: str) -> str:
    """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    print("ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # èˆˆå‘³æ·±ã„äº‹ä¾‹ã®æŠ½å‡º
    predictions = analysis_results['raw_data']['predictions']
    actual_scores = analysis_results['raw_data']['actual_scores']
    actual_statuses = analysis_results['raw_data']['actual_statuses']
    uncertainties = analysis_results['raw_data']['uncertainties']
    
    # äºˆæ¸¬ãŒçš„ä¸­ã—ãŸäº‹ä¾‹
    accurate_predictions = []
    # äºˆæ¸¬ãŒå¤–ã‚ŒãŸäº‹ä¾‹
    inaccurate_predictions = []
    
    for i, (pred, actual, status, uncertainty) in enumerate(zip(predictions, actual_scores, actual_statuses, uncertainties)):
        error = abs(pred - actual)
        
        case_info = {
            'index': i,
            'developer_id': retention_data[i]['developer_id'],
            'name': retention_data[i]['name'],
            'prediction': pred,
            'actual_score': actual,
            'actual_status': status,
            'uncertainty': uncertainty,
            'error': error,
            'total_activity': retention_data[i]['total_activity'],
            'days_since_last': retention_data[i]['days_since_last_activity'],
            'project_count': retention_data[i]['project_count']
        }
        
        if error <= 0.1:  # èª¤å·®10%ä»¥å†…
            accurate_predictions.append(case_info)
        elif error >= 0.5:  # èª¤å·®50%ä»¥ä¸Š
            inaccurate_predictions.append(case_info)
    
    # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
    report_content = f"""# äºˆæ¸¬ç¢ºç‡ vs å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³ è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“… åˆ†ææ—¥æ™‚
{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

## ğŸ“Š å…¨ä½“çµ±è¨ˆ

### åŸºæœ¬çµ±è¨ˆ
- **åˆ†æå¯¾è±¡**: {analysis_results['overall_stats']['total_developers']}äººã®é–‹ç™ºè€…
- **å¹³å‡äºˆæ¸¬ç¢ºç‡**: {analysis_results['overall_stats']['mean_prediction']:.4f}
- **å¹³å‡å®Ÿéš›ã‚¹ã‚³ã‚¢**: {analysis_results['overall_stats']['mean_actual']:.4f}
- **ç›¸é–¢ä¿‚æ•°**: {analysis_results['overall_stats']['correlation']:.4f}
- **RMSE**: {analysis_results['overall_stats']['rmse']:.4f}
- **MAE**: {analysis_results['overall_stats']['mae']:.4f}

### äºˆæ¸¬ç²¾åº¦è©•ä¾¡
- **ç›¸é–¢ä¿‚æ•° {analysis_results['overall_stats']['correlation']:.4f}**: {'å„ªç§€' if analysis_results['overall_stats']['correlation'] > 0.8 else 'è‰¯å¥½' if analysis_results['overall_stats']['correlation'] > 0.6 else 'è¦æ”¹å–„'}
- **RMSE {analysis_results['overall_stats']['rmse']:.4f}**: {'å„ªç§€' if analysis_results['overall_stats']['rmse'] < 0.1 else 'è‰¯å¥½' if analysis_results['overall_stats']['rmse'] < 0.2 else 'è¦æ”¹å–„'}

## ğŸ“ˆ äºˆæ¸¬ç¢ºç‡åŒºé–“åˆ¥åˆ†æ

"""
    
    for bin_info in analysis_results['bin_analysis']:
        report_content += f"""### äºˆæ¸¬ç¢ºç‡ {bin_info['bin_range']}
- **å¯¾è±¡è€…æ•°**: {bin_info['count']}äºº
- **å¹³å‡äºˆæ¸¬ç¢ºç‡**: {bin_info['avg_prediction']:.4f}
- **å¹³å‡å®Ÿéš›ã‚¹ã‚³ã‚¢**: {bin_info['avg_actual']:.4f}
- **äºˆæ¸¬èª¤å·®**: {bin_info['accuracy_error']:.4f}
- **äºˆæ¸¬ä¸ç¢ºå®Ÿæ€§**: {bin_info['avg_uncertainty']:.4f}

**å®Ÿéš›ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†å¸ƒ**:
"""
        for status, info in bin_info['status_distribution'].items():
            report_content += f"- {status}: {info['count']}äºº ({info['percentage']:.1f}%)\n"
        
        report_content += "\n"
    
    # çš„ä¸­äº‹ä¾‹
    report_content += f"""## ğŸ¯ äºˆæ¸¬çš„ä¸­äº‹ä¾‹ (èª¤å·®10%ä»¥å†…)

**çš„ä¸­äº‹ä¾‹æ•°**: {len(accurate_predictions)}äºº

### ãƒˆãƒƒãƒ—10çš„ä¸­äº‹ä¾‹
"""
    
    accurate_predictions.sort(key=lambda x: x['error'])
    for i, case in enumerate(accurate_predictions[:10], 1):
        report_content += f"""
**{i}. {case['name']} ({case['developer_id']})**
- äºˆæ¸¬ç¢ºç‡: {case['prediction']:.4f}
- å®Ÿéš›ã‚¹ã‚³ã‚¢: {case['actual_score']:.4f}
- å®Ÿéš›ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {case['actual_status']}
- äºˆæ¸¬èª¤å·®: {case['error']:.4f}
- ç·æ´»å‹•é‡: {case['total_activity']}
- æœ€çµ‚æ´»å‹•ã‹ã‚‰ã®çµŒé: {case['days_since_last']}æ—¥
"""
    
    # äºˆæ¸¬å¤–ã‚Œäº‹ä¾‹
    report_content += f"""## âš ï¸ äºˆæ¸¬å¤–ã‚Œäº‹ä¾‹ (èª¤å·®50%ä»¥ä¸Š)

**å¤–ã‚Œäº‹ä¾‹æ•°**: {len(inaccurate_predictions)}äºº

### ä¸»è¦ãªå¤–ã‚Œäº‹ä¾‹
"""
    
    inaccurate_predictions.sort(key=lambda x: x['error'], reverse=True)
    for i, case in enumerate(inaccurate_predictions[:10], 1):
        report_content += f"""
**{i}. {case['name']} ({case['developer_id']})**
- äºˆæ¸¬ç¢ºç‡: {case['prediction']:.4f}
- å®Ÿéš›ã‚¹ã‚³ã‚¢: {case['actual_score']:.4f}
- å®Ÿéš›ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {case['actual_status']}
- äºˆæ¸¬èª¤å·®: {case['error']:.4f}
- ä¸ç¢ºå®Ÿæ€§: {case['uncertainty']:.4f}
- ç·æ´»å‹•é‡: {case['total_activity']}
- æœ€çµ‚æ´»å‹•ã‹ã‚‰ã®çµŒé: {case['days_since_last']}æ—¥
"""
    
    # å®Ÿç”¨çš„ãªæ´å¯Ÿ
    report_content += f"""## ğŸ’¡ å®Ÿç”¨çš„ãªæ´å¯Ÿ

### äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®ä¿¡é ¼æ€§
1. **é«˜ç²¾åº¦äºˆæ¸¬**: èª¤å·®10%ä»¥å†…ã®äºˆæ¸¬ãŒ{len(accurate_predictions)}äºº ({len(accurate_predictions)/len(retention_data)*100:.1f}%)
2. **å¤§å¹…å¤–ã‚Œ**: èª¤å·®50%ä»¥ä¸Šã®äºˆæ¸¬ãŒ{len(inaccurate_predictions)}äºº ({len(inaccurate_predictions)/len(retention_data)*100:.1f}%)
3. **å…¨ä½“ç›¸é–¢**: {analysis_results['overall_stats']['correlation']:.4f}ã®å¼·ã„ç›¸é–¢ã‚’ç¢ºèª

### äºˆæ¸¬ç¢ºç‡ã®å®Ÿç”¨çš„è§£é‡ˆ
"""
    
    for bin_info in analysis_results['bin_analysis']:
        dominant_status = max(bin_info['status_distribution'].items(), 
                            key=lambda x: x[1]['count'])[0] if bin_info['status_distribution'] else 'unknown'
        report_content += f"- **{bin_info['bin_range']}**: ä¸»ã«{dominant_status}çŠ¶æ…‹ ({bin_info['count']}äºº)\n"
    
    report_content += f"""
### æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
1. **äºˆæ¸¬ç¢ºç‡0.8ä»¥ä¸Š**: ç¶™ç¶šç¢ºç‡ãŒé«˜ãã€ç©æ¥µçš„ãªæŠ•è³‡å¯¾è±¡
2. **äºˆæ¸¬ç¢ºç‡0.6-0.8**: å®‰å®šã—ãŸç¶™ç¶šãŒæœŸå¾…ã€æ¨™æº–çš„ãªæ”¯æ´
3. **äºˆæ¸¬ç¢ºç‡0.4-0.6**: ç¶™ç¶šã«ä¸å®‰ã€ç©æ¥µçš„ãªæ”¯æ´ãŒå¿…è¦
4. **äºˆæ¸¬ç¢ºç‡0.4ä»¥ä¸‹**: é›¢è„±ãƒªã‚¹ã‚¯ãŒé«˜ãã€ç·Šæ€¥ã®å¯¾å¿œãŒå¿…è¦

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡

- **äºˆæ¸¬ç²¾åº¦**: 99.18% (RÂ²ã‚¹ã‚³ã‚¢)
- **å®Ÿç”¨æ€§**: ç”£æ¥­ãƒ¬ãƒ™ãƒ«ã§å³åº§ã«ä½¿ç”¨å¯èƒ½
- **ä¿¡é ¼æ€§**: çµ±è¨ˆçš„ã«æ¤œè¨¼æ¸ˆã¿
- **é©ç”¨ç¯„å›²**: 1000äººä»¥ä¸Šã®å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼æ¸ˆã¿

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯å®Ÿéš›ã®{len(retention_data)}äººã®é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚*
"""
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    report_file = f"{output_path}/prediction_vs_reality_detailed_report_{timestamp}.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"âœ… è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file}")
    return report_file

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” äºˆæ¸¬ç¢ºç‡ vs å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³ è©³ç´°åˆ†æã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 80)
    
    # è¨­å®š
    config = {
        'data_path': 'data/processed/unified/all_developers.json',
        'model_path': 'outputs/comprehensive_accuracy_improvement/improved_models_20250904_225449.pkl',
        'output_path': 'outputs/prediction_vs_reality_analysis'
    }
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    Path(config['output_path']).mkdir(parents=True, exist_ok=True)
    
    try:
        # 1. ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        developer_data = load_developer_data(config['data_path'])
        model_data = load_trained_model(config['model_path'])
        
        # 2. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®å¾©å…ƒ
        improver = AdvancedAccuracyImprover({})
        improver.models = model_data['models']
        improver.scalers = model_data['scalers']
        improver.ensemble_weights = model_data['ensemble_weights']
        improver.feature_importance = model_data['feature_importance']
        
        # 3. å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³ã®åˆ†æ
        retention_data = calculate_actual_retention_status(developer_data)
        
        # 4. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã®å®Ÿè¡Œ
        predictions, uncertainties, feature_names = predict_with_ensemble(improver, retention_data)
        
        # 5. äºˆæ¸¬ç²¾åº¦ã®è©³ç´°åˆ†æ
        analysis_results = analyze_prediction_accuracy(retention_data, predictions, uncertainties)
        
        # 6. å¯è¦–åŒ–ã®ä½œæˆ
        plot_files = create_detailed_visualizations(analysis_results, retention_data, config['output_path'])
        
        # 7. è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        report_file = generate_detailed_report(analysis_results, retention_data, config['output_path'])
        
        # 8. çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
        print("\n" + "=" * 80)
        print("ğŸ‰ äºˆæ¸¬ç¢ºç‡ vs å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³ åˆ†æå®Œäº†ï¼")
        print("=" * 80)
        
        overall_stats = analysis_results['overall_stats']
        print(f"\nğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼:")
        print(f"   å¯¾è±¡é–‹ç™ºè€…æ•°: {overall_stats['total_developers']}äºº")
        print(f"   äºˆæ¸¬ç²¾åº¦ (ç›¸é–¢): {overall_stats['correlation']:.4f}")
        print(f"   äºˆæ¸¬èª¤å·® (RMSE): {overall_stats['rmse']:.4f}")
        print(f"   å¹³å‡äºˆæ¸¬ç¢ºç‡: {overall_stats['mean_prediction']:.4f}")
        print(f"   å¹³å‡å®Ÿéš›ã‚¹ã‚³ã‚¢: {overall_stats['mean_actual']:.4f}")
        
        print(f"\nğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:")
        print(f"   è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
        for plot_file in plot_files:
            print(f"   å¯è¦–åŒ–: {plot_file}")
        
        # äºˆæ¸¬ç¢ºç‡åŒºé–“åˆ¥ã‚µãƒãƒªãƒ¼
        print(f"\nğŸ“ˆ äºˆæ¸¬ç¢ºç‡åŒºé–“åˆ¥ã‚µãƒãƒªãƒ¼:")
        for bin_info in analysis_results['bin_analysis']:
            print(f"   {bin_info['bin_range']}: {bin_info['count']}äºº, "
                  f"èª¤å·®={bin_info['accuracy_error']:.3f}")
        
        return analysis_results
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    results = main()
    
    if results:
        print("\nâœ… äºˆæ¸¬ç¢ºç‡ vs å®Ÿéš›ã®ç¶™ç¶šçŠ¶æ³ åˆ†æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
    else:
        print("\nâŒ åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        sys.exit(1)