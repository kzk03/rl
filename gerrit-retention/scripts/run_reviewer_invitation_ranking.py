#!/usr/bin/env python3
"""Run reviewer invitation ranking evaluation.

Generates Cartesian (change x reviewer) candidates with negative sampling and trains a
logistic ranking baseline.

Example:
  uv run python scripts/run_reviewer_invitation_ranking.py \
    --changes data/processed/unified/all_reviews.json \
    --min-total-reviews 20 --max-neg-per-pos 5
"""
from __future__ import annotations

import argparse
import json
from math import exp
from pathlib import Path

import numpy as np

from gerrit_retention.recommendation.reviewer_invitation_ranking import (
    InvitationRankingBuildConfig,
    build_invitation_ranking_samples,
    evaluate_invitation_ranking,
)


def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument('--changes', default='data/processed/unified/all_reviews.json')
    ap.add_argument('--min-total-reviews', type=int, default=20)
    ap.add_argument('--recent-days', type=int, default=30)
    ap.add_argument('--max-neg-per-pos', type=int, default=5)
    ap.add_argument('--hard-fraction', type=float, default=0.5)
    ap.add_argument('--idf-mode', choices=['global', 'recent'], default='global', help='IDF window: global over all changes or recent sliding window')
    ap.add_argument('--idf-recent-days', type=int, default=90, help='Window size (days) when --idf-mode=recent')
    ap.add_argument('--output', default='outputs/reviewer_invitation_ranking')
    return ap.parse_args()


def main():
    args = parse_args()
    changes_path = Path(args.changes)
    if not changes_path.exists():
        print(f'‚ùå changes file not found: {changes_path}')
        return 1
    out_dir = Path(args.output)
    out_dir.mkdir(parents=True, exist_ok=True)
    cfg = InvitationRankingBuildConfig(
        min_total_reviews=args.min_total_reviews,
        recent_days=args.recent_days,
        max_neg_per_pos=args.max_neg_per_pos,
        hard_fraction=args.hard_fraction,
    idf_mode=args.idf_mode,
    idf_recent_days=args.idf_recent_days,
    )
    print(f'üì• building ranking samples from {changes_path}')
    samples = build_invitation_ranking_samples(changes_path, cfg)
    print(f'‚úÖ built samples: {len(samples)} (pos rate ~ {sum(s["label"] for s in samples)/max(1,len(samples)):.3f})')
    if len(samples) < 50:
        print('‚ö†Ô∏è insufficient samples (<50)')
        return 1
    metrics, model, test, probs = evaluate_invitation_ranking(samples)
    print('üìä Metrics:')
    for k, v in metrics.items():
        print(f'  {k}: {v}')
    # Save outputs
    (out_dir / 'metrics.json').write_text(json.dumps(metrics, indent=2), encoding='utf-8')
    detail = []
    for s, p in zip(test, probs):
        st = s['state'].copy()
        st.update({'label': s['label'], 'prob': float(p), 'ts': s['ts']})
        detail.append(st)
    (out_dir / 'test_predictions.json').write_text(json.dumps(detail[:1000], indent=2), encoding='utf-8')

    # --- Export model weights for IRL-style preference interpretation ---
    weight_payload = {}
    try:
        if model.model is not None:
            coef = model.model.coef_[0].tolist()
            intercept = float(model.model.intercept_[0])
            features = model.features
            scaler_stats = None
            if model.scaler is not None:
                scaler_stats = {
                    'mean': model.scaler.mean_.tolist(),
                    'scale': model.scaler.scale_.tolist(),
                }
            # Odds ratio for +1 std (since coefficients are over standardized features)
            odds_ratio = [float(np.exp(c)) for c in coef]
            # Relative importance (normalized abs weight)
            abs_sum = sum(abs(c) for c in coef) or 1.0
            rel_importance = [float(abs(c) / abs_sum) for c in coef]
            weight_rows = []
            for f, c, or_, ri in zip(features, coef, odds_ratio, rel_importance):
                weight_rows.append({
                    'feature': f,
                    'coef_std': c,
                    'odds_ratio(+1SD)': or_,
                    'rel_importance': ri,
                })
            weight_payload = {
                'intercept_std': intercept,
                'weights': weight_rows,
                'scaler': scaler_stats,
                'notes': 'coef_std „ÅØ StandardScaler ÈÅ©Áî®ÂæåÁâπÂæ¥„Å´ÂØæ„Åô„Çã‰øÇÊï∞„ÄÇodds_ratio „ÅØ 1 Ê®ôÊ∫ñÂÅèÂ∑ÆÂ¢óÂä†ÊôÇ„ÅÆ„Ç™„ÉÉ„Ç∫ÂÄçÁéá (‰ªñÊù°‰ª∂‰∏ÄÂÆö)„ÄÇ'
            }
            (out_dir / 'weights.json').write_text(json.dumps(weight_payload, indent=2, ensure_ascii=False), encoding='utf-8')
            print('üßÆ exported weights.json for preference analysis')

            # --- Also export a human-friendly CSV with Japanese labels ---
            try:
                jp_labels = {
                    'reviewer_total_reviews': 'Á¥ØÁ©ç„É¨„Éì„É•„ÉºÂèÇÂä†Êï∞',
                    'reviewer_recent_reviews_30d': 'ÈÅéÂéª30Êó•„É¨„Éì„É•„ÉºÂèÇÂä†Êï∞',
                    'reviewer_gap_days': 'ÊúÄÁµÇÂèÇÂä†„Åã„Çâ„ÅÆÁµåÈÅéÊó•Êï∞',
                    'match_off_specialty_flag': 'Â∞ÇÈñÄÂ§ñ„Éï„É©„Ç∞(ÈÅéÂéª30Êó•Âêå‰∏Ä„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÁµåÈ®ìÁÑ°)',
                    'off_specialty_recent_ratio': 'Â∞ÇÈñÄÂ§ñÊØîÁéá(=1-Âêå‰∏Ä„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊØîÁéá)',
                    'reviewer_recent_reviews_7d': 'ÈÅéÂéª7Êó•„É¨„Éì„É•„ÉºÂèÇÂä†Êï∞',
                    'reviewer_proj_share_30d': 'ÈÅéÂéª30Êó•Âêå‰∏Ä„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊØîÁéá',
                    'reviewer_active_flag_30d': 'ÈÅéÂéª30Êó•Ê¥ªÂãï„Éï„É©„Ç∞',
                    'reviewer_proj_prev_reviews_30d': 'ÈÅéÂéª30Êó•Âêå‰∏Ä„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂèÇÂä†Êï∞',
                    'macro_bus_factor_top5_share': '‰∏ä‰Ωç5‰∫∫30Êó•„Ç∑„Çß„Ç¢',
                    'reviewer_file_jaccard_30d': 'ÈÅéÂéª30Êó•„Éï„Ç°„Ç§„É´„Éë„ÇπÈ°û‰ººÂ∫¶(Jaccard)',
                    'reviewer_file_tfidf_cosine_30d': 'ÈÅéÂéª30Êó•„Éï„Ç°„Ç§„É´„Éà„Éº„ÇØ„É≥TF-IDF„Ç≥„Çµ„Ç§„É≥',
                    'reviewer_pending_reviews': 'Êú™„ÇØ„É≠„Éº„Ç∫„É¨„Éì„É•„ÉºÊï∞',
                    'reviewer_workload_deviation_z': 'Ê¥ªÂãïÈáèZ„Çπ„Ç≥„Ç¢',
                    'change_current_invited_cnt': 'Â§âÊõ¥„Åß„ÅÆÊãõÂæÖ‰∫∫Êï∞',
                    'reviewer_night_activity_share_30d': 'ÈÅéÂéª30Êó•Â§úÈñìÊ¥ªÂãïÊØîÁéá',
                    'reviewer_overload_flag': 'ÈÅéË≤†Ëç∑„Éï„É©„Ç∞(Âπ≥Âùá+œÉ‰ª•‰∏ä)',
                    'change_prev_positive_cnt': 'Â§âÊõ¥ÊôÇÁÇπ„Åæ„Åß„ÅÆÊó¢ÂèÇÂä†‰∫∫Êï∞(„Éó„É¨„Éº„Çπ„Éõ„É´„ÉÄ)',
                    '_intercept': '„Éô„Éº„Çπ„É©„Ç§„É≥ÂàáÁâá',
                }

                # Build rows (excluding intercept for now)
                csv_lines = []
                header = ['feature', 'japanese_name', 'coef_std', 'abs', 'odds_ratio_plus1SD', 'rel_importance']
                csv_lines.append(','.join(header))
                for f, c, or_, ri in zip(features, coef, odds_ratio, rel_importance):
                    jp = jp_labels.get(f, f)
                    row = [
                        f,
                        jp,
                        f"{c}",
                        f"{abs(c)}",
                        f"{or_}",
                        f"{ri}",
                    ]
                    csv_lines.append(','.join(str(x) for x in row))

                # Append intercept row at the end
                inter_row = [
                    '_intercept',
                    jp_labels.get('_intercept', '_intercept'),
                    f"{intercept}",
                    f"{abs(intercept)}",
                    'NA',
                    'NA',
                ]
                csv_lines.append(','.join(str(x) for x in inter_row))

                (out_dir / 'weights_summary.csv').write_text('\n'.join(csv_lines), encoding='utf-8')
                print('üìÑ exported weights_summary.csv')
            except Exception as e:
                print(f'‚ö†Ô∏è weights_summary.csv export failed: {e}')
            # --- Reward analysis (inverse RL style decomposition) ---
            try:
                inter = intercept
                def sigmoid(z):
                    return 1.0 / (1.0 + exp(-z))
                base_prob = sigmoid(inter)
                analysis_rows = []
                means = weight_payload['scaler']['mean'] if scaler_stats else [0.0]*len(features)
                stds = weight_payload['scaler']['scale'] if scaler_stats else [1.0]*len(features)
                for i, (f, c, m, sd) in enumerate(zip(features, coef, means, stds)):
                    if sd == 0:
                        orig_coef = 0.0
                        delta_prob_1raw = 0.0
                    else:
                        orig_coef = c / sd  # coefficient in original raw units (per +1 raw unit)
                        delta_prob_1raw = sigmoid(inter + c * (1.0 / sd)) - base_prob
                    delta_prob_1sd = sigmoid(inter + c) - base_prob
                    analysis_rows.append({
                        'feature': f,
                        'coef_std': c,
                        'coef_per_raw_unit': orig_coef,
                        'odds_ratio(+1SD)': float(np.exp(c)),
                        'delta_prob(+1SD)': delta_prob_1sd,
                        'delta_prob(+1_raw_unit)': delta_prob_1raw,
                        'mean_raw': m,
                        'std_raw': sd,
                    })
                reward_analysis = {
                    'baseline_logit': inter,
                    'baseline_prob': base_prob,
                    'features': analysis_rows,
                    'notes': 'delta_prob „ÅØ‰ªñÁâπÂæ¥„ÇíÂπ≥Âùá(Ê®ôÊ∫ñÂåñÂæå0)„Å´Âõ∫ÂÆö„Åó„ÅüÊù°‰ª∂‰ªò„ÅçËøë‰ººÂΩ±Èüø„ÄÇÂÖ±Á∑öÊÄß„Å´„Çà„ÇäÁúü„ÅÆÈôêÁïåÂäπÊûú„Å®„ÅØÁï∞„Å™„ÇãÂèØËÉΩÊÄß„ÅÇ„Çä„ÄÇcoef_per_raw_unit „ÅØÊú™Ê®ôÊ∫ñÂåñÁ©∫Èñì„Åß„ÅÆ log-odds Â§âÂåñ„ÄÇ'
                }
                (out_dir / 'reward_analysis.json').write_text(json.dumps(reward_analysis, indent=2, ensure_ascii=False), encoding='utf-8')
                print('üßæ exported reward_analysis.json')
            except Exception as e:  # nested
                print(f'‚ö†Ô∏è reward analysis export failed: {e}')
    except Exception as e:
        print(f'‚ö†Ô∏è weight export failed: {e}')
    print(f'üíæ wrote outputs to {out_dir}')
    return 0


if __name__ == '__main__':
    raise SystemExit(main())
