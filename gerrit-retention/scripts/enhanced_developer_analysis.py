#!/usr/bin/env python3
"""
å¼·åŒ–ã•ã‚ŒãŸé–‹ç™ºè€…åˆ†æã‚·ã‚¹ãƒ†ãƒ 

ä½œæ¥­è² è·ã€å°‚é–€æ€§ä¸€è‡´ç‡ã€ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯ã‚’è€ƒæ…®ã—ãŸ
åŒ…æ‹¬çš„ãªé–‹ç™ºè€…ç¶™ç¶šç‡äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import sys
import warnings
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from src.gerrit_retention.prediction.advanced_accuracy_improver import (
    AdvancedAccuracyImprover,
)
from src.gerrit_retention.prediction.workload_expertise_analyzer import (
    WorkloadExpertiseAnalyzer,
)


class EnhancedDeveloperAnalyzer:
    """å¼·åŒ–ã•ã‚ŒãŸé–‹ç™ºè€…åˆ†æã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, data_path: str):
        self.data_path = data_path
        self.developer_data = None
        self.workload_analyzer = None
        self.accuracy_improver = None
        self.enhanced_predictions = {}
        
    def load_data_and_initialize(self):
        """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        with open(self.data_path, 'r', encoding='utf-8') as f:
            self.developer_data = json.load(f)
        
        # åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        config = {'output_path': 'outputs/enhanced_analysis'}
        self.workload_analyzer = WorkloadExpertiseAnalyzer(config)
        self.accuracy_improver = AdvancedAccuracyImprover(config)
        
        print(f"âœ… {len(self.developer_data)}äººã®é–‹ç™ºè€…ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿å®Œäº†")
    
    def analyze_all_developers_enhanced(self):
        """å…¨é–‹ç™ºè€…ã®å¼·åŒ–åˆ†æ"""
        print("ğŸ” å¼·åŒ–ã•ã‚ŒãŸå…¨é–‹ç™ºè€…åˆ†æã‚’é–‹å§‹...")
        
        for i, dev in enumerate(self.developer_data):
            if i % 100 == 0:
                print(f"   é€²æ—: {i}/{len(self.developer_data)} ({i/len(self.developer_data)*100:.1f}%)")
            
            dev_id = dev.get('developer_id', f'developer_{i}')
            enhanced_analysis = self.analyze_single_developer_enhanced(dev, dev_id)
            self.enhanced_predictions[dev_id] = enhanced_analysis
        
        print("âœ… å¼·åŒ–ã•ã‚ŒãŸå…¨é–‹ç™ºè€…åˆ†æå®Œäº†")
    
    def analyze_single_developer_enhanced(self, dev_data: Dict[str, Any], dev_id: str) -> Dict[str, Any]:
        """å˜ä¸€é–‹ç™ºè€…ã®å¼·åŒ–åˆ†æ"""
        # åŸºæœ¬çš„ãªç¶™ç¶šç‡äºˆæ¸¬
        base_features = self.accuracy_improver.extract_advanced_features(dev_data)
        
        # ä½œæ¥­è² è·ãƒ»å°‚é–€æ€§ãƒ»ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆåˆ†æ
        comprehensive_analysis = self.workload_analyzer.generate_comprehensive_analysis(dev_data)
        
        # çµ±åˆã‚¹ã‚³ã‚¢ã®è¨ˆç®—
        wellness_scores = comprehensive_analysis['wellness_scores']
        
        # ç¶™ç¶šç‡äºˆæ¸¬ã®èª¿æ•´ï¼ˆä½œæ¥­è² è·ã¨å°‚é–€æ€§ã‚’è€ƒæ…®ï¼‰
        base_retention_score = self._calculate_base_retention_score(dev_data)
        
        # ä½œæ¥­è² è·ã«ã‚ˆã‚‹èª¿æ•´
        workload_adjustment = (wellness_scores['workload_score'] - 0.5) * 0.2
        
        # å°‚é–€æ€§ã«ã‚ˆã‚‹èª¿æ•´
        expertise_adjustment = (wellness_scores['expertise_score'] - 0.5) * 0.15
        
        # ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯ã«ã‚ˆã‚‹èª¿æ•´
        burnout_adjustment = -(1.0 - wellness_scores['burnout_score']) * 0.25
        
        # èª¿æ•´å¾Œã®ç¶™ç¶šç‡ã‚¹ã‚³ã‚¢
        adjusted_retention_score = base_retention_score + workload_adjustment + expertise_adjustment + burnout_adjustment
        adjusted_retention_score = max(0.0, min(1.0, adjusted_retention_score))
        
        # ã‚«ãƒ†ã‚´ãƒªã¨ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®å†è¨ˆç®—
        if adjusted_retention_score >= 0.8:
            category = "é«˜ç¶™ç¶šç‡"
            risk_level = "ä½ãƒªã‚¹ã‚¯"
            color = "ğŸŸ¢"
        elif adjusted_retention_score >= 0.5:
            category = "ä¸­ç¶™ç¶šç‡"
            risk_level = "ä¸­ãƒªã‚¹ã‚¯"
            color = "ğŸŸ¡"
        else:
            category = "ä½ç¶™ç¶šç‡"
            risk_level = "é«˜ãƒªã‚¹ã‚¯"
            color = "ğŸ”´"
        
        # ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯ã«ã‚ˆã‚‹è¿½åŠ åˆ†é¡
        burnout_level = comprehensive_analysis['burnout_risk']['burnout_level']
        if burnout_level in ['critical', 'high']:
            risk_level = "ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯"
            color = "ğŸ”¥"
        
        # åŒ…æ‹¬çš„ãªæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ
        comprehensive_recommendations = self._generate_comprehensive_recommendations(
            dev_data, comprehensive_analysis, adjusted_retention_score
        )
        
        return {
            'basic_info': {
                'developer_id': dev_id,
                'name': dev_data.get('name', 'Unknown'),
                'first_seen': dev_data.get('first_seen', ''),
                'last_activity': dev_data.get('last_activity', ''),
                'projects': dev_data.get('projects', []),
                'sources': dev_data.get('sources', [])
            },
            'enhanced_prediction': {
                'base_retention_score': base_retention_score,
                'adjusted_retention_score': adjusted_retention_score,
                'workload_adjustment': workload_adjustment,
                'expertise_adjustment': expertise_adjustment,
                'burnout_adjustment': burnout_adjustment,
                'category': category,
                'risk_level': risk_level,
                'color': color
            },
            'workload_analysis': comprehensive_analysis['workload_analysis'],
            'expertise_analysis': comprehensive_analysis['expertise_analysis'],
            'burnout_risk': comprehensive_analysis['burnout_risk'],
            'wellness_scores': wellness_scores,
            'comprehensive_recommendations': comprehensive_recommendations,
            'activity_stats': {
                'changes_authored': dev_data.get('changes_authored', 0),
                'changes_reviewed': dev_data.get('changes_reviewed', 0),
                'total_insertions': dev_data.get('total_insertions', 0),
                'total_deletions': dev_data.get('total_deletions', 0),
                'project_count': len(dev_data.get('projects', [])),
                'source_count': len(dev_data.get('sources', []))
            }
        }
    
    def _calculate_base_retention_score(self, dev_data: Dict[str, Any]) -> float:
        """åŸºæœ¬ç¶™ç¶šç‡ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
        try:
            current_time = datetime.now()
            last_activity = datetime.fromisoformat(
                dev_data.get('last_activity', '').replace(' ', 'T')
            )
            days_since_last = (current_time - last_activity).days
            
            # æ™‚é–“ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
            if days_since_last <= 7:
                time_score = 1.0
            elif days_since_last <= 30:
                time_score = 0.8
            elif days_since_last <= 90:
                time_score = 0.5
            elif days_since_last <= 180:
                time_score = 0.3
            else:
                time_score = 0.1
            
            # æ´»å‹•é‡ã‚¹ã‚³ã‚¢
            total_activity = dev_data.get('changes_authored', 0) + dev_data.get('changes_reviewed', 0)
            if total_activity >= 100:
                activity_score = 1.0
            elif total_activity >= 50:
                activity_score = 0.8
            elif total_activity >= 20:
                activity_score = 0.6
            elif total_activity >= 5:
                activity_score = 0.4
            else:
                activity_score = 0.2
            
            # çµ±åˆã‚¹ã‚³ã‚¢
            base_score = time_score * 0.6 + activity_score * 0.4
            return base_score
            
        except:
            return 0.3
    
    def _generate_comprehensive_recommendations(self, dev_data: Dict[str, Any],
                                             comprehensive_analysis: Dict[str, Any],
                                             retention_score: float) -> List[str]:
        """åŒ…æ‹¬çš„ãªæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ"""
        recommendations = []
        
        # åŸºæœ¬çš„ãªæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        workload_recs = comprehensive_analysis['recommendations']
        recommendations.extend(workload_recs)
        
        # ç¶™ç¶šç‡ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹ã®è¿½åŠ æ¨å¥¨
        if retention_score >= 0.8:
            recommendations.append("ğŸŒŸ ç·åˆçš„ã«å„ªç§€ãªé–‹ç™ºè€…ã§ã™ã€‚ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—æ©Ÿä¼šã‚’æä¾›ã—ã¦ãã ã•ã„")
        elif retention_score >= 0.5:
            recommendations.append("ğŸ“ˆ ç¶™ç¶šç‡å‘ä¸Šã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚å€‹åˆ¥ã‚µãƒãƒ¼ãƒˆã‚’å¼·åŒ–ã—ã¦ãã ã•ã„")
        else:
            recommendations.append("ğŸš¨ ç¶™ç¶šç‡ãŒä½ã„ã§ã™ã€‚åŒ…æ‹¬çš„ãªæ”¯æ´ç­–ãŒå¿…è¦ã§ã™")
        
        # ä½œæ¥­è² è·èª¿æ•´ã®æ¨å¥¨
        workload_stress = comprehensive_analysis['workload_analysis'].get('workload_stress', 0.0)
        if workload_stress > 0.5:
            recommendations.append("âš–ï¸ ä½œæ¥­è² è·ã®å†é…åˆ†ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        # å°‚é–€æ€§ãƒãƒƒãƒãƒ³ã‚°ã®æ¨å¥¨
        expertise_match = comprehensive_analysis['expertise_analysis'].get('expertise_match_score', 0.0)
        if expertise_match < 0.5:
            recommendations.append("ğŸ¯ ã‚¹ã‚­ãƒ«ãƒãƒƒãƒãƒ³ã‚°ã®æ”¹å–„ãŒå¿…è¦ã§ã™")
        
        # ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆäºˆé˜²ã®æ¨å¥¨
        burnout_level = comprehensive_analysis['burnout_risk']['burnout_level']
        if burnout_level in ['high', 'critical']:
            recommendations.append("ğŸ›¡ï¸ ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆäºˆé˜²ç­–ã®å³åº§ã®å®Ÿæ–½ãŒå¿…è¦ã§ã™")
        
        return recommendations
    
    def display_enhanced_developer_details(self, dev_id: str):
        """å¼·åŒ–ã•ã‚ŒãŸé–‹ç™ºè€…è©³ç´°ã®è¡¨ç¤º"""
        analysis = self.enhanced_predictions.get(dev_id)
        if not analysis:
            print(f"âŒ é–‹ç™ºè€… {dev_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        basic = analysis['basic_info']
        pred = analysis['enhanced_prediction']
        workload = analysis['workload_analysis']
        expertise = analysis['expertise_analysis']
        burnout = analysis['burnout_risk']
        wellness = analysis['wellness_scores']
        stats = analysis['activity_stats']
        
        print(f"\n{pred['color']} å¼·åŒ–ã•ã‚ŒãŸé–‹ç™ºè€…åˆ†æ: {basic['name']}")
        print("=" * 80)
        
        print(f"ğŸ“§ ID: {basic['developer_id']}")
        print(f"ğŸ‘¤ åå‰: {basic['name']}")
        print(f"ğŸ“… åˆå›å‚åŠ : {basic['first_seen']}")
        print(f"ğŸ•’ æœ€çµ‚æ´»å‹•: {basic['last_activity']}")
        
        print(f"\nğŸ¯ å¼·åŒ–ã•ã‚ŒãŸç¶™ç¶šç‡äºˆæ¸¬:")
        print(f"   åŸºæœ¬ã‚¹ã‚³ã‚¢: {pred['base_retention_score']:.4f}")
        print(f"   èª¿æ•´å¾Œã‚¹ã‚³ã‚¢: {pred['adjusted_retention_score']:.4f} ({pred['adjusted_retention_score']*100:.1f}%)")
        print(f"   ä½œæ¥­è² è·èª¿æ•´: {pred['workload_adjustment']:+.4f}")
        print(f"   å°‚é–€æ€§èª¿æ•´: {pred['expertise_adjustment']:+.4f}")
        print(f"   ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆèª¿æ•´: {pred['burnout_adjustment']:+.4f}")
        print(f"   ã‚«ãƒ†ã‚´ãƒª: {pred['category']}")
        print(f"   ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {pred['risk_level']}")
        
        print(f"\nğŸ“Š ã‚¦ã‚§ãƒ«ãƒã‚¹ã‚¹ã‚³ã‚¢:")
        print(f"   ä½œæ¥­è² è·ã‚¹ã‚³ã‚¢: {wellness['workload_score']:.4f} ({wellness['workload_score']*100:.1f}%)")
        print(f"   å°‚é–€æ€§ã‚¹ã‚³ã‚¢: {wellness['expertise_score']:.4f} ({wellness['expertise_score']*100:.1f}%)")
        print(f"   ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆè€æ€§: {wellness['burnout_score']:.4f} ({wellness['burnout_score']*100:.1f}%)")
        print(f"   ç·åˆã‚¦ã‚§ãƒ«ãƒã‚¹: {wellness['overall_wellness']:.4f} ({wellness['overall_wellness']*100:.1f}%)")
        
        print(f"\nğŸ”§ ä½œæ¥­è² è·åˆ†æ:")
        print(f"   æ—¥æ¬¡ãƒã‚§ãƒ³ã‚¸è² è·: {workload.get('daily_changes_load', 0):.4f}")
        print(f"   æ—¥æ¬¡ã‚³ãƒ¼ãƒ‰è² è·: {workload.get('daily_code_load', 0):.4f}")
        print(f"   ä½œæ¥­å¼·åº¦: {workload.get('code_intensity', 0):.4f}")
        print(f"   è² è·ãƒ¬ãƒ™ãƒ«: {workload.get('workload_level', 0):.1f}")
        print(f"   ã‚¹ãƒˆãƒ¬ã‚¹æŒ‡æ¨™: {workload.get('workload_stress', 0):.4f}")
        
        print(f"\nğŸ¯ å°‚é–€æ€§åˆ†æ:")
        print(f"   å°‚é–€æ€§ãƒãƒƒãƒ: {expertise.get('expertise_match_score', 0):.4f}")
        print(f"   ãƒ‰ãƒ¡ã‚¤ãƒ³ä¸€è²«æ€§: {expertise.get('domain_consistency', 0):.4f}")
        print(f"   ã‚¹ã‚­ãƒ«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ: {expertise.get('skill_alignment', 0):.4f}")
        print(f"   å°‚é–€æ€§ä¿¡é ¼åº¦: {expertise.get('expertise_confidence', 0):.4f}")
        
        print(f"\nğŸ”¥ ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯:")
        print(f"   ç·åˆãƒªã‚¹ã‚¯: {burnout.get('total_burnout_risk', 0):.4f}")
        print(f"   ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {burnout.get('burnout_level', 'unknown')}")
        print(f"   ä½œæ¥­è² è·ãƒªã‚¹ã‚¯: {burnout.get('workload_burnout_risk', 0):.4f}")
        print(f"   å°‚é–€æ€§ãƒŸã‚¹ãƒãƒƒãƒãƒªã‚¹ã‚¯: {burnout.get('expertise_mismatch_risk', 0):.4f}")
        print(f"   ç¶™ç¶šæ€§ãƒªã‚¹ã‚¯: {burnout.get('continuity_risk', 0):.4f}")
        
        print(f"\nğŸ“Š æ´»å‹•çµ±è¨ˆ:")
        print(f"   ä½œæˆã—ãŸãƒã‚§ãƒ³ã‚¸: {stats['changes_authored']:,}")
        print(f"   ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ãŸãƒã‚§ãƒ³ã‚¸: {stats['changes_reviewed']:,}")
        print(f"   ç·æŒ¿å…¥è¡Œæ•°: {stats['total_insertions']:,}")
        print(f"   ç·å‰Šé™¤è¡Œæ•°: {stats['total_deletions']:,}")
        print(f"   å‚åŠ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: {stats['project_count']}")
        
        print(f"\nğŸ’¡ åŒ…æ‹¬çš„æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        for i, rec in enumerate(analysis['comprehensive_recommendations'], 1):
            print(f"   {i}. {rec}")
        
        print(f"\nğŸ¢ å‚åŠ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ:")
        for project in basic['projects'][:5]:
            print(f"   â€¢ {project}")
        if len(basic['projects']) > 5:
            print(f"   ... ä»– {len(basic['projects']) - 5} ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
    
    def get_enhanced_summary_report(self) -> Dict[str, Any]:
        """å¼·åŒ–ã•ã‚ŒãŸã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        if not self.enhanced_predictions:
            return {}
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
        categories = {}
        risk_levels = {}
        burnout_levels = {}
        total_devs = len(self.enhanced_predictions)
        
        retention_scores = []
        wellness_scores = []
        workload_scores = []
        expertise_scores = []
        burnout_scores = []
        
        for analysis in self.enhanced_predictions.values():
            pred = analysis['enhanced_prediction']
            wellness = analysis['wellness_scores']
            burnout = analysis['burnout_risk']
            
            category = pred['category']
            risk_level = pred['risk_level']
            burnout_level = burnout['burnout_level']
            
            categories[category] = categories.get(category, 0) + 1
            risk_levels[risk_level] = risk_levels.get(risk_level, 0) + 1
            burnout_levels[burnout_level] = burnout_levels.get(burnout_level, 0) + 1
            
            retention_scores.append(pred['adjusted_retention_score'])
            wellness_scores.append(wellness['overall_wellness'])
            workload_scores.append(wellness['workload_score'])
            expertise_scores.append(wellness['expertise_score'])
            burnout_scores.append(wellness['burnout_score'])
        
        return {
            'total_developers': total_devs,
            'categories': categories,
            'risk_levels': risk_levels,
            'burnout_levels': burnout_levels,
            'statistics': {
                'retention_scores': {
                    'mean': np.mean(retention_scores),
                    'std': np.std(retention_scores),
                    'min': np.min(retention_scores),
                    'max': np.max(retention_scores)
                },
                'wellness_scores': {
                    'mean': np.mean(wellness_scores),
                    'std': np.std(wellness_scores),
                    'min': np.min(wellness_scores),
                    'max': np.max(wellness_scores)
                },
                'workload_scores': {
                    'mean': np.mean(workload_scores),
                    'std': np.std(workload_scores)
                },
                'expertise_scores': {
                    'mean': np.mean(expertise_scores),
                    'std': np.std(expertise_scores)
                },
                'burnout_scores': {
                    'mean': np.mean(burnout_scores),
                    'std': np.std(burnout_scores)
                }
            }
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ å¼·åŒ–ã•ã‚ŒãŸé–‹ç™ºè€…åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 80)
    print("ğŸ“‹ æ–°æ©Ÿèƒ½:")
    print("   â€¢ ä½œæ¥­è² è·åˆ†æ")
    print("   â€¢ å°‚é–€æ€§ä¸€è‡´ç‡åˆ†æ")
    print("   â€¢ ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯è©•ä¾¡")
    print("   â€¢ ã‚¦ã‚§ãƒ«ãƒã‚¹ã‚¹ã‚³ã‚¢")
    print("   â€¢ åŒ…æ‹¬çš„æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    print("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã®è¨­å®š
    data_path = "data/processed/unified/all_developers.json"
    
    # ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    analyzer = EnhancedDeveloperAnalyzer(data_path)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åˆæœŸåŒ–
        analyzer.load_data_and_initialize()
        
        # å…¨é–‹ç™ºè€…ã®å¼·åŒ–åˆ†æ
        analyzer.analyze_all_developers_enhanced()
        
        # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        summary = analyzer.get_enhanced_summary_report()
        
        print("\nğŸ“Š å¼·åŒ–ã•ã‚ŒãŸå…¨ä½“ã‚µãƒãƒªãƒ¼:")
        print("-" * 60)
        print(f"ç·é–‹ç™ºè€…æ•°: {summary['total_developers']:,}äºº")
        
        print(f"\nğŸ“ˆ ç¶™ç¶šç‡ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ:")
        for category, count in summary['categories'].items():
            percentage = (count / summary['total_developers']) * 100
            print(f"   {category}: {count:,}äºº ({percentage:.1f}%)")
        
        print(f"\nâš ï¸ ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ:")
        for risk, count in summary['risk_levels'].items():
            percentage = (count / summary['total_developers']) * 100
            print(f"   {risk}: {count:,}äºº ({percentage:.1f}%)")
        
        print(f"\nğŸ”¥ ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯åˆ†å¸ƒ:")
        for burnout, count in summary['burnout_levels'].items():
            percentage = (count / summary['total_developers']) * 100
            print(f"   {burnout}: {count:,}äºº ({percentage:.1f}%)")
        
        print(f"\nğŸ“Š ã‚¦ã‚§ãƒ«ãƒã‚¹çµ±è¨ˆ:")
        stats = summary['statistics']
        print(f"   èª¿æ•´å¾Œç¶™ç¶šç‡: å¹³å‡={stats['retention_scores']['mean']:.4f}, "
              f"æ¨™æº–åå·®={stats['retention_scores']['std']:.4f}")
        print(f"   ç·åˆã‚¦ã‚§ãƒ«ãƒã‚¹: å¹³å‡={stats['wellness_scores']['mean']:.4f}, "
              f"æ¨™æº–åå·®={stats['wellness_scores']['std']:.4f}")
        print(f"   ä½œæ¥­è² è·ã‚¹ã‚³ã‚¢: å¹³å‡={stats['workload_scores']['mean']:.4f}")
        print(f"   å°‚é–€æ€§ã‚¹ã‚³ã‚¢: å¹³å‡={stats['expertise_scores']['mean']:.4f}")
        print(f"   ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆè€æ€§: å¹³å‡={stats['burnout_scores']['mean']:.4f}")
        
        # é«˜ãƒªã‚¹ã‚¯é–‹ç™ºè€…ã®ç‰¹å®š
        high_risk_devs = [analysis for analysis in analyzer.enhanced_predictions.values()
                         if analysis['enhanced_prediction']['risk_level'] in ['é«˜ãƒªã‚¹ã‚¯', 'ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯']]
        
        print(f"\nğŸš¨ é«˜ãƒªã‚¹ã‚¯ãƒ»ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯é–‹ç™ºè€…: {len(high_risk_devs)}äºº")
        if high_risk_devs:
            print("ä¸Šä½5äºº:")
            sorted_high_risk = sorted(high_risk_devs, 
                                    key=lambda x: x['enhanced_prediction']['adjusted_retention_score'])
            
            for i, analysis in enumerate(sorted_high_risk[:5], 1):
                basic = analysis['basic_info']
                pred = analysis['enhanced_prediction']
                burnout = analysis['burnout_risk']
                print(f"{i}. {basic['name']} ({basic['developer_id']})")
                print(f"   ç¶™ç¶šç‡: {pred['adjusted_retention_score']:.4f}, "
                      f"ãƒãƒ¼ãƒ³ã‚¢ã‚¦ãƒˆãƒªã‚¹ã‚¯: {burnout['burnout_level']}")
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
        print(f"\nğŸ” å¼·åŒ–ã•ã‚ŒãŸå€‹åˆ¥é–‹ç™ºè€…è©³ç´°è¡¨ç¤º")
        print("=" * 80)
        print("é–‹ç™ºè€…IDã¾ãŸã¯åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ'quit'ã§çµ‚äº†ï¼‰:")
        
        while True:
            query = input("\næ¤œç´¢ > ").strip()
            if query.lower() in ['quit', 'exit', 'q']:
                break
            
            if not query:
                continue
            
            # æ¤œç´¢å®Ÿè¡Œ
            results = []
            query_lower = query.lower()
            
            for analysis in analyzer.enhanced_predictions.values():
                basic = analysis['basic_info']
                if (query_lower in basic['developer_id'].lower() or
                    query_lower in basic['name'].lower()):
                    results.append(analysis)
            
            if not results:
                print(f"âŒ '{query}' ã«ä¸€è‡´ã™ã‚‹é–‹ç™ºè€…ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            
            if len(results) == 1:
                # 1äººã®å ´åˆã¯è©³ç´°è¡¨ç¤º
                analyzer.display_enhanced_developer_details(results[0]['basic_info']['developer_id'])
            else:
                # è¤‡æ•°ã®å ´åˆã¯ãƒªã‚¹ãƒˆè¡¨ç¤º
                print(f"\nğŸ” æ¤œç´¢çµæœ: {len(results)}äºº")
                print("-" * 60)
                for i, analysis in enumerate(results[:10], 1):
                    basic = analysis['basic_info']
                    pred = analysis['enhanced_prediction']
                    wellness = analysis['wellness_scores']
                    print(f"{i}. {basic['name']} ({basic['developer_id']})")
                    print(f"   ç¶™ç¶šç‡: {pred['adjusted_retention_score']:.4f}, "
                          f"ã‚¦ã‚§ãƒ«ãƒã‚¹: {wellness['overall_wellness']:.4f}")
                
                # è©³ç´°è¡¨ç¤ºã®é¸æŠ
                try:
                    choice = input("\nè©³ç´°ã‚’è¦‹ãŸã„ç•ªå·ã‚’å…¥åŠ› (Enter ã§ã‚¹ã‚­ãƒƒãƒ—): ").strip()
                    if choice and choice.isdigit():
                        idx = int(choice) - 1
                        if 0 <= idx < min(len(results), 10):
                            analyzer.display_enhanced_developer_details(results[idx]['basic_info']['developer_id'])
                except:
                    pass
        
        print("\nâœ… å¼·åŒ–ã•ã‚ŒãŸé–‹ç™ºè€…åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
        return analyzer
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    analyzer = main()