#!/usr/bin/env python3
"""
å¼·åŒ–å­¦ç¿’ã‚¿ã‚¹ã‚¯æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸå®Ÿéš›ã®ã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦æœ€é©åŒ–
"""

import json
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import torch

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

import sys

from gerrit_retention.utils.logger import get_logger

sys.path.append('scripts')
from advanced_rl_system import AdvancedActorCritic

logger = get_logger(__name__)

@dataclass
class TaskAssignmentRecommendation:
    """ã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦æ¨å¥¨çµæœ"""
    developer_id: str
    developer_name: str
    task_id: str
    action: str  # 'assign', 'reject', 'defer'
    confidence: float
    reasoning: List[str]
    action_probabilities: Dict[str, float]
    expected_value: float

class RLTaskOptimizer:
    """å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®ã‚¿ã‚¹ã‚¯æœ€é©åŒ–å™¨"""
    
    def __init__(self, model_path: str = 'models/advanced_ppo_agent.pth'):
        self.device = torch.device('cpu')
        self.model_path = model_path
        
        # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        self.actor_critic = AdvancedActorCritic(obs_dim=20, action_dim=3)
        self._load_model()
        
        # è¡Œå‹•ãƒãƒƒãƒ”ãƒ³ã‚°
        self.action_names = ['assign', 'reject', 'defer']
        self.action_descriptions = {
            'assign': 'å‰²ã‚Šå½“ã¦æ¨å¥¨',
            'reject': 'å‰²ã‚Šå½“ã¦éæ¨å¥¨',
            'defer': 'å¾Œã§æ¤œè¨'
        }
        
        logger.info("å¼·åŒ–å­¦ç¿’ã‚¿ã‚¹ã‚¯æœ€é©åŒ–å™¨ã‚’åˆæœŸåŒ–")
    
    def _load_model(self):
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            checkpoint = torch.load(self.model_path, map_location=self.device)
            self.actor_critic.load_state_dict(checkpoint['actor_critic_state_dict'])
            self.actor_critic.eval()
            logger.info(f"è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿: {self.model_path}")
        except Exception as e:
            logger.warning(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}. ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ã‚’ä½¿ç”¨")
    
    def _build_observation(self, developer: Dict, task: Dict, context: Dict = None) -> np.ndarray:
        """è¦³æ¸¬ãƒ™ã‚¯ãƒˆãƒ«ã®æ§‹ç¯‰"""
        obs = np.zeros(20, dtype=np.float32)
        
        if context is None:
            context = {}
        
        # é–‹ç™ºè€…ç‰¹å¾´é‡ (0-9)
        obs[0] = np.tanh((developer['changes_authored'] + developer['changes_reviewed']) / 100.0)
        obs[1] = np.tanh(developer['changes_authored'] / 50.0)
        obs[2] = np.tanh(developer['changes_reviewed'] / 100.0)
        obs[3] = np.tanh(len(developer['projects']) / 10.0)
        obs[4] = context.get('stress_level', np.random.normal(0, 0.3))
        obs[5] = context.get('workload', np.random.uniform(-0.5, 0.5))
        obs[6] = context.get('expertise_match', np.random.uniform(-0.3, 0.7))
        obs[7] = context.get('availability', np.random.uniform(0.2, 1.0))
        obs[8] = context.get('collaboration_score', np.random.uniform(-0.2, 0.8))
        obs[9] = context.get('recent_performance', np.random.uniform(-0.3, 0.7))
        
        # ã‚¿ã‚¹ã‚¯ç‰¹å¾´é‡ (10-14)
        obs[10] = np.tanh(task.get('lines_added', 0) / 500.0)
        obs[11] = np.tanh(task.get('files_changed', 0) / 10.0)
        obs[12] = 1.0 if task.get('status') == 'NEW' else -1.0
        obs[13] = np.tanh(task.get('score', 0) / 2.0)
        obs[14] = context.get('task_priority', np.random.uniform(-0.5, 0.5))
        
        # ç’°å¢ƒçŠ¶æ…‹ (15-19)
        obs[15] = context.get('team_workload', np.random.uniform(-0.3, 0.3))
        obs[16] = context.get('deadline_pressure', np.random.uniform(-0.5, 0.5))
        obs[17] = context.get('team_stress', np.random.uniform(-0.3, 0.3))
        obs[18] = context.get('sprint_progress', np.random.uniform(-0.2, 0.8))
        obs[19] = context.get('resource_availability', np.random.uniform(0.0, 1.0))
        
        return obs
    
    def get_recommendation(
        self, 
        developer: Dict, 
        task: Dict, 
        context: Dict = None
    ) -> TaskAssignmentRecommendation:
        """å˜ä¸€ã®ã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦æ¨å¥¨ã‚’å–å¾—"""
        
        # è¦³æ¸¬ãƒ™ã‚¯ãƒˆãƒ«ã®æ§‹ç¯‰
        obs = self._build_observation(developer, task, context)
        obs_tensor = torch.FloatTensor(obs).unsqueeze(0)
        
        # ãƒ¢ãƒ‡ãƒ«æ¨è«–
        with torch.no_grad():
            action_logits, value = self.actor_critic(obs_tensor)
            probs = torch.softmax(action_logits, dim=-1)
            
            # æœ€é©è¡Œå‹•ã®é¸æŠ
            best_action_idx = torch.argmax(probs, dim=-1).item()
            best_action = self.action_names[best_action_idx]
            confidence = probs[0, best_action_idx].item()
            
            # è¡Œå‹•ç¢ºç‡ã®è¾æ›¸
            action_probs = {
                action: probs[0, i].item() 
                for i, action in enumerate(self.action_names)
            }
        
        # æ¨å¥¨ç†ç”±ã®ç”Ÿæˆ
        reasoning = self._generate_reasoning(
            developer, task, best_action, confidence, obs, context
        )
        
        return TaskAssignmentRecommendation(
            developer_id=developer['developer_id'],
            developer_name=developer['name'],
            task_id=task.get('change_id', 'unknown'),
            action=best_action,
            confidence=confidence,
            reasoning=reasoning,
            action_probabilities=action_probs,
            expected_value=value.item()
        )
    
    def _generate_reasoning(
        self, 
        developer: Dict, 
        task: Dict, 
        action: str, 
        confidence: float, 
        obs: np.ndarray,
        context: Dict = None
    ) -> List[str]:
        """æ¨å¥¨ç†ç”±ã®ç”Ÿæˆ"""
        reasons = []
        
        # é–‹ç™ºè€…ã®æ´»å‹•ãƒ¬ãƒ™ãƒ«
        total_activity = developer['changes_authored'] + developer['changes_reviewed']
        
        # ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘ã•
        task_complexity = task.get('lines_added', 0) + task.get('files_changed', 0) * 10
        
        if action == 'assign':
            reasons.append(f"é«˜ã„ä¿¡é ¼åº¦ ({confidence:.1%}) ã§å‰²ã‚Šå½“ã¦ã‚’æ¨å¥¨")
            
            if total_activity > 50:
                reasons.append(f"è±Šå¯ŒãªçµŒé¨“ (ç·æ´»å‹•: {total_activity}ä»¶)")
            
            if task_complexity < 200:
                reasons.append("é©åº¦ãªã‚µã‚¤ã‚ºã®ã‚¿ã‚¹ã‚¯")
            
            if obs[4] < 0:  # ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«
                reasons.append("é–‹ç™ºè€…ã®ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«ãŒé©æ­£")
            
            if obs[6] > 0.3:  # å°‚é–€æ€§ãƒãƒƒãƒ
                reasons.append("å°‚é–€æ€§ãŒé©åˆ")
            
            if len(developer['projects']) > 0:
                reasons.append("é–¢é€£ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®çµŒé¨“ã‚ã‚Š")
        
        elif action == 'reject':
            reasons.append(f"é«˜ã„ä¿¡é ¼åº¦ ({confidence:.1%}) ã§å‰²ã‚Šå½“ã¦ã‚’éæ¨å¥¨")
            
            if total_activity < 10:
                reasons.append("é–‹ç™ºè€…ã®çµŒé¨“ãŒä¸è¶³")
            
            if task_complexity > 500:
                reasons.append("ã‚¿ã‚¹ã‚¯ãŒè¤‡é›‘ã™ãã‚‹")
            
            if obs[4] > 0.5:  # é«˜ã‚¹ãƒˆãƒ¬ã‚¹
                reasons.append("é–‹ç™ºè€…ã®ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«ãŒé«˜ã„")
            
            if obs[5] > 0.5:  # é«˜è² è·
                reasons.append("ç¾åœ¨ã®ä½œæ¥­è² è·ãŒé«˜ã„")
        
        else:  # defer
            reasons.append("ã‚ˆã‚Šè©³ç´°ãªæ¤œè¨ãŒå¿…è¦")
            
            if 0.3 < confidence < 0.7:
                reasons.append("åˆ¤æ–­ãŒå›°é›£ãªã‚±ãƒ¼ã‚¹")
            
            if obs[16] > 0.5:  # ç· åˆ‡ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼
                reasons.append("ç· åˆ‡ã‚’è€ƒæ…®ã—ãŸæ…é‡ãªåˆ¤æ–­")
        
        # æœ€ä½1ã¤ã®ç†ç”±ã‚’ä¿è¨¼
        if not reasons:
            reasons.append(f"AIåˆ¤æ–­ã«ã‚ˆã‚‹ {self.action_descriptions[action]}")
        
        return reasons
    
    def optimize_team_assignments(
        self, 
        developers: List[Dict], 
        tasks: List[Dict],
        max_assignments_per_developer: int = 3
    ) -> Dict:
        """ãƒãƒ¼ãƒ å…¨ä½“ã®ã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦æœ€é©åŒ–"""
        
        logger.info(f"ãƒãƒ¼ãƒ æœ€é©åŒ–é–‹å§‹: {len(developers)}åã®é–‹ç™ºè€…, {len(tasks)}ä»¶ã®ã‚¿ã‚¹ã‚¯")
        
        # å…¨ã¦ã®çµ„ã¿åˆã‚ã›ã§æ¨å¥¨ã‚’å–å¾—
        all_recommendations = []
        
        for task in tasks:
            task_recommendations = []
            
            for developer in developers:
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®è¨­å®š
                context = {
                    'stress_level': np.random.normal(0, 0.3),
                    'workload': np.random.uniform(-0.5, 0.5),
                    'expertise_match': np.random.uniform(-0.3, 0.7),
                    'availability': np.random.uniform(0.2, 1.0),
                    'task_priority': np.random.uniform(-0.5, 0.5)
                }
                
                recommendation = self.get_recommendation(developer, task, context)
                task_recommendations.append(recommendation)
            
            # ã‚¿ã‚¹ã‚¯ã”ã¨ã«æœ€é©ãªå‰²ã‚Šå½“ã¦ã‚’é¸æŠ
            assign_recommendations = [
                rec for rec in task_recommendations 
                if rec.action == 'assign'
            ]
            
            if assign_recommendations:
                # ä¿¡é ¼åº¦ãŒæœ€ã‚‚é«˜ã„æ¨å¥¨ã‚’é¸æŠ
                best_recommendation = max(
                    assign_recommendations, 
                    key=lambda x: x.confidence
                )
                all_recommendations.append(best_recommendation)
        
        # é–‹ç™ºè€…ã”ã¨ã®å‰²ã‚Šå½“ã¦æ•°ã‚’åˆ¶é™
        developer_assignments = {}
        final_assignments = []
        
        # ä¿¡é ¼åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_recommendations = sorted(
            all_recommendations, 
            key=lambda x: x.confidence, 
            reverse=True
        )
        
        for rec in sorted_recommendations:
            dev_id = rec.developer_id
            current_count = developer_assignments.get(dev_id, 0)
            
            if current_count < max_assignments_per_developer:
                final_assignments.append(rec)
                developer_assignments[dev_id] = current_count + 1
        
        # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
        total_tasks = len(tasks)
        assigned_tasks = len(final_assignments)
        assignment_rate = assigned_tasks / total_tasks if total_tasks > 0 else 0
        
        avg_confidence = np.mean([rec.confidence for rec in final_assignments]) if final_assignments else 0
        
        # é–‹ç™ºè€…åˆ¥çµ±è¨ˆ
        developer_stats = {}
        for dev_id, count in developer_assignments.items():
            developer = next(d for d in developers if d['developer_id'] == dev_id)
            developer_stats[dev_id] = {
                'name': developer['name'],
                'assignments': count,
                'avg_confidence': np.mean([
                    rec.confidence for rec in final_assignments 
                    if rec.developer_id == dev_id
                ])
            }
        
        optimization_result = {
            'assignments': final_assignments,
            'statistics': {
                'total_tasks': total_tasks,
                'assigned_tasks': assigned_tasks,
                'assignment_rate': assignment_rate,
                'average_confidence': avg_confidence,
                'developer_stats': developer_stats
            }
        }
        
        logger.info(f"æœ€é©åŒ–å®Œäº†: {assigned_tasks}/{total_tasks}ä»¶ã®ã‚¿ã‚¹ã‚¯ã‚’å‰²ã‚Šå½“ã¦ (æˆåŠŸç‡: {assignment_rate:.1%})")
        
        return optimization_result


def demonstrate_rl_optimization():
    """å¼·åŒ–å­¦ç¿’æœ€é©åŒ–ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    logger.info("=== å¼·åŒ–å­¦ç¿’ã‚¿ã‚¹ã‚¯æœ€é©åŒ–ãƒ‡ãƒ¢ ===")
    
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    with open('data/processed/unified/all_developers.json', 'r') as f:
        developers_data = json.load(f)
    
    with open('data/processed/unified/all_reviews.json', 'r') as f:
        reviews_data = json.load(f)
    
    # äººé–“ã®é–‹ç™ºè€…ã®ã¿ã‚’æŠ½å‡º
    human_developers = []
    for dev in developers_data:
        name_lower = dev['name'].lower()
        email_lower = dev['developer_id'].lower()
        
        is_bot = any(keyword in name_lower for keyword in ['bot', 'robot', 'lint', 'presubmit', 'treehugger'])
        is_bot = is_bot or any(keyword in email_lower for keyword in ['bot', 'robot', 'system.gserviceaccount', 'presubmit'])
        
        if not is_bot and (dev['changes_authored'] > 0 or dev['changes_reviewed'] > 5):
            human_developers.append(dev)
    
    # ä¸Šä½é–‹ç™ºè€…ã¨ã‚¿ã‚¹ã‚¯ã‚’é¸æŠ
    top_developers = sorted(
        human_developers, 
        key=lambda x: x['changes_authored'] + x['changes_reviewed'], 
        reverse=True
    )[:8]
    
    interesting_tasks = [
        task for task in reviews_data 
        if task.get('lines_added', 0) > 0  # ã‚ˆã‚Šç·©ã„æ¡ä»¶
    ][:6]
    
    # ã‚¿ã‚¹ã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…¨ã¦ã®ã‚¿ã‚¹ã‚¯ã‚’ä½¿ç”¨
    if not interesting_tasks:
        interesting_tasks = reviews_data[:6]
    
    # æœ€é©åŒ–å™¨ã®åˆæœŸåŒ–
    optimizer = RLTaskOptimizer()
    
    # ãƒãƒ¼ãƒ æœ€é©åŒ–ã®å®Ÿè¡Œ
    optimization_result = optimizer.optimize_team_assignments(
        top_developers, interesting_tasks, max_assignments_per_developer=2
    )
    
    # çµæœã®è¡¨ç¤º
    print("\\nğŸ¤– å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹æœ€é©ã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦çµæœ")
    print("=" * 60)
    
    assignments = optimization_result['assignments']
    stats = optimization_result['statistics']
    
    print(f"\\nğŸ“Š å…¨ä½“çµ±è¨ˆ:")
    print(f"   ç·ã‚¿ã‚¹ã‚¯æ•°: {stats['total_tasks']}ä»¶")
    print(f"   å‰²ã‚Šå½“ã¦æ¸ˆã¿: {stats['assigned_tasks']}ä»¶")
    print(f"   å‰²ã‚Šå½“ã¦ç‡: {stats['assignment_rate']:.1%}")
    print(f"   å¹³å‡ä¿¡é ¼åº¦: {stats['average_confidence']:.1%}")
    
    print(f"\\nğŸ‘¥ é–‹ç™ºè€…åˆ¥å‰²ã‚Šå½“ã¦:")
    for dev_id, dev_stats in stats['developer_stats'].items():
        print(f"   {dev_stats['name']}: {dev_stats['assignments']}ä»¶ (ä¿¡é ¼åº¦: {dev_stats['avg_confidence']:.1%})")
    
    print(f"\\nğŸ“‹ è©³ç´°ãªå‰²ã‚Šå½“ã¦æ¨å¥¨:")
    for i, assignment in enumerate(assignments, 1):
        print(f"\\n   {i}. ã‚¿ã‚¹ã‚¯ {assignment.task_id}")
        print(f"      â†’ {assignment.developer_name} ({assignment.developer_id})")
        print(f"      æ¨å¥¨: {assignment.action} (ä¿¡é ¼åº¦: {assignment.confidence:.1%})")
        print(f"      æœŸå¾…ä¾¡å€¤: {assignment.expected_value:.2f}")
        print(f"      ç†ç”±:")
        for reason in assignment.reasoning:
            print(f"        â€¢ {reason}")
        
        # è¡Œå‹•ç¢ºç‡ã®è©³ç´°
        probs = assignment.action_probabilities
        print(f"      ç¢ºç‡åˆ†å¸ƒ: å‰²å½“{probs['assign']:.1%}, æ‹’å¦{probs['reject']:.1%}, å»¶æœŸ{probs['defer']:.1%}")
    
    print("\\n" + "=" * 60)
    logger.info("å¼·åŒ–å­¦ç¿’æœ€é©åŒ–ãƒ‡ãƒ¢å®Œäº†")


if __name__ == "__main__":
    demonstrate_rl_optimization()