#!/usr/bin/env python3
"""
æ‹¡å¼µç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ãŸå„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ãƒ©ãƒ™ãƒ«ä»˜ãIRLè¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ‹¡å¼µIRLç‰ˆã®ç‰¹å¾´:
- çŠ¶æ…‹ç‰¹å¾´é‡: 32æ¬¡å…ƒï¼ˆé€šå¸¸IRLã¯10æ¬¡å…ƒï¼‰
- è¡Œå‹•ç‰¹å¾´é‡: 9æ¬¡å…ƒï¼ˆé€šå¸¸IRLã¯5æ¬¡å…ƒï¼‰
- é«˜å„ªå…ˆåº¦ç‰¹å¾´é‡ã‚’çµ±åˆï¼š
  * A1: æ´»å‹•é »åº¦ã®å¤šæœŸé–“æ¯”è¼ƒ
  * B1: ãƒ¬ãƒ“ãƒ¥ãƒ¼è² è·æŒ‡æ¨™
  * C1: ç›¸äº’ä½œç”¨ã®æ·±ã•
  * D1: å°‚é–€æ€§ã®ä¸€è‡´åº¦
  
é‡è¦ãªè¨­è¨ˆ:
- å„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰å°†æ¥ã®è²¢çŒ®ã‚’ãƒ©ãƒ™ãƒ«ã¨ã—ã¦è¨ˆç®—
- seq_lenå€‹ã®ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã§1ã¤ï¼‰
- ã™ã¹ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã§äºˆæ¸¬ã¨æå¤±ã‚’è¨ˆç®—
- ã‚ˆã‚Šè±Šå¯Œãªå­¦ç¿’ä¿¡å·ã‚’æ´»ç”¨

ç›®çš„:
- å„æ™‚ç‚¹ã§ã®ç¶™ç¶šäºˆæ¸¬ã‚’å­¦ç¿’
- æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚ˆã‚Šè©³ç´°ã«å­¦ç¿’
- äºˆæ¸¬ç²¾åº¦ã®å‘ä¸Š
- æ‹¡å¼µç‰¹å¾´é‡ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Š
"""
from __future__ import annotations

import argparse
import json
import logging
import pickle
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

import numpy as np
import pandas as pd
import torch
from sklearn.metrics import (
    auc,
    f1_score,
    precision_recall_curve,
    precision_score,
    recall_score,
    roc_auc_score,
)

ROOT = Path(__file__).resolve().parents[3]
SRC = ROOT / "src"
if str(SRC) not in sys.path:
    sys.path.append(str(SRC))

SCRIPTS_DIR = ROOT / "scripts" / "training" / "irl"
if str(SCRIPTS_DIR) not in sys.path:
    sys.path.append(str(SCRIPTS_DIR))

from train_irl_within_training_period import (
    extract_cutoff_evaluation_trajectories,
    extract_full_sequence_monthly_label_trajectories,
    extract_monthly_aggregated_label_trajectories,
    extract_multi_step_label_trajectories,
    find_optimal_threshold,
    load_review_logs,
)

from gerrit_retention.rl_prediction.enhanced_retention_irl_system import (
    EnhancedRetentionIRLSystem,
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def train_irl_model_multi_step(
    trajectories: List[Dict[str, Any]],
    config: Dict[str, Any],
    epochs: int = 30
) -> EnhancedRetentionIRLSystem:
    """
    æ‹¡å¼µç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ãŸå„ã‚¹ãƒ†ãƒƒãƒ—ãƒ©ãƒ™ãƒ«ä»˜ãIRLãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
    
    Args:
        trajectories: å„ã‚¹ãƒ†ãƒƒãƒ—ãƒ©ãƒ™ãƒ«ä»˜ãè»Œè·¡ãƒ‡ãƒ¼ã‚¿
        config: ãƒ¢ãƒ‡ãƒ«è¨­å®š
        epochs: ã‚¨ãƒãƒƒã‚¯æ•°
        
    Returns:
        è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    """
    logger.info("=" * 80)
    logger.info("æ‹¡å¼µIRLè¨“ç·´é–‹å§‹")
    logger.info(f"ç‰¹å¾´é‡: çŠ¶æ…‹32æ¬¡å…ƒã€è¡Œå‹•9æ¬¡å…ƒ")
    logger.info(f"è»Œè·¡æ•°: {len(trajectories)}")
    logger.info(f"ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
    logger.info(f"ç›®æ¨™: å„æ™‚ç‚¹ã§ã®ç¶™ç¶šäºˆæ¸¬ã‚’å­¦ç¿’ï¼ˆæ‹¡å¼µç‰¹å¾´é‡ç‰ˆï¼‰")
    logger.info("=" * 80)
    
    # IRLã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    irl_system = EnhancedRetentionIRLSystem(config)
    
    # è¨“ç·´
    result = irl_system.train_irl_multi_step_labels(
        expert_trajectories=trajectories,
        epochs=epochs
    )
    
    logger.info("=" * 80)
    logger.info(f"æ‹¡å¼µIRLè¨“ç·´å®Œäº†: æœ€çµ‚æå¤± = {result['final_loss']:.4f}")
    logger.info("=" * 80)
    
    return irl_system


def evaluate_model(
    irl_system: EnhancedRetentionIRLSystem,
    eval_trajectories: List[Dict[str, Any]],
    threshold: float = 0.5
) -> Dict[str, Any]:
    """æ‹¡å¼µIRLãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡"""
    logger.info("=" * 80)
    logger.info("æ‹¡å¼µIRLãƒ¢ãƒ‡ãƒ«è©•ä¾¡é–‹å§‹")
    logger.info(f"è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(eval_trajectories)}")
    logger.info(f"é–¾å€¤: {threshold}")
    logger.info("=" * 80)
    
    predictions = []
    true_labels = []
    prediction_details = []  # è©³ç´°æƒ…å ±ã‚’ä¿å­˜
    
    for trajectory in eval_trajectories:
        developer = trajectory.get('developer', trajectory.get('developer_info', {}))
        activity_history = trajectory['activity_history']
        context_date = trajectory.get('context_date', datetime.now())
        true_label = trajectory.get('future_contribution', False)
        
        # äºˆæ¸¬
        result = irl_system.predict_continuation_probability(
            developer, activity_history, context_date
        )
        
        pred_prob = result['continuation_probability']
        predictions.append(pred_prob)
        true_labels.append(1 if true_label else 0)
        
        # è©³ç´°æƒ…å ±ã‚’ä¿å­˜
        developer_email = developer.get('developer_email', 'unknown')
        prediction_details.append({
            'reviewer_email': developer_email,
            'predicted_prob': pred_prob,
            'true_label': 1 if true_label else 0,
            'activity_count': len(activity_history)
        })
    
    predictions = np.array(predictions)
    true_labels = np.array(true_labels)
    
    # æœ€é©é–¾å€¤ã‚’æ¢ç´¢
    optimal_threshold, best_metrics = find_optimal_threshold(true_labels, predictions)
    
    # è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆæœ€é©é–¾å€¤ä½¿ç”¨ï¼‰
    pred_binary = (predictions >= optimal_threshold).astype(int)
    
    metrics = {
        'auc_roc': float(roc_auc_score(true_labels, predictions)),
        'precision': float(precision_score(true_labels, pred_binary, zero_division=0)),
        'recall': float(recall_score(true_labels, pred_binary, zero_division=0)),
        'f1': float(f1_score(true_labels, pred_binary, zero_division=0)),
        'optimal_threshold': float(optimal_threshold),
        'best_f1': float(best_metrics['f1']) if best_metrics else 0.0,
        'sample_count': len(eval_trajectories),
        'positive_count': int(true_labels.sum()),
        'negative_count': int((1 - true_labels).sum()),
        'continuation_rate': float(true_labels.mean()),
    }
    
    # AUC-PR
    precision_curve, recall_curve, _ = precision_recall_curve(true_labels, predictions)
    metrics['auc_pr'] = float(auc(recall_curve, precision_curve))
    
    logger.info(f"AUC-ROC: {metrics['auc_roc']:.3f}")
    logger.info(f"AUC-PR: {metrics['auc_pr']:.3f}")
    logger.info(f"æœ€é©é–¾å€¤: {metrics['optimal_threshold']:.3f} (F1={metrics['best_f1']:.3f})")
    logger.info(f"Precision: {metrics['precision']:.3f}")
    logger.info(f"Recall: {metrics['recall']:.3f}")
    logger.info(f"F1: {metrics['f1']:.3f}")
    logger.info(f"ç¶™ç¶šç‡: {metrics['continuation_rate']:.1%}")
    
    # äºˆæ¸¬è©³ç´°ã‚‚è¿”ã™
    return metrics, prediction_details


def main():
    parser = argparse.ArgumentParser(description='æ‹¡å¼µç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ãŸå„ã‚¹ãƒ†ãƒƒãƒ—ãƒ©ãƒ™ãƒ«ä»˜ãIRLè¨“ç·´')
    parser.add_argument('--reviews', type=str, required=True, help='ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ­ã‚°CSV')
    parser.add_argument('--train-start', type=str, required=True, help='å­¦ç¿’é–‹å§‹æ—¥')
    parser.add_argument('--train-end', type=str, required=True, help='å­¦ç¿’çµ‚äº†æ—¥')
    parser.add_argument('--eval-start', type=str, required=True, help='è©•ä¾¡é–‹å§‹æ—¥')
    parser.add_argument('--eval-end', type=str, required=True, help='è©•ä¾¡çµ‚äº†æ—¥')
    parser.add_argument('--history-window', type=int, default=12, help='å±¥æ­´ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆãƒ¶æœˆï¼‰')
    parser.add_argument('--future-window-start', type=int, default=0, help='å°†æ¥çª“é–‹å§‹ï¼ˆãƒ¶æœˆï¼‰')
    parser.add_argument('--future-window-end', type=int, default=3, help='å°†æ¥çª“çµ‚äº†ï¼ˆãƒ¶æœˆï¼‰')
    parser.add_argument('--seq-len', type=int, default=0, 
                        help='LSTMã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ï¼ˆ0=å¯å¤‰é•·ï¼šå…¨æ´»å‹•ã‚’ä½¿ç”¨ï¼‰')
    parser.add_argument('--use-monthly-labels', action='store_true',
                        help='ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚ç‚¹ãƒ™ãƒ¼ã‚¹ãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨ï¼ˆãƒ©ãƒ™ãƒ«=ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å˜ä½ã€å­¦ç¿’=æ´»å‹•å˜ä½ã€æ™‚ç³»åˆ—ä¿æŒï¼‰')
    parser.add_argument('--use-full-sequence', action='store_true',
                        help='å…¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼‹æœˆæ¬¡é›†ç´„ãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãªã—ã€ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å˜ä½ç¶™ç¶šç‡ï¼‰')
    parser.add_argument('--epochs', type=int, default=30, help='è¨“ç·´ã‚¨ãƒãƒƒã‚¯æ•°')
    parser.add_argument('--eval-future-window-start', type=int, default=None, 
                        help='è©•ä¾¡æ™‚ã®å°†æ¥çª“é–‹å§‹ï¼ˆãƒ¶æœˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ=future-window-startï¼‰')
    parser.add_argument('--eval-future-window-end', type=int, default=None, 
                        help='è©•ä¾¡æ™‚ã®å°†æ¥çª“çµ‚äº†ï¼ˆãƒ¶æœˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ=future-window-endï¼‰')
    parser.add_argument('--output', type=str, required=True, help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    args = parser.parse_args()
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info("=" * 80)
    logger.info("ğŸ”¬ æ‹¡å¼µç‰¹å¾´é‡IRLè¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    # è©•ä¾¡ç”¨ã®å°†æ¥çª“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯è¨“ç·´æ™‚ã¨åŒã˜ï¼‰
    eval_future_start = args.eval_future_window_start if args.eval_future_window_start is not None else args.future_window_start
    eval_future_end = args.eval_future_window_end if args.eval_future_window_end is not None else args.future_window_end
    
    if args.use_full_sequence:
        logger.info("å…¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼‹æœˆæ¬¡é›†ç´„ãƒ©ãƒ™ãƒ«æ‹¡å¼µIRLè¨“ç·´ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãªã—ï¼‰")
    elif args.use_monthly_labels:
        logger.info("ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚ç‚¹ãƒ™ãƒ¼ã‚¹ãƒ©ãƒ™ãƒ«æ‹¡å¼µIRLè¨“ç·´")
    else:
        logger.info("å„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ãƒ©ãƒ™ãƒ«ä»˜ãæ‹¡å¼µIRLè¨“ç·´")
    logger.info("=" * 80)
    logger.info(f"ç‰¹å¾´é‡: çŠ¶æ…‹32æ¬¡å…ƒ / è¡Œå‹•9æ¬¡å…ƒï¼ˆé€šå¸¸IRLã¯10æ¬¡å…ƒ/5æ¬¡å…ƒï¼‰")
    logger.info(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ­ã‚°: {args.reviews}")
    logger.info(f"å­¦ç¿’æœŸé–“: {args.train_start} ï½ {args.train_end}")
    logger.info(f"è©•ä¾¡æœŸé–“: {args.eval_start} ï½ {args.eval_end}")
    logger.info(f"å±¥æ­´ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: {args.history_window}ãƒ¶æœˆ")
    logger.info(f"è¨“ç·´ãƒ©ãƒ™ãƒ«: {args.future_window_start}ï½{args.future_window_end}ãƒ¶æœˆ")
    logger.info(f"è©•ä¾¡ãƒ©ãƒ™ãƒ«: {eval_future_start}ï½{eval_future_end}ãƒ¶æœˆ")
    if args.use_full_sequence:
        logger.info("ãƒ©ãƒ™ãƒ«ä»˜ã‘: æœˆæ¬¡é›†ç´„ï¼ˆå„æœˆæœ«ã‹ã‚‰å°†æ¥çª“å†…ã«æ´»å‹•ãŒã‚ã‚‹ã‹ï¼‰")
        logger.info("å­¦ç¿’: å„æ´»å‹•ï¼ˆã‚¹ãƒ†ãƒƒãƒ—ï¼‰å˜ä½ã€æœˆã”ã¨ã«åŒã˜ãƒ©ãƒ™ãƒ«")
        logger.info("ç¶™ç¶šç‡: ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å˜ä½ï¼ˆæœ€çµ‚æœˆã®ãƒ©ãƒ™ãƒ«ã§åˆ¤å®šï¼‰")
        logger.info("ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: ãªã—ï¼ˆå„ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‹ã‚‰1ã‚µãƒ³ãƒ—ãƒ«ï¼‰")
    elif args.use_monthly_labels:
        logger.info("ãƒ©ãƒ™ãƒ«ä»˜ã‘: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚ç‚¹ãƒ™ãƒ¼ã‚¹ï¼ˆå„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚ç‚¹ã‹ã‚‰å°†æ¥çª“å†…ã«æ´»å‹•ãŒã‚ã‚‹ã‹ï¼‰")
        logger.info("å­¦ç¿’: å„æ´»å‹•ï¼ˆã‚¹ãƒ†ãƒƒãƒ—ï¼‰å˜ä½ã€å…¨ã‚¹ãƒ†ãƒƒãƒ—ã§åŒã˜ãƒ©ãƒ™ãƒ«ï¼ˆæ™‚ç³»åˆ—å­¦ç¿’ä¿æŒï¼‰")
    if eval_future_start != args.future_window_start or eval_future_end != args.future_window_end:
        logger.info("  âš ï¸ è¨“ç·´ã¨è©•ä¾¡ã§ç•°ãªã‚‹ãƒ©ãƒ™ãƒ«æœŸé–“ã‚’ä½¿ç”¨ï¼ˆã‚¯ãƒ­ã‚¹è©•ä¾¡ï¼‰")
    if args.seq_len == 0:
        logger.info("LSTMã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: å¯å¤‰é•·ï¼ˆå…¨æ´»å‹•ã‚’ä½¿ç”¨ï¼‰")
        seq_len_val = None
    else:
        logger.info(f"LSTMã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: {args.seq_len}")
        seq_len_val = args.seq_len
    logger.info(f"ã‚¨ãƒãƒƒã‚¯æ•°: {args.epochs}")
    logger.info(f"å‡ºåŠ›: {output_dir}")
    logger.info("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_review_logs(Path(args.reviews))
    
    # æ—¥ä»˜ã‚’è§£æ
    train_start = pd.Timestamp(args.train_start)
    train_end = pd.Timestamp(args.train_end)
    eval_start = pd.Timestamp(args.eval_start)
    eval_end = pd.Timestamp(args.eval_end)
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    logger.info("\n" + "=" * 80)
    if args.use_full_sequence:
        logger.info("è¨“ç·´ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆå…¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼‹æœˆæ¬¡é›†ç´„ãƒ©ãƒ™ãƒ«ä»˜ãï¼‰")
    elif args.use_monthly_labels:
        logger.info("è¨“ç·´ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚ç‚¹ãƒ™ãƒ¼ã‚¹ãƒ©ãƒ™ãƒ«ä»˜ãï¼‰")
    else:
        logger.info("è¨“ç·´ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ãƒ©ãƒ™ãƒ«ä»˜ãï¼‰")
    logger.info("=" * 80)
    
    if args.use_full_sequence:
        train_trajectories = extract_full_sequence_monthly_label_trajectories(
            df=df,
            train_start=train_start,
            train_end=train_end,
            future_window_start_months=args.future_window_start,
            future_window_end_months=args.future_window_end,
            min_history_events=3,
        )
    elif args.use_monthly_labels:
        train_trajectories = extract_monthly_aggregated_label_trajectories(
            df=df,
            train_start=train_start,
            train_end=train_end,
            history_window_months=args.history_window,
            future_window_start_months=args.future_window_start,
            future_window_end_months=args.future_window_end,
            sampling_interval_months=1,
            seq_len=seq_len_val,
            min_history_events=3,
        )
    else:
        train_trajectories = extract_multi_step_label_trajectories(
            df=df,
            train_start=train_start,
            train_end=train_end,
            history_window_months=args.history_window,
            future_window_start_months=args.future_window_start,
            future_window_end_months=args.future_window_end,
            sampling_interval_months=1,
            seq_len=seq_len_val,
            min_history_events=3,
        )
    
    logger.info(f"è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(train_trajectories)}")
    
    if len(train_trajectories) == 0:
        logger.error("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    logger.info("\n" + "=" * 80)
    logger.info("è©•ä¾¡ãƒ‡ãƒ¼ã‚¿æŠ½å‡º")
    logger.info("=" * 80)
    
    eval_trajectories = extract_cutoff_evaluation_trajectories(
        df=df,
        cutoff_date=train_end,  # è¨“ç·´çµ‚äº†æ—¥ã‹ã‚‰è©•ä¾¡
        history_window_months=args.history_window,
        future_window_start_months=eval_future_start,
        future_window_end_months=eval_future_end,
        min_history_events=3,
    )
    
    logger.info(f"è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(eval_trajectories)}")
    
    # ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆæ‹¡å¼µIRL: state_dim=32, action_dim=9ï¼‰
    config = {
        'state_dim': 32,  # æ‹¡å¼µç‰¹å¾´é‡
        'action_dim': 9,  # æ‹¡å¼µç‰¹å¾´é‡
        'hidden_dim': 256,  # ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        'learning_rate': 0.0001,
        'sequence': True,
        'seq_len': args.seq_len,
        'dropout': 0.2,
    }
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    irl_system = train_irl_model_multi_step(
        train_trajectories,
        config,
        epochs=args.epochs
    )
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    model_path = output_dir / 'enhanced_irl_model.pt'
    irl_system.save_model(str(model_path))
    logger.info(f"æ‹¡å¼µIRLãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")
    
    # è©•ä¾¡
    if len(eval_trajectories) > 0:
        metrics, prediction_details = evaluate_model(irl_system, eval_trajectories)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜
        metrics_path = output_dir / 'metrics.json'
        with open(metrics_path, 'w') as f:
            json.dump(metrics, f, indent=2)
        logger.info(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜: {metrics_path}")
        
        # äºˆæ¸¬è©³ç´°ã‚’CSVã«ä¿å­˜
        predictions_path = output_dir / 'predictions.csv'
        pred_df = pd.DataFrame(prediction_details)
        pred_df['predicted_binary'] = (pred_df['predicted_prob'] >= metrics['optimal_threshold']).astype(int)
        pred_df.to_csv(predictions_path, index=False)
        logger.info(f"äºˆæ¸¬è©³ç´°ä¿å­˜: {predictions_path} ({len(pred_df)}ä»¶)")
        
        # è»Œè·¡ã‚’ä¿å­˜
        trajectories_path = output_dir / 'train_trajectories.pkl'
        with open(trajectories_path, 'wb') as f:
            pickle.dump(train_trajectories[:100], f)  # æœ€åˆã®100å€‹ã®ã¿ä¿å­˜
        logger.info(f"è¨“ç·´è»Œè·¡ä¿å­˜: {trajectories_path}")
        
        eval_trajectories_path = output_dir / 'eval_trajectories.pkl'
        with open(eval_trajectories_path, 'wb') as f:
            pickle.dump(eval_trajectories, f)
        logger.info(f"è©•ä¾¡è»Œè·¡ä¿å­˜: {eval_trajectories_path}")
    
    logger.info("\n" + "=" * 80)
    logger.info("æ‹¡å¼µIRLè¨“ç·´å®Œäº†ï¼")
    logger.info("=" * 80)


if __name__ == '__main__':
    main()

