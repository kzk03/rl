#!/usr/bin/env python3
"""
ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦IRLå­¦ç¿’

è¨“ç·´ãƒ©ãƒ™ãƒ«ã‚’ç‹¬ç«‹ã—ãŸã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§å®šç¾©:
- 0-3m: 0ï½3ãƒ¶æœˆå¾Œã«æ´»å‹•
- 3-6m: 3ï½6ãƒ¶æœˆå¾Œã«æ´»å‹•ï¼ˆ0-3mã¯é™¤ãï¼‰
- 6-9m: 6ï½9ãƒ¶æœˆå¾Œã«æ´»å‹•ï¼ˆ0-6mã¯é™¤ãï¼‰
- 9-12m: 9ï½12ãƒ¶æœˆå¾Œã«æ´»å‹•ï¼ˆ0-9mã¯é™¤ãï¼‰

ã“ã‚Œã«ã‚ˆã‚Šã€å„è¨“ç·´ãƒ©ãƒ™ãƒ«ãŒç•°ãªã‚‹æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã‚’å­¦ç¿’ã—ã¾ã™ã€‚
"""
from __future__ import annotations

import argparse
import json
import logging
import sys
from pathlib import Path
from typing import Any, Dict, List

import numpy as np
import pandas as pd
import torch
from sklearn.metrics import (
    auc,
    f1_score,
    precision_recall_curve,
    precision_score,
    recall_score,
    roc_auc_score,
)

ROOT = Path(__file__).resolve().parents[3]
SRC = ROOT / "src"
if str(SRC) not in sys.path:
    sys.path.append(str(SRC))

SCRIPTS_DIR = ROOT / "scripts" / "training" / "irl"
if str(SCRIPTS_DIR) not in sys.path:
    sys.path.append(str(SCRIPTS_DIR))

from train_irl_within_training_period import (
    extract_cutoff_evaluation_trajectories,
    find_optimal_threshold,
    load_review_logs,
)

from gerrit_retention.rl_prediction.retention_irl_system import RetentionIRLSystem

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def extract_sliding_window_trajectories(
    df: pd.DataFrame,
    train_start: pd.Timestamp,
    train_end: pd.Timestamp,
    future_window_start_months: int = 0,
    future_window_end_months: int = 3,
    min_history_events: int = 3,
    reviewer_col: str = 'reviewer_email',
    date_col: str = 'request_time',
    project: str = None
) -> List[Dict[str, Any]]:
    """
    ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç‰ˆï¼šæ™‚ç³»åˆ—è¨“ç·´ï¼‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆäºˆæ¸¬è»Œè·¡ã‚’æŠ½å‡º
    
    ç‰¹å¾´ï¼š
    - **è¨“ç·´**ï¼šæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®ç‰¹å¾´é‡ï¼‰
    - **äºˆæ¸¬**ï¼šã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ã§äºˆæ¸¬ï¼ˆç‰¹å®šæ™‚ç‚¹ã§ã®é›†ç´„ç‰¹å¾´é‡ï¼‰
    - **ãƒ©ãƒ™ãƒ«**ï¼šæœˆæ¬¡é›†ç´„ãƒ©ãƒ™ãƒ«ï¼ˆå„æœˆæœ«ã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã«æ´»å‹•ãŒã‚ã‚‹ã‹ï¼‰
    - **ç¶™ç¶šç‡**ï¼šãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å˜ä½ï¼ˆæœ€çµ‚æœˆã®ãƒ©ãƒ™ãƒ«ã§åˆ¤å®šï¼‰
    
    Args:
        df: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿
        train_start: å­¦ç¿’é–‹å§‹æ—¥
        train_end: å­¦ç¿’çµ‚äº†æ—¥
        future_window_start_months: å°†æ¥çª“é–‹å§‹ï¼ˆæœˆæ•°ï¼‰
        future_window_end_months: å°†æ¥çª“çµ‚äº†ï¼ˆæœˆæ•°ï¼‰
        min_history_events: æœ€å°æ´»å‹•æ•°
        reviewer_col: ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼åˆ—å
        date_col: æ—¥ä»˜åˆ—å
        project: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆæŒ‡å®šæ™‚ã¯å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ï¼‰
    
    Returns:
        å„ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®è»Œè·¡ã®ãƒªã‚¹ãƒˆï¼ˆ1ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼=1ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    """
    logger.info("=" * 80)
    logger.info("ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç‰ˆï¼šæ™‚ç³»åˆ—è¨“ç·´ï¼‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆäºˆæ¸¬è»Œè·¡æŠ½å‡ºã‚’é–‹å§‹")
    logger.info(f"å­¦ç¿’æœŸé–“: {train_start} ï½ {train_end}")
    logger.info(f"å°†æ¥çª“: {future_window_start_months}ï½{future_window_end_months}ãƒ¶æœˆï¼ˆã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ï¼‰")
    if project:
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project} (å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ)")
    else:
        logger.info("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
    logger.info("è¨“ç·´: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®ç‰¹å¾´é‡ï¼‰")
    logger.info("äºˆæ¸¬: ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ï¼ˆç‰¹å®šæ™‚ç‚¹ã§ã®é›†ç´„ç‰¹å¾´é‡ï¼‰")
    logger.info("ãƒ©ãƒ™ãƒ«: æœˆæ¬¡é›†ç´„ãƒ©ãƒ™ãƒ«ï¼ˆå„æœˆæœ«ã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã«æ´»å‹•ãŒã‚ã‚‹ã‹ï¼‰")
    logger.info("ç¶™ç¶šåˆ¤å®š: å±¥æ­´æœŸé–“å†…ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®ç¶™ç¶šã®ã¿ã‚’ã‚«ã‚¦ãƒ³ãƒˆ")
    if future_window_start_months > 0:
        logger.info(f"âš ï¸  ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: {future_window_start_months}ãƒ¶æœˆä»¥å†…ã®æ´»å‹•ã¯é™¤å¤–")
    logger.info("=" * 80)
    
    trajectories = []
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨
    if project and 'project' in df.columns:
        df = df[df['project'] == project].copy()
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œ: {len(df)}ä»¶")
    
    # å­¦ç¿’æœŸé–“å†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    train_df = df[(df[date_col] >= train_start) & (df[date_col] < train_end)]
    
    # å…¨ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’å–å¾—
    all_reviewers = train_df[reviewer_col].unique()
    logger.info(f"ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æ•°: {len(all_reviewers)}")
    
    reviewer_continuation_count = 0
    
    # å„ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ã¤ã„ã¦1ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆ
    for idx, reviewer in enumerate(all_reviewers):
        if (idx + 1) % 100 == 0:
            logger.info(f"å‡¦ç†ä¸­: {idx+1}/{len(all_reviewers)}")
        
        # ã“ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®å­¦ç¿’æœŸé–“å†…ã®å…¨æ´»å‹•
        reviewer_history = train_df[train_df[reviewer_col] == reviewer]
        
        # æœ€å°ã‚¤ãƒ™ãƒ³ãƒˆæ•°ã‚’æº€ãŸã•ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if len(reviewer_history) < min_history_events:
            continue
        
        # æ´»å‹•å±¥æ­´ã‚’æ™‚ç³»åˆ—é †ã«ä¸¦ã¹ã‚‹
        reviewer_history_sorted = reviewer_history.sort_values(date_col)
        
        # ã“ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®å…¨æ´»å‹•ï¼ˆå­¦ç¿’æœŸé–“å¤–ã‚‚å«ã‚€ï¼‰ã‚’æ™‚ç³»åˆ—é †ã«å–å¾—
        reviewer_all_activities = df[df[reviewer_col] == reviewer].sort_values(date_col)
        
        # å±¥æ­´æœŸé–“å†…ã§æ´»å‹•ã—ã¦ã„ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
        history_projects = set(reviewer_history_sorted['project'].dropna().unique())
        
        # æœˆã”ã¨ã«ãƒ©ãƒ™ãƒ«ã‚’è¨ˆç®—ï¼ˆæœˆæ¬¡é›†ç´„ãƒ©ãƒ™ãƒ«ï¼‰
        monthly_labels = {}
        
        for _, row in reviewer_history_sorted.iterrows():
            activity_date = pd.Timestamp(row[date_col])
            month_key = (activity_date.year, activity_date.month)
            
            if month_key not in monthly_labels:
                # ã“ã®æœˆã®æœ€çµ‚æ—¥
                month_end = (activity_date + pd.offsets.MonthEnd(0))
                
                # å°†æ¥çª“ã®ç¯„å›²ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
                future_start = month_end + pd.DateOffset(months=future_window_start_months)
                future_end = month_end + pd.DateOffset(months=future_window_end_months)
                
                # å°†æ¥çª“ãŒå­¦ç¿’æœŸé–“ã‚’è¶…ãˆã‚‹å ´åˆã¯None
                if future_end > train_end + pd.DateOffset(months=12):  # æœ€å¤§1å¹´å…ˆã¾ã§
                    monthly_labels[month_key] = None
                else:
                    # ã“ã®æœˆã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°çª“å†…ã«æ´»å‹•ãŒã‚ã‚‹ã‹ï¼ˆå±¥æ­´æœŸé–“å†…ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ï¼‰
                    future_activities = reviewer_all_activities[
                        (reviewer_all_activities[date_col] >= future_start) &
                        (reviewer_all_activities[date_col] < future_end) &
                        (reviewer_all_activities['project'].isin(history_projects))
                    ]
                    monthly_labels[month_key] = len(future_activities) > 0
        
        # æ´»å‹•å±¥æ­´ã‚’æ§‹ç¯‰ï¼ˆæ™‚ç³»åˆ—è¨“ç·´ç”¨ï¼‰
        activity_history = []
        step_labels = []
        
        for _, row in reviewer_history_sorted.iterrows():
            activity_date = pd.Timestamp(row[date_col])
            month_key = (activity_date.year, activity_date.month)
            
            # ã“ã®æœˆã®ãƒ©ãƒ™ãƒ«ãŒNoneã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if monthly_labels[month_key] is None:
                continue
            
            activity = {
                'timestamp': row[date_col],
                'action_type': 'review',
                'project': row.get('project', 'unknown'),
                'request_time': row.get('request_time', row[date_col]),  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“è¨ˆç®—ç”¨
            }
            activity_history.append(activity)
            step_labels.append(monthly_labels[month_key])
        
        # ãƒ©ãƒ™ãƒ«ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if not step_labels:
            continue
        
        # ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å˜ä½ã®ç¶™ç¶šåˆ¤å®šï¼ˆæœ€çµ‚æœˆã®ãƒ©ãƒ™ãƒ«ï¼‰
        final_month_label = step_labels[-1]
        if final_month_label:
            reviewer_continuation_count += 1
        
        # è»Œè·¡ã‚’ä½œæˆ
        developer_info = {
            'developer_email': reviewer
        }
        
        trajectory = {
            'developer_info': developer_info,
            'activity_history': activity_history,
            'context_date': train_end,  # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ—¥
            'step_labels': step_labels,  # æœˆæ¬¡é›†ç´„ãƒ©ãƒ™ãƒ«
            'seq_len': len(step_labels),
            'reviewer': reviewer,
            'history_count': len(reviewer_history)
        }
        
        trajectories.append(trajectory)
    
    logger.info("=" * 80)
    logger.info(f"è»Œè·¡æŠ½å‡ºå®Œäº†: {len(trajectories)}ã‚µãƒ³ãƒ—ãƒ«ï¼ˆãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ï¼‰")
    if trajectories:
        total_steps = sum(t['seq_len'] for t in trajectories)
        continued_steps = sum(sum(t['step_labels']) for t in trajectories)
        logger.info(f"  ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps}")
        logger.info(f"  ç¶™ç¶šã‚¹ãƒ†ãƒƒãƒ—ç‡: {continued_steps/total_steps*100:.1f}% ({continued_steps}/{total_steps})")
        logger.info(f"  ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å˜ä½ç¶™ç¶šç‡: {reviewer_continuation_count/len(trajectories)*100:.1f}% ({reviewer_continuation_count}/{len(trajectories)})")
    logger.info("=" * 80)
    
    return trajectories


def extract_cutoff_evaluation_trajectories(
    df: pd.DataFrame,
    cutoff_date: pd.Timestamp,
    history_window_months: int = 12,
    future_window_start_months: int = 0,
    future_window_end_months: int = 3,
    min_history_events: int = 3,
    reviewer_col: str = 'reviewer_email',
    date_col: str = 'request_time',
    project: str = None
) -> List[Dict[str, Any]]:
    """
    Cutoffæ™‚ç‚¹ã§ã®è©•ä¾¡ç”¨è»Œè·¡ã‚’æŠ½å‡ºï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ç”¨ï¼‰
    
    Args:
        df: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ­ã‚°
        cutoff_date: Cutoffæ—¥ï¼ˆé€šå¸¸ã¯è¨“ç·´çµ‚äº†æ—¥ï¼‰
        history_window_months: å±¥æ­´ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆãƒ¶æœˆï¼‰
        future_window_start_months: å°†æ¥çª“ã®é–‹å§‹ï¼ˆãƒ¶æœˆï¼‰
        future_window_end_months: å°†æ¥çª“ã®çµ‚äº†ï¼ˆãƒ¶æœˆï¼‰
        min_history_events: æœ€å°ã‚¤ãƒ™ãƒ³ãƒˆæ•°
        reviewer_col: ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚«ãƒ©ãƒ å
        date_col: æ—¥ä»˜ã‚«ãƒ©ãƒ å
        project: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆæŒ‡å®šæ™‚ã¯å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ï¼‰
    
    Returns:
        è»Œè·¡ãƒªã‚¹ãƒˆ
    """
    logger.info("=" * 80)
    logger.info("Cutoffè©•ä¾¡ç”¨è»Œè·¡æŠ½å‡ºã‚’é–‹å§‹ï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ç”¨ï¼‰")
    logger.info(f"Cutoffæ—¥: {cutoff_date}")
    logger.info(f"å±¥æ­´ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: {history_window_months}ãƒ¶æœˆ")
    logger.info(f"å°†æ¥çª“: {future_window_start_months}ï½{future_window_end_months}ãƒ¶æœˆ")
    if project:
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project} (å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ)")
    else:
        logger.info("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
    logger.info("ç¶™ç¶šåˆ¤å®š: å±¥æ­´æœŸé–“å†…ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®ç¶™ç¶šã®ã¿ã‚’ã‚«ã‚¦ãƒ³ãƒˆ")
    logger.info("=" * 80)
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨
    if project and 'project' in df.columns:
        df = df[df['project'] == project].copy()
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œ: {len(df)}ä»¶")
    
    trajectories = []
    
    # å±¥æ­´æœŸé–“
    history_start = cutoff_date - pd.DateOffset(months=history_window_months)
    history_end = cutoff_date
    
    # å°†æ¥çª“
    future_start = cutoff_date + pd.DateOffset(months=future_window_start_months)
    future_end = cutoff_date + pd.DateOffset(months=future_window_end_months)
    
    logger.info(f"å±¥æ­´æœŸé–“: {history_start} ï½ {history_end}")
    logger.info(f"å°†æ¥çª“: {future_start} ï½ {future_end}")
    
    # å±¥æ­´æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿
    history_df = df[
        (df[date_col] >= history_start) &
        (df[date_col] < history_end)
    ]
    
    # å°†æ¥æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿
    future_df = df[
        (df[date_col] >= future_start) &
        (df[date_col] < future_end)
    ]
    
    # å±¥æ­´æœŸé–“å†…ã«æ´»å‹•ãŒã‚ã£ãŸãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’å¯¾è±¡
    active_reviewers = history_df[reviewer_col].unique()
    logger.info(f"å±¥æ­´æœŸé–“å†…ã®æ´»å‹•ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æ•°: {len(active_reviewers)}")
    
    for reviewer in active_reviewers:
        # å±¥æ­´æœŸé–“ã®æ´»å‹•
        reviewer_history = history_df[history_df[reviewer_col] == reviewer]
        
        # æœ€å°ã‚¤ãƒ™ãƒ³ãƒˆæ•°ã‚’æº€ãŸã•ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if len(reviewer_history) < min_history_events:
            continue
        
        # å°†æ¥æœŸé–“ã®æ´»å‹•
        reviewer_future = future_df[future_df[reviewer_col] == reviewer]
        
        # ç¶™ç¶šãƒ©ãƒ™ãƒ«
        future_contribution = len(reviewer_future) > 0
        
        # æ´»å‹•å±¥æ­´ã‚’æ§‹ç¯‰
        activity_history = []
        for _, row in reviewer_history.iterrows():
            activity = {
                'timestamp': row[date_col],
                'action_type': 'review',
                'project': row.get('project', 'unknown'),
                'request_time': row.get('request_time', row[date_col]),  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“è¨ˆç®—ç”¨
            }
            activity_history.append(activity)
        
        # é–‹ç™ºè€…æƒ…å ±
        developer_info = {
            'developer_email': reviewer,
            'first_seen': reviewer_history[date_col].min(),
            'changes_authored': 0,
            'changes_reviewed': len(reviewer_history),
            'projects': reviewer_history['project'].unique().tolist() if 'project' in reviewer_history.columns else []
        }
        
        # è»Œè·¡ã‚’ä½œæˆ
        trajectory = {
            'developer': developer_info,
            'activity_history': activity_history,
            'context_date': cutoff_date,
            'future_contribution': future_contribution,
            'reviewer': reviewer,
            'history_count': len(reviewer_history),
            'future_count': len(reviewer_future)
        }
        
        trajectories.append(trajectory)
    
    # çµ±è¨ˆæƒ…å ±
    positive_count = sum(1 for t in trajectories if t['future_contribution'])
    positive_rate = positive_count / len(trajectories) if trajectories else 0
    
    logger.info("=" * 80)
    logger.info(f"è»Œè·¡æŠ½å‡ºå®Œäº†: {len(trajectories)}ã‚µãƒ³ãƒ—ãƒ«")
    logger.info(f"  ç¶™ç¶šç‡: {positive_rate:.1%} ({positive_count}/{len(trajectories)})")
    logger.info("=" * 80)
    
    return trajectories


def train_irl_model_temporal(
    trajectories: List[Dict[str, Any]],
    config: Dict[str, Any],
    epochs: int = 30
) -> RetentionIRLSystem:
    """
    æ™‚ç³»åˆ—è¨“ç·´ç‰ˆIRLãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
    
    Args:
        trajectories: æ™‚ç³»åˆ—è»Œè·¡ãƒ‡ãƒ¼ã‚¿
        config: ãƒ¢ãƒ‡ãƒ«è¨­å®š
        epochs: ã‚¨ãƒãƒƒã‚¯æ•°
        
    Returns:
        è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    """
    logger.info("=" * 80)
    logger.info("æ™‚ç³»åˆ—è¨“ç·´ç‰ˆIRLãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚’é–‹å§‹")
    logger.info(f"è»Œè·¡æ•°: {len(trajectories)}")
    logger.info(f"ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
    logger.info(f"ç›®æ¨™: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ç¶™ç¶šäºˆæ¸¬ã‚’å­¦ç¿’")
    logger.info("=" * 80)
    
    # IRLã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    irl_system = RetentionIRLSystem(config)
    
    # æ™‚ç³»åˆ—è¨“ç·´
    result = irl_system.train_irl_temporal_trajectories(
        expert_trajectories=trajectories,
        epochs=epochs
    )
    
    logger.info("=" * 80)
    logger.info(f"è¨“ç·´å®Œäº†: æœ€çµ‚æå¤± = {result['final_loss']:.4f}")
    logger.info("=" * 80)
    
    return irl_system


def evaluate_model_snapshot(
    irl_system: RetentionIRLSystem,
    eval_trajectories: List[Dict[str, Any]]
) -> tuple[Dict[str, float], List[Dict[str, Any]]]:
    """
    ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ã§ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
    
    Args:
        irl_system: è¨“ç·´æ¸ˆã¿IRLã‚·ã‚¹ãƒ†ãƒ 
        eval_trajectories: è©•ä¾¡ç”¨è»Œè·¡ãƒ‡ãƒ¼ã‚¿
        
    Returns:
        (è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹, äºˆæ¸¬è©³ç´°ã®ãƒªã‚¹ãƒˆ)
    """
    logger.info("=" * 80)
    logger.info("ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ã§ãƒ¢ãƒ‡ãƒ«è©•ä¾¡é–‹å§‹")
    logger.info(f"è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(eval_trajectories)}")
    logger.info("=" * 80)
    
    # äºˆæ¸¬
    predictions = []
    true_labels = []
    prediction_details = []
    
    for trajectory in eval_trajectories:
        # developer_info ã‹ã‚‰ developer_email ã‚’å–å¾—
        developer = trajectory.get('developer', trajectory.get('developer_info', {}))
        if isinstance(developer, dict):
            reviewer_email = developer.get('developer_email', 'unknown')
            activity_count = len(trajectory['activity_history'])
        else:
            reviewer_email = 'unknown'
            activity_count = len(trajectory['activity_history'])
        
        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ã§äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—
        developer = trajectory.get('developer', {})
        activity_history = trajectory.get('activity_history', [])
        context_date = trajectory.get('context_date', None)
        
        result = irl_system.predict_continuation_probability_snapshot(
            developer=developer,
            activity_history=activity_history,
            context_date=context_date
        )
        prob = result.get('continuation_probability', 0.0)
        
        # çœŸã®ãƒ©ãƒ™ãƒ«ã‚’å–å¾—
        true_label = trajectory.get('future_contribution', False)
        
        predictions.append(prob)
        true_labels.append(1 if true_label else 0)
        
        prediction_details.append({
            'reviewer_email': reviewer_email,
            'predicted_prob': prob,
            'true_label': 1 if true_label else 0,
            'activity_count': activity_count,
            'reasoning': result.get('reasoning', ''),
            'confidence': result.get('confidence', 0.0)
        })
    
    # è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    from sklearn.metrics import (
        auc,
        f1_score,
        precision_recall_curve,
        precision_score,
        recall_score,
        roc_auc_score,
    )
    
    if len(set(true_labels)) > 1:  # æ­£ä¾‹ã¨è² ä¾‹ãŒä¸¡æ–¹å­˜åœ¨ã™ã‚‹å ´åˆ
        auc_roc = roc_auc_score(true_labels, predictions)
        precision, recall, thresholds = precision_recall_curve(true_labels, predictions)
        auc_pr = auc(recall, precision)
        
        # æœ€é©é–¾å€¤ï¼ˆF1ã‚¹ã‚³ã‚¢ãŒæœ€å¤§ï¼‰
        f1_scores = [f1_score(true_labels, [1 if p >= t else 0 for p in predictions]) for t in thresholds]
        optimal_threshold = thresholds[np.argmax(f1_scores)]
        
        # æœ€é©é–¾å€¤ã§ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        binary_predictions = [1 if p >= optimal_threshold else 0 for p in predictions]
        precision_val = precision_score(true_labels, binary_predictions)
        recall_val = recall_score(true_labels, binary_predictions)
        f1_val = f1_score(true_labels, binary_predictions)
        
        metrics = {
            'auc_roc': auc_roc,
            'auc_pr': auc_pr,
            'precision': precision_val,
            'recall': recall_val,
            'f1_score': f1_val,
            'optimal_threshold': optimal_threshold,
            'continuation_rate': sum(true_labels) / len(true_labels)
        }
    else:
        metrics = {
            'auc_roc': 0.5,
            'auc_pr': sum(true_labels) / len(true_labels),
            'precision': 0.0,
            'recall': 0.0,
            'f1_score': 0.0,
            'optimal_threshold': 0.5,
            'continuation_rate': sum(true_labels) / len(true_labels)
        }
    
    logger.info("=" * 80)
    logger.info("è©•ä¾¡å®Œäº†")
    logger.info(f"AUC-ROC: {metrics['auc_roc']:.4f}")
    logger.info(f"AUC-PR: {metrics['auc_pr']:.4f}")
    logger.info(f"Precision: {metrics['precision']:.4f}")
    logger.info(f"Recall: {metrics['recall']:.4f}")
    logger.info(f"F1-Score: {metrics['f1_score']:.4f}")
    logger.info(f"ç¶™ç¶šç‡: {metrics['continuation_rate']:.1%}")
    logger.info("=" * 80)
    
    return metrics, prediction_details


def main():
    parser = argparse.ArgumentParser(description='ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦IRLè¨“ç·´ãƒ»è©•ä¾¡')
    parser.add_argument('--reviews', type=str, required=True,
                        help='ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ­ã‚°CSVãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--train-start', type=str, required=True,
                        help='å­¦ç¿’é–‹å§‹æ—¥ (YYYY-MM-DD)')
    parser.add_argument('--train-end', type=str, required=True,
                        help='å­¦ç¿’çµ‚äº†æ—¥ (YYYY-MM-DD)')
    parser.add_argument('--eval-start', type=str, required=True,
                        help='è©•ä¾¡é–‹å§‹æ—¥ (YYYY-MM-DD)')
    parser.add_argument('--eval-end', type=str, required=True,
                        help='è©•ä¾¡çµ‚äº†æ—¥ (YYYY-MM-DD)')
    parser.add_argument('--future-window-start', type=int, default=0,
                        help='å°†æ¥çª“é–‹å§‹ï¼ˆæœˆæ•°ï¼‰')
    parser.add_argument('--future-window-end', type=int, default=3,
                        help='å°†æ¥çª“çµ‚äº†ï¼ˆæœˆæ•°ï¼‰')
    parser.add_argument('--eval-future-window-start', type=int, default=None,
                        help='è©•ä¾¡ç”¨å°†æ¥çª“é–‹å§‹ï¼ˆæœˆæ•°ï¼‰')
    parser.add_argument('--eval-future-window-end', type=int, default=None,
                        help='è©•ä¾¡ç”¨å°†æ¥çª“çµ‚äº†ï¼ˆæœˆæ•°ï¼‰')
    parser.add_argument('--epochs', type=int, default=20,
                        help='è¨“ç·´ã‚¨ãƒãƒƒã‚¯æ•°')
    parser.add_argument('--min-history-events', type=int, default=3,
                        help='æœ€å°å±¥æ­´ã‚¤ãƒ™ãƒ³ãƒˆæ•°')
    parser.add_argument('--output', type=str, required=True,
                        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--project', type=str, default=None,
                        help='ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆæŒ‡å®šæ™‚ã¯å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ï¼‰')
    parser.add_argument('--model', type=str, default=None,
                        help='æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæŒ‡å®šæ™‚ã¯è©•ä¾¡ã®ã¿ï¼‰')
    
    args = parser.parse_args()
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ—¥ä»˜å¤‰æ›
    train_start = pd.Timestamp(args.train_start)
    train_end = pd.Timestamp(args.train_end)
    eval_start = pd.Timestamp(args.eval_start)
    eval_end = pd.Timestamp(args.eval_end)
    
    # è©•ä¾¡ç”¨å°†æ¥çª“ï¼ˆæŒ‡å®šãŒãªã„å ´åˆã¯è¨“ç·´ã¨åŒã˜ï¼‰
    eval_future_window_start = args.eval_future_window_start if args.eval_future_window_start is not None else args.future_window_start
    eval_future_window_end = args.eval_future_window_end if args.eval_future_window_end is not None else args.future_window_end
    
    logger.info("=" * 80)
    logger.info("ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦IRLè¨“ç·´ãƒ»è©•ä¾¡")
    logger.info("=" * 80)
    logger.info(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿: {args.reviews}")
    logger.info(f"å­¦ç¿’æœŸé–“: {train_start} ï½ {train_end}")
    logger.info(f"è©•ä¾¡æœŸé–“: {eval_start} ï½ {eval_end}")
    logger.info(f"è¨“ç·´ãƒ©ãƒ™ãƒ«: {args.future_window_start}-{args.future_window_end}m")
    logger.info(f"è©•ä¾¡æœŸé–“: {eval_future_window_start}-{eval_future_window_end}m")
    if args.project:
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {args.project}")
    logger.info("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_review_logs(args.reviews)
    
    # ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆæ™‚é–“ç‰¹å¾´é‡é™¤å¤–ç‰ˆï¼‰
    config = {
        'state_dim': 9,   # æ™‚é–“çµŒéã‚’é™¤å¤–ï¼ˆ10â†’9ï¼‰
        'action_dim': 4,  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’å«ã‚€ï¼ˆ3â†’4ï¼‰
        'hidden_dim': 128,
        'learning_rate': 0.0001,
        'sequence': True,
        'seq_len': 0,  # å¯å¤‰é•·
    }
    logger.info(f"ğŸ”§ Config: state_dim={config['state_dim']}, action_dim={config['action_dim']}")
    
    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¾ãŸã¯èª­ã¿è¾¼ã¿
    if args.model and Path(args.model).exists():
        # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        logger.info(f"æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰: {args.model}")
        irl_system = RetentionIRLSystem.load_model(args.model)
        model_path = Path(args.model)
    else:
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼‰
        train_trajectories = extract_sliding_window_trajectories(
            df,
            train_start=train_start,
            train_end=train_end,
            future_window_start_months=args.future_window_start,
            future_window_end_months=args.future_window_end,
            min_history_events=args.min_history_events,
            project=args.project,
        )
        
        if not train_trajectories:
            logger.error("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆæ™‚ç³»åˆ—ï¼‰
        irl_system = train_irl_model_temporal(
            train_trajectories,
            config,
            epochs=args.epochs
        )
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        model_path = output_dir / 'irl_model.pt'
        irl_system.save_model(str(model_path))
        logger.info(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")
    
    # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
    eval_trajectories = extract_cutoff_evaluation_trajectories(
        df,
        cutoff_date=eval_start,
        history_window_months=12,
        future_window_start_months=eval_future_window_start,
        future_window_end_months=eval_future_window_end,
        min_history_events=args.min_history_events,
        project=args.project,
    )
    
    if not eval_trajectories:
        logger.error("è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç‰¹å¾´é‡ï¼‰
    metrics, prediction_details = evaluate_model_snapshot(irl_system, eval_trajectories)
    
    # çµæœä¿å­˜
    metrics_path = output_dir / 'metrics.json'
    with open(metrics_path, 'w') as f:
        json.dump(metrics, f, indent=2)
    logger.info(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜: {metrics_path}")
    
    # äºˆæ¸¬è©³ç´°ã‚’ä¿å­˜
    if prediction_details:
        predictions_df = pd.DataFrame(prediction_details)
        predictions_df['predicted_binary'] = (predictions_df['predicted_prob'] >= metrics['optimal_threshold']).astype(int)
        predictions_path = output_dir / 'predictions.csv'
        predictions_df.to_csv(predictions_path, index=False)
        logger.info(f"äºˆæ¸¬è©³ç´°ä¿å­˜: {predictions_path}")
    
    logger.info("=" * 80)
    logger.info("å®Œäº†ï¼")
    logger.info("=" * 80)


if __name__ == '__main__':
    main()
