#!/usr/bin/env python3
"""
æ‹¡å¼µIRL ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç‰ˆè¨“ç·´ãƒ»è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

train_irl_sliding_window.py ã®æ‹¡å¼µIRLç‰ˆ
- çŠ¶æ…‹ç‰¹å¾´é‡: 32æ¬¡å…ƒ
- è¡Œå‹•ç‰¹å¾´é‡: 9æ¬¡å…ƒ
- ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãƒ©ãƒ™ãƒ«ï¼ˆä¾‹: 0-3m, 3-6m, 6-9m, 9-12mï¼‰
"""
from __future__ import annotations

import argparse
import json
import logging
import pickle
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

import numpy as np
import pandas as pd
import torch
from sklearn.metrics import (
    auc,
    f1_score,
    precision_recall_curve,
    precision_score,
    recall_score,
    roc_auc_score,
)

ROOT = Path(__file__).resolve().parents[3]
SRC = ROOT / "src"
if str(SRC) not in sys.path:
    sys.path.append(str(SRC))

from gerrit_retention.rl_prediction.enhanced_retention_irl_system import (
    EnhancedRetentionIRLSystem,
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_review_logs(csv_path: str) -> pd.DataFrame:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ­ã‚°ã‚’CSVã‹ã‚‰èª­ã¿è¾¼ã¿"""
    logger.info(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿ä¸­: {csv_path}")
    df = pd.read_csv(csv_path)
    df['request_time'] = pd.to_datetime(df['request_time'])
    logger.info(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ­ã‚°èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}ä»¶")
    logger.info(f"æœŸé–“: {df['request_time'].min()} ï½ {df['request_time'].max()}")
    return df


# def extract_sliding_window_trajectories(
#     df: pd.DataFrame,
#     train_start: pd.Timestamp,
#     train_end: pd.Timestamp,
#     future_window_start_months: int = 0,
#     future_window_end_months: int = 3,
#     min_history_events: int = 3,
#     reviewer_col: str = 'reviewer_email',
#     date_col: str = 'request_time',
#     project: str = None
# ) -> List[Dict[str, Any]]:
#     """
#     ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç‰ˆï¼šå…¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼‹æœˆæ¬¡é›†ç´„ãƒ©ãƒ™ãƒ«ä»˜ãè»Œè·¡ã‚’æŠ½å‡ºï¼ˆæ‹¡å¼µIRLç”¨ï¼‰
#     
#     train_irl_sliding_window.py ã® extract_sliding_window_trajectories ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯
#     """
#    logger.info("=" * 80)
#    logger.info("æ‹¡å¼µIRL ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç‰ˆï¼šå…¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼‹æœˆæ¬¡é›†ç´„ãƒ©ãƒ™ãƒ«ä»˜ãè»Œè·¡æŠ½å‡ºã‚’é–‹å§‹")
#    logger.info(f"å­¦ç¿’æœŸé–“: {train_start} ï½ {train_end}")
#    logger.info(f"å°†æ¥çª“: {future_window_start_months}ï½{future_window_end_months}ãƒ¶æœˆï¼ˆã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ï¼‰")
#    if project:
#        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project} (å˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ)")
#    else:
#        logger.info("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
#    logger.info("=" * 80)
#    
#    trajectories = []
#    
#    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨
#    if project and 'project' in df.columns:
#        df = df[df['project'] == project].copy()
#        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œ: {len(df)}ä»¶")
#    
#    # è©•ä¾¡æœŸé–“å†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆè©•ä¾¡æ™‚ã¯è©•ä¾¡æœŸé–“ã‚’ä½¿ç”¨ï¼‰
#    eval_end = pd.Timestamp('2024-04-01')  # è©•ä¾¡æœŸé–“ã®çµ‚äº†æ—¥
#    train_df = df[(df[date_col] >= train_start) & (df[date_col] < eval_end)]
#    
#    # å…¨ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’å–å¾—
#    all_reviewers = train_df[reviewer_col].unique()
#    logger.info(f"ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æ•°: {len(all_reviewers)}")
#    
#    reviewer_continuation_count = 0
#    
#    # å„ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ã¤ã„ã¦1ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆ
#    for idx, reviewer in enumerate(all_reviewers):
#        if (idx + 1) % 100 == 0:
#            logger.info(f"å‡¦ç†ä¸­: {idx+1}/{len(all_reviewers)}")
#        
#        # ã“ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®å­¦ç¿’æœŸé–“å†…ã®å…¨æ´»å‹•
#        reviewer_history = train_df[train_df[reviewer_col] == reviewer]
#        
#        # æœ€å°ã‚¤ãƒ™ãƒ³ãƒˆæ•°ã‚’æº€ãŸã•ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
#        if len(reviewer_history) < min_history_events:
#            continue
#        
#        # æ´»å‹•å±¥æ­´ã‚’æ™‚ç³»åˆ—é †ã«ä¸¦ã¹ã‚‹
#        reviewer_history_sorted = reviewer_history.sort_values(date_col)
#        
#        # ã“ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®å…¨æ´»å‹•ï¼ˆå­¦ç¿’æœŸé–“å¤–ã‚‚å«ã‚€ï¼‰ã‚’æ™‚ç³»åˆ—é †ã«å–å¾—
#        reviewer_all_activities = df[df[reviewer_col] == reviewer].sort_values(date_col)
#        
#        # å±¥æ­´æœŸé–“å†…ã§æ´»å‹•ã—ã¦ã„ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
#        history_projects = set(reviewer_history_sorted['project'].dropna().unique())
#        
#        # æœˆã”ã¨ã«ãƒ©ãƒ™ãƒ«ã‚’è¨ˆç®—
#        monthly_labels = {}
#        
#        for _, row in reviewer_history_sorted.iterrows():
#            activity_date = pd.Timestamp(row[date_col])
#            month_key = (activity_date.year, activity_date.month)
#            
#            if month_key not in monthly_labels:
#                # ã“ã®æœˆã®æœ€çµ‚æ—¥
#                month_end = (activity_date + pd.offsets.MonthEnd(0))
#                
#                # å°†æ¥çª“ã®ç¯„å›²ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
#                future_start = month_end + pd.DateOffset(months=future_window_start_months)
#                future_end = month_end + pd.DateOffset(months=future_window_end_months)
#                
#                # å°†æ¥çª“ãŒè©•ä¾¡æœŸé–“ã‚’è¶…ãˆã‚‹å ´åˆã¯Noneï¼ˆå­¦ç¿’æœŸé–“ã§ã¯ãªãè©•ä¾¡æœŸé–“ã§åˆ¤å®šï¼‰
#                eval_end = pd.Timestamp('2024-04-01')  # è©•ä¾¡æœŸé–“ã®çµ‚äº†æ—¥
#                if future_end > eval_end:
#                    monthly_labels[month_key] = None
#                else:
#                    # ã“ã®æœˆã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°çª“å†…ã«æ´»å‹•ãŒã‚ã‚‹ã‹ï¼ˆå±¥æ­´æœŸé–“å†…ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ï¼‰
#                    future_activities = reviewer_all_activities[
#                        (reviewer_all_activities[date_col] >= future_start) &
#                        (reviewer_all_activities[date_col] < future_end) &
#                        (reviewer_all_activities['project'].isin(history_projects))
#                    ]
#                    monthly_labels[month_key] = len(future_activities) > 0
#        
#        # æ´»å‹•å±¥æ­´ã‚’æ§‹ç¯‰
#        activity_history = []
#        step_labels = []
#        
#        for _, row in reviewer_history_sorted.iterrows():
#            activity_date = pd.Timestamp(row[date_col])
#            month_key = (activity_date.year, activity_date.month)
#            
#            # ã“ã®æœˆã®ãƒ©ãƒ™ãƒ«ãŒNoneã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
#            if monthly_labels[month_key] is None:
#                continue
#            
#            activity = {
#                'timestamp': row[date_col],
#                'action_type': 'review',
#                'project': row.get('project', 'unknown'),
#            }
#            activity_history.append(activity)
#            step_labels.append(monthly_labels[month_key])
#        
#        # ãƒ©ãƒ™ãƒ«ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
#        if not step_labels:
#            continue
#        
#        # ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å˜ä½ã®ç¶™ç¶šåˆ¤å®šï¼ˆæœ€çµ‚æœˆã®ãƒ©ãƒ™ãƒ«ï¼‰
#        final_month_label = step_labels[-1]
#        if final_month_label:
#            reviewer_continuation_count += 1
#        
#        # è»Œè·¡ã‚’ä½œæˆ
#        developer_info = {
#            'developer_email': reviewer
#        }
#        
#        trajectory = {
#            'developer_info': developer_info,
#            'activity_history': activity_history,
#            'context_date': train_end,  # å›ºå®šæ™‚ç‚¹
#            'step_labels': step_labels,
#            'seq_len': len(step_labels)
#        }
#        
#        trajectories.append(trajectory)
#    
#    logger.info("=" * 80)
#    logger.info(f"è»Œè·¡æŠ½å‡ºå®Œäº†: {len(trajectories)}ã‚µãƒ³ãƒ—ãƒ«ï¼ˆãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ï¼‰")
#    if trajectories:
#        total_steps = sum(t['seq_len'] for t in trajectories)
#        continued_steps = sum(sum(t['step_labels']) for t in trajectories)
#        logger.info(f"  ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps}")
#        logger.info(f"  ç¶™ç¶šã‚¹ãƒ†ãƒƒãƒ—ç‡: {continued_steps/total_steps*100:.1f}% ({continued_steps}/{total_steps})")
#        logger.info(f"  ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å˜ä½ç¶™ç¶šç‡: {reviewer_continuation_count/len(trajectories)*100:.1f}% ({reviewer_continuation_count}/{len(trajectories)})")
#    logger.info("=" * 80)
#    
##     return trajectories


def train_irl_model_multi_step(
    trajectories: List[Dict[str, Any]],
    config: Dict[str, Any],
    epochs: int = 30
) -> EnhancedRetentionIRLSystem:
    """
    å„ã‚¹ãƒ†ãƒƒãƒ—ãƒ©ãƒ™ãƒ«ä»˜ãæ‹¡å¼µIRLãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
    """
    logger.info("=" * 80)
    logger.info("æ‹¡å¼µIRLè¨“ç·´é–‹å§‹")
    logger.info(f"è»Œè·¡æ•°: {len(trajectories)}")
    logger.info(f"ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
    logger.info("=" * 80)
    
    # IRLã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    irl_system = EnhancedRetentionIRLSystem(config)
    
    # è¨“ç·´
    result = irl_system.train_irl_multi_step_labels(
        expert_trajectories=trajectories,
        epochs=epochs
    )
    
    logger.info("=" * 80)
    logger.info(f"è¨“ç·´å®Œäº†: æœ€çµ‚æå¤± = {result['final_loss']:.4f}")
    logger.info("=" * 80)
    
    return irl_system


def find_optimal_threshold(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
    """æœ€é©ãªé–¾å€¤ã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆF1ã‚¹ã‚³ã‚¢ã‚’æœ€å¤§åŒ–ï¼‰"""
    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)
    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)
    
    best_idx = np.argmax(f1_scores)
    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5
    
    return {
        'threshold': float(best_threshold),
        'f1': float(f1_scores[best_idx]),
        'precision': float(precision[best_idx]),
        'recall': float(recall[best_idx])
    }


def evaluate_model(
    irl_system: EnhancedRetentionIRLSystem,
    trajectories: List[Dict[str, Any]],
    optimal_threshold: float = 0.5
) -> Dict[str, Any]:
    """ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡"""
    logger.info(f"è©•ä¾¡é–‹å§‹: {len(trajectories)}ã‚µãƒ³ãƒ—ãƒ«")
    
    y_true = []
    y_pred = []
    
    for traj in trajectories:
        developer = traj.get('developer_info', traj.get('developer', {}))
        activity_history = traj['activity_history']
        context_date = traj['context_date']
        step_labels = traj.get('step_labels', [])
        
        if not activity_history:
            continue
        
        # cutoffè©•ä¾¡ã§ã¯ future_contribution ã‚’ä½¿ç”¨
        future_contribution = traj.get('future_contribution', False)
        
        # äºˆæ¸¬
        try:
            result = irl_system.predict_continuation_probability(
                developer=developer,
                activity_history=activity_history,
                context_date=context_date
            )
            prob = result['continuation_probability']
            
            y_true.append(1 if future_contribution else 0)
            y_pred.append(prob)
            
        except Exception as e:
            logger.warning(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    if len(y_true) == 0:
        logger.warning("è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«ãŒ0ä»¶ã§ã™")
        return {
            'auc_roc': 0.0,
            'auc_pr': 0.0,
            'f1': 0.0,
            'precision': 0.0,
            'recall': 0.0,
            'optimal_threshold': 0.5,
            'sample_count': 0,
            'continuation_rate': 0.0
        }
    
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    auc_roc = roc_auc_score(y_true, y_pred)
    
    precision, recall, _ = precision_recall_curve(y_true, y_pred)
    auc_pr = auc(recall, precision)
    
    # é–¾å€¤é©ç”¨
    y_pred_binary = (y_pred >= optimal_threshold).astype(int)
    
    f1 = f1_score(y_true, y_pred_binary)
    precision_val = precision_score(y_true, y_pred_binary, zero_division=0)
    recall_val = recall_score(y_true, y_pred_binary, zero_division=0)
    
    continuation_rate = np.mean(y_true)
    
    logger.info(f"è©•ä¾¡å®Œäº†: AUC-ROC={auc_roc:.3f}, AUC-PR={auc_pr:.3f}, F1={f1:.3f}, Precision={precision_val:.3f}, Recall={recall_val:.3f}")
    logger.info(f"ç¶™ç¶šç‡: {continuation_rate:.1%} ({np.sum(y_true)}/{len(y_true)})")
    
    return {
        'auc_roc': float(auc_roc),
        'auc_pr': float(auc_pr),
        'f1': float(f1),
        'precision': float(precision_val),
        'recall': float(recall_val),
        'optimal_threshold': float(optimal_threshold),
        'sample_count': int(len(y_true)),
        'continuation_rate': float(continuation_rate)
    }


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--reviews', required=True, help='ãƒ¬ãƒ“ãƒ¥ãƒ¼CSVãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--train-start', required=True, help='è¨“ç·´é–‹å§‹æ—¥')
    parser.add_argument('--train-end', required=True, help='è¨“ç·´çµ‚äº†æ—¥')
    parser.add_argument('--eval-start', required=True, help='è©•ä¾¡é–‹å§‹æ—¥')
    parser.add_argument('--eval-end', required=True, help='è©•ä¾¡çµ‚äº†æ—¥')
    parser.add_argument('--future-window-start', type=int, required=True)
    parser.add_argument('--future-window-end', type=int, required=True)
    parser.add_argument('--eval-future-window-start', type=int, default=None)
    parser.add_argument('--eval-future-window-end', type=int, default=None)
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--min-history-events', type=int, default=3)
    parser.add_argument('--output', default='enhanced_irl_model.pt')
    parser.add_argument('--project', default=None, help='ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆå˜ä¸€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨ï¼‰')
    parser.add_argument('--model', default=None, help='æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ï¼ˆè©•ä¾¡ã®ã¿ï¼‰')
    
    args = parser.parse_args()
    
    # æ—¥ä»˜å¤‰æ›
    train_start = pd.Timestamp(args.train_start)
    train_end = pd.Timestamp(args.train_end)
    eval_start = pd.Timestamp(args.eval_start)
    eval_end = pd.Timestamp(args.eval_end)
    
    # è©•ä¾¡ç”¨ã®å°†æ¥çª“ï¼ˆæŒ‡å®šãŒãªã‘ã‚Œã°è¨“ç·´ã¨åŒã˜ï¼‰
    eval_future_start = args.eval_future_window_start if args.eval_future_window_start is not None else args.future_window_start
    eval_future_end = args.eval_future_window_end if args.eval_future_window_end is not None else args.future_window_end
    
    logger.info("=" * 80)
    logger.info("æ‹¡å¼µIRL ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨“ç·´ãƒ»è©•ä¾¡")
    logger.info("=" * 80)
    logger.info(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿: {args.reviews}")
    logger.info(f"å­¦ç¿’æœŸé–“: {train_start} ï½ {train_end}")
    logger.info(f"è©•ä¾¡æœŸé–“: {eval_start} ï½ {eval_end}")
    logger.info(f"è¨“ç·´ãƒ©ãƒ™ãƒ«: {args.future_window_start}-{args.future_window_end}m")
    logger.info(f"è©•ä¾¡æœŸé–“: {eval_future_start}-{eval_future_end}m")
    if args.project:
        logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {args.project}")
    logger.info("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_review_logs(args.reviews)
    
    # ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆæ‹¡å¼µIRLï¼‰
    config = {
        'state_dim': 32,   # æ‹¡å¼µç‰¹å¾´é‡
        'action_dim': 9,   # æ‹¡å¼µç‰¹å¾´é‡
        'hidden_dim': 128,
        'learning_rate': 0.0001,
        'sequence': True,
        'seq_len': 0,  # å¯å¤‰é•·
    }
    logger.info(f"ğŸ”§ Config: state_dim={config['state_dim']}, action_dim={config['action_dim']}")
    
    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¾ãŸã¯èª­ã¿è¾¼ã¿
    if args.model and Path(args.model).exists():
        # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        logger.info(f"æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰: {args.model}")
        irl_system = EnhancedRetentionIRLSystem.load_model(args.model)
        logger.info("ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
    else:
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆcutoffæ™‚ç‚¹ã§ã®è©•ä¾¡ï¼‰
        from train_irl_within_training_period import (
            extract_cutoff_evaluation_trajectories,
        )
        train_trajectories = extract_cutoff_evaluation_trajectories(
            df,
            cutoff_date=train_end,
            history_window_months=12,
            future_window_start_months=args.future_window_start,
            future_window_end_months=args.future_window_end,
            min_history_events=args.min_history_events,
            project=args.project,
        )
        
        if len(train_trajectories) == 0:
            logger.error("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶ã§ã™")
            return
        
        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        irl_system = train_irl_model_multi_step(
            trajectories=train_trajectories,
            config=config,
            epochs=args.epochs
        )
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        irl_system.save_model(str(output_path))
        logger.info(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {output_path}")
    
    # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆcutoffæ™‚ç‚¹ã§ã®è©•ä¾¡ï¼‰
    from train_irl_within_training_period import extract_cutoff_evaluation_trajectories
    eval_trajectories = extract_cutoff_evaluation_trajectories(
        df,
        cutoff_date=eval_start,
        history_window_months=12,
        future_window_start_months=eval_future_start,
        future_window_end_months=eval_future_end,
        min_history_events=args.min_history_events,
        project=args.project,
    )
    
    if len(eval_trajectories) == 0:
        logger.warning("è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶ã§ã™")
        return
    
    # æœ€é©é–¾å€¤ã‚’è¦‹ã¤ã‘ã‚‹
    logger.info("æœ€é©é–¾å€¤ã‚’è¨ˆç®—ä¸­...")
    y_true_thresh = []
    y_pred_thresh = []
    
    for traj in eval_trajectories:
        try:
            result = irl_system.predict_continuation_probability(
                developer=traj['developer_info'],
                activity_history=traj['activity_history'],
                context_date=traj['context_date']
            )
            y_true_thresh.append(1 if traj['step_labels'][-1] else 0)
            y_pred_thresh.append(result['continuation_probability'])
        except:
            continue
    
    if len(y_true_thresh) > 0:
        threshold_info = find_optimal_threshold(np.array(y_true_thresh), np.array(y_pred_thresh))
        optimal_threshold = threshold_info['threshold']
        logger.info(f"æœ€é©é–¾å€¤: {optimal_threshold:.3f} (F1={threshold_info['f1']:.3f})")
    else:
        optimal_threshold = 0.5
    
    # è©•ä¾¡
    metrics = evaluate_model(irl_system, eval_trajectories, optimal_threshold)
    
    # çµæœä¿å­˜
    output_path = Path(args.output)
    if output_path.suffix == '.pt':
        metrics_path = output_path.parent / 'metrics.json'
    else:
        metrics_path = Path(args.output).with_suffix('.json') if not args.output.endswith('.json') else Path(args.output)
    
    metrics_path.parent.mkdir(parents=True, exist_ok=True)
    with open(metrics_path, 'w') as f:
        json.dump(metrics, f, indent=2)
    
    logger.info(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜: {metrics_path}")
    logger.info("=" * 80)
    logger.info("å®Œäº†ï¼")
    logger.info("=" * 80)


if __name__ == "__main__":
    main()


