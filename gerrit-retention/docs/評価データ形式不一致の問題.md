# 評価データ形式不一致の問題

## 🚨 根本原因

訓練時と評価時でデータ形式が異なっているため、モデルが正しく予測できていない。

### 訓練時のデータ形式

**関数**: `extract_sliding_window_trajectories`
- **月次集約**: 各月の活動をまとめる
- **ラベル**: 各月の最終日から将来窓内に活動があるか
- **シーケンス**: 月単位（例: 12ヶ月 = 12ステップ）
- **activity_history**: 月ごとにまとめられた活動

```python
# 訓練データの構造
trajectory = {
    'activity_history': [
        {'timestamp': '2022-01-31', 'type': 'review', ...},  # 1月の活動（複数をまとめる）
        {'timestamp': '2022-02-28', 'type': 'review', ...},  # 2月の活動
        ...
    ],  # 月単位（12個）
    'step_labels': [True, True, False, ...],  # 各月のラベル
}
```

### 評価時のデータ形式

**関数**: `extract_cutoff_evaluation_trajectories`
- **月次集約なし**: 全活動を個別に保持
- **シーケンス**: 活動単位（例: 457件の活動 = 457ステップ）
- **activity_history**: 全活動がそのまま

```python
# 評価データの構造
trajectory = {
    'activity_history': [
        {'timestamp': '2022-01-01', 'type': 'review', ...},  # 個別の活動1
        {'timestamp': '2022-01-05', 'type': 'review', ...},  # 個別の活動2
        {'timestamp': '2022-01-10', 'type': 'review', ...},  # 個別の活動3
        ...  # 457個の個別活動
    ],
    'future_contribution': True,  # レビュアー全体のラベル
}
```

---

## 📊 なぜこれが問題なのか

### 問題1: シーケンス長の不一致

```
訓練時: 12ステップ（月単位）
評価時: 457ステップ（活動単位）

→ LSTMが想定外の長さを受け取る
→ モデルが混乱
```

### 問題2: 特徴量の意味が異なる

```python
# 訓練時（月次集約）
extract_developer_state(developer, month_activities, month_end_date)
→ その月までの累積統計

# 評価時（活動単位）
extract_developer_state(developer, activity_history[:i+1], fixed_context_date)
→ i番目の活動までの統計
→ context_dateが固定（2023-01-01）で意味をなさない
```

### 問題3: 予測確率が0.47に固定される理由

```python
# 評価時の予測ロジック
for i in range(457):  # 各活動について
    step_history = activity_history[:i+1]
    step_state = extract_developer_state(developer, step_history, 2023-01-01)
    # → context_dateが固定で、履歴も細かすぎる
    # → 特徴量が正しく計算されない
    # → モデルが全員を「同じ」と判断
    # → 予測確率が0.47前後に収束
```

---

## ✅ 解決策

### Option A: 評価データも月次集約する（推奨）

```python
def extract_cutoff_evaluation_trajectories_monthly(
    df: pd.DataFrame,
    cutoff_date: pd.Timestamp,
    history_window_months: int = 12,
    future_window_start_months: int = 0,
    future_window_end_months: int = 3,
    ...
):
    """
    訓練時と同じ月次集約形式で評価データを抽出
    """
    # 履歴期間を月単位に分割
    history_start = cutoff_date - pd.DateOffset(months=history_window_months)
    
    for reviewer in active_reviewers:
        # 月ごとの活動を集約
        monthly_activities = {}
        for _, row in reviewer_history.iterrows():
            month_key = (row[date_col].year, row[date_col].month)
            if month_key not in monthly_activities:
                monthly_activities[month_key] = []
            monthly_activities[month_key].append(row)
        
        # 月次の activity_history を構築
        activity_history = []
        for month_key in sorted(monthly_activities.keys()):
            month_activities = monthly_activities[month_key]
            # 月の最終活動を代表として使用
            last_activity = month_activities[-1]
            activity_history.append({
                'timestamp': last_activity[date_col],
                'action_type': 'review',
                'project': last_activity['project'],
                'monthly_count': len(month_activities),  # この月の活動数
            })
        
        # レビュアー全体のラベル
        future_contribution = len(reviewer_future) > 0
        
        trajectory = {
            'developer': developer_info,
            'activity_history': activity_history,  # 月次集約
            'context_date': cutoff_date,
            'future_contribution': future_contribution,
        }
        trajectories.append(trajectory)
```

### Option B: 予測時に月次集約を行う（複雑）

```python
def predict_continuation_probability(...):
    # activity_historyを月次に集約
    monthly_activities = aggregate_by_month(activity_history)
    
    # 月次集約された履歴で予測
    ...
```

### Option C: 訓練データを活動単位にする（非推奨）

```
問題:
- ラベル付けが複雑になる
- シーケンスが長すぎる
- 計算コストが増加
```

---

## 🎯 推奨実装: Option A

### 実装手順

1. **新しい関数を作成**:
   ```python
   scripts/training/irl/train_irl_within_training_period.py
   に extract_cutoff_evaluation_trajectories_monthly を追加
   ```

2. **スライディングウィンドウ版で使用**:
   ```python
   scripts/training/irl/train_irl_sliding_window.py
   で extract_cutoff_evaluation_trajectories_monthly を使用
   ```

3. **再実行**:
   ```bash
   bash scripts/training/irl/run_sliding_cross_evaluation_nova.sh
   ```

---

## 期待される改善

### 修正前（現状）

```
評価時:
  予測確率: 全員0.47（固定）
  Precision: 0.27 (継続率と同じ)
  Recall: 1.00 (全員継続と予測)
```

### 修正後（期待）

```
評価時:
  予測確率: 0.0-1.0（広い分布）
  Precision: 0.6-0.8
  Recall: 0.6-0.8
  → 訓練時と同様のバランス
```

---

## 次のステップ

1. ✅ **extract_cutoff_evaluation_trajectories_monthly を実装**
2. ✅ **train_irl_sliding_window.py で使用**
3. ⚠️ **1つのモデルでテスト**
4. ⬜ **全モデルで再実行**

実装しますか？
