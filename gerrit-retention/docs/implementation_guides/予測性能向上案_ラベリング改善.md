# 予測性能向上案: ラベリング改善

## 📅 作成日

2025-10-30

## 🎯 目標

現在の平均 AUC-PR 0.413 を改善する。

## 🔍 現状の問題

### 1. ラベリングロジックの複雑さ

```
訓練期間: 2021-01-01 ～ 2023-01-01
  - 特徴量計算期間: 2021-01-01 ～ 2023-01-01
  - ラベル期間: 2023-01-01 + (future_window) ～

ユーザーの懸念:
1. 訓練期間でアサインされなかったやつは除外すべき？
2. 訓練期間でアサインはあるけど、指定期間（future_window）ではないやつは重み付の負例？
```

### 2. 現在のロジック

```python
# 訓練期間内にレビュー依頼を受けたレビュアーを対象
active_reviewers = history_df[reviewer_col].unique()

for reviewer in active_reviewers:
    # ラベル期間に依頼がない → すべて負例（依頼なし）として扱う
    if len(reviewer_label) == 0:
        future_acceptance = False
        sample_weight = 0.3  # 低い重み
    else:
        # 依頼がある場合
        future_acceptance = len(accepted_requests) > 0
        sample_weight = 1.0
```

### 3. データの分布

```
train_3-6m: 正例18 (14.9%), 負例103 (85.1%)
  - 依頼あり→拒否（重み=1.0）: 27
  - 依頼なし（重み=0.3）: 76
```

**問題点**:

- 依頼なしのサンプルが大半（76/103 = 73.8%）
- これらの重みが 0.3 でも影響が大きい

---

## 💡 改善案

### 案 1: より厳密な除外基準

#### 提案

```
1. 訓練期間でアサインされなかったレビュアー → 除外
2. 訓練期間でアサインがあったが、ラベル期間（future_window）でも依頼がある → 正例/負例（重み1.0）
3. 訓練期間でアサインがあったが、ラベル期間（future_window）で依頼がない → 重み付き負例（重み0.1）
```

#### 実装方針

```python
# 訓練期間内にレビュー依頼を受けたレビュアーを対象
active_reviewers = history_df[reviewer_col].unique()

for reviewer in active_reviewers:
    # ラベル期間のレビュー依頼をチェック
    reviewer_label = label_df[label_df[reviewer_col] == reviewer]

    if len(reviewer_label) == 0:
        # ラベル期間に依頼がない → 重み付き負例
        future_acceptance = False
        sample_weight = 0.1  # さらに低い重み（0.3 → 0.1）
        negative_without_requests += 1
    else:
        # ラベル期間に依頼がある → 通常の処理
        accepted_requests = reviewer_label[reviewer_label[label_col] == 1]
        rejected_requests = reviewer_label[reviewer_label[label_col] == 0]
        future_acceptance = len(accepted_requests) > 0
        sample_weight = 1.0

        if future_acceptance:
            positive_count += 1
        else:
            negative_count += 1
            negative_with_requests += 1
```

#### 期待される効果

✅ **サンプル品質の向上**

- 低重みサンプル（依頼なし）の影響をさらに削減
- より信頼性の高いサンプルに集中

⚠️ **注意点**

- sample_weight=0.1 は非常に低い
- 正例がさらに少なくなる可能性

---

### 案 2: 拡張期間の活用改善

#### 提案

```
1. 訓練期間でアサインがあった → 対象
2. ラベル期間（future_window）で依頼がある → 正例/負例（重み1.0）
3. ラベル期間で依頼がないが、拡張期間（12ヶ月）で依頼がある → 重み付き負例（重み0.2）
4. 拡張期間でも依頼がない → 除外（実質離脱者）
```

#### 実装方針

```python
for reviewer in active_reviewers:
    reviewer_label = label_df[label_df[reviewer_col] == reviewer]

    if len(reviewer_label) == 0:
        # ラベル期間に依頼がない → 拡張期間をチェック
        reviewer_extended_label = extended_label_df[extended_label_df[reviewer_col] == reviewer]

        if len(reviewer_extended_label) > 0:
            # 拡張期間に依頼がある → 重み付き負例
            future_acceptance = False
            sample_weight = 0.2
            negative_without_requests_in_window += 1
        else:
            # 拡張期間にも依頼がない → 除外（実質離脱者）
            continue  # スキップ
    else:
        # ラベル期間に依頼がある → 通常の処理
        # （現在のロジック）
```

#### 期待される効果

✅ **データの質向上**

- 実質離脱者を除外することで、予測可能性のあるサンプルのみを使用
- 中間的な重み（0.2）でバランスを取る

⚠️ **注意点**

- サンプル数がさらに減少する可能性
- 離脱予測のタスク定義が変わる

---

### 案 3: 2 段階の評価期間

#### 提案

```
短期（0-6m）と長期（6-12m）で異なるラベリング戦略を採用

1. 訓練期間でアサインがあった → 対象
2. 短期（0-6m）で依頼がある → 重み1.0
3. 短期で依頼がなく、長期（6-12m）で依頼がある → 重み0.3
4. 長期でも依頼がない → 重み0.1
```

#### 期待される効果

✅ **時間的パターンの活用**

- 短期の活動を重視しつつ、長期の活動も考慮
- より細かい階層的ラベリング

⚠️ **注意点**

- 実装が複雑になる
- パラメータが増える

---

## 🔬 推奨する実験順序

### 実験 1: sample_weight=0.1（案 1 の簡易版）

```python
# 変更点
sample_weight = 0.1  # 0.3 → 0.1

# その他は現状維持
```

**期待**: 低重みサンプルの影響を削減

---

### 実験 2: 拡張期間考慮の除外（案 2）

```python
# 変更点
if len(reviewer_label) == 0:
    reviewer_extended_label = extended_label_df[extended_label_df[reviewer_col] == reviewer]

    if len(reviewer_extended_label) > 0:
        # 重み付き負例
        sample_weight = 0.2
    else:
        # 除外
        continue

# sample_weight は現状維持（0.3）
```

**期待**: 実質離脱者を除外してデータ品質向上

---

### 実験 3: 組み合わせ

```python
# 実験1 + 実験2
if len(reviewer_label) == 0:
    reviewer_extended_label = extended_label_df[extended_label_df[reviewer_col] == reviewer]

    if len(reviewer_extended_label) > 0:
        sample_weight = 0.1  # さらに低い重み
    else:
        continue  # 除外
```

**期待**: 最大の効果

---

## 📊 評価方法

各実験で以下を記録:

1. **メトリクス**

   - 平均 AUC-PR
   - Precision, Recall, F1
   - 各期間の個別結果

2. **データ分布**

   - 正例数、負例数
   - 重み付きサンプルの割合
   - 除外されたサンプル数

3. **比較**
   - ベースライン（現状: AUC-PR 0.413）との比較

---

## 🎯 目標値

### 期待される改善

- **現状**: AUC-PR 0.413
- **目標**: AUC-PR 0.50 以上
- **理想**: AUC-PR 0.60 以上

### 達成条件

1. すべての期間で Recall=1.0 問題が発生しない
2. 各期間でバランスの取れた Precision/Recall
3. 対角線（同一期間）での AUC-PR > 0.50

---

## 📝 次のステップ

1. **実験 1 を実行**: sample_weight=0.1
2. **結果を分析**: AUC-PR の変化を確認
3. **実験 2 に進む**: 拡張期間考慮の除外
4. **最良設定を決定**: 実験 1 と 2 の組み合わせ

---

## 参考

- [訓練結果\_重み 0.3](訓練結果_重み0.3.md)
- [負例の構成とラベリングロジック](負例の構成とラベリングロジック.md)
- [精度改善のための課題と対策](精度改善のための課題と対策.md)

---

作成日: 2025-10-30
