# 学習ラベルと評価期間の関係

## 概要

IRL 訓練における「学習時のラベル期間」と「評価時の予測期間」の関係について説明します。

---

## 2 つのアプローチ

### **アプローチ 1: 各期間ごとに個別モデル訓練**

```
実験1: 1ヶ月後ラベルで学習 → 1ヶ月後を予測
実験2: 3ヶ月後ラベルで学習 → 3ヶ月後を予測
実験3: 6ヶ月後ラベルで学習 → 6ヶ月後を予測
実験4: 12ヶ月後ラベルで学習 → 12ヶ月後を予測
```

**実行スクリプト:**

```bash
bash scripts/training/irl/run_fixed_history_variable_label_experiments.sh
```

**長所:**

- ✅ 各期間に最適化されたモデル
- ✅ 最高の予測精度
- ✅ 各期間の「学習しやすさ」を比較可能

**短所:**

- ❌ 4 つのモデルが必要
- ❌ 訓練時間が 4 倍

**研究的意義:**

- 「どの期間が予測しやすいか？」を分析
- 継続率の変化を観察
- 最適なラベル期間の特定

---

### **アプローチ 2: 単一モデル・複数期間評価**

```
学習: 3ヶ月後ラベルで訓練（1回のみ）

評価:
  - 1ヶ月後の継続を予測  ← 汎化性能
  - 3ヶ月後の継続を予測  ← 訓練と同じ
  - 6ヶ月後の継続を予測  ← 汎化性能
  - 12ヶ月後の継続を予測 ← 汎化性能
```

**実行スクリプト:**

```bash
bash scripts/training/irl/run_single_model_multi_eval.sh
```

**長所:**

- ✅ 1 つのモデルで済む
- ✅ 訓練時間が短い
- ✅ モデルの汎化性能を測定可能

**短所:**

- ❌ 訓練期間と異なる期間の精度は低下する可能性

**研究的意義:**

- 「学習したパターンが他の期間に汎化するか？」を分析
- モデルのロバスト性評価
- 実用的なデプロイメントの可能性

---

## 比較表

| 項目             | アプローチ 1（個別）   | アプローチ 2（単一）       |
| ---------------- | ---------------------- | -------------------------- |
| モデル数         | 4 個                   | 1 個                       |
| 訓練時間         | 長い（4 倍）           | 短い                       |
| 各期間の精度     | 最高                   | 訓練期間以外は低下の可能性 |
| 汎化性能評価     | ❌                     | ✅                         |
| 学習しやすさ分析 | ✅                     | ❌                         |
| 実用性           | 低い（複数モデル管理） | 高い（単一モデル）         |

---

## 具体例

### アプローチ 1 の結果イメージ

```
実験1（1m後ラベル）:
  訓練: 1m後の継続で学習
  評価: 1m後を予測 → AUC-PR: 0.85

実験2（3m後ラベル）:
  訓練: 3m後の継続で学習
  評価: 3m後を予測 → AUC-PR: 0.89

実験3（6m後ラベル）:
  訓練: 6m後の継続で学習
  評価: 6m後を予測 → AUC-PR: 0.87

実験4（12m後ラベル）:
  訓練: 12m後の継続で学習
  評価: 12m後を予測 → AUC-PR: 0.82

結論: 3ヶ月後が最も学習しやすい！
```

### アプローチ 2 の結果イメージ

```
訓練: 3m後の継続で学習（1回のみ）

評価1（1m後）:
  予測: 1m後の継続 → AUC-PR: 0.84
  ※ 訓練より短い期間なので精度低下

評価2（3m後）:
  予測: 3m後の継続 → AUC-PR: 0.89
  ※ 訓練と同じなので最高精度

評価3（6m後）:
  予測: 6m後の継続 → AUC-PR: 0.85
  ※ 訓練より長いが汎化できている

評価4（12m後）:
  予測: 12m後の継続 → AUC-PR: 0.78
  ※ 訓練から大きく離れると精度低下

結論: 3m訓練のモデルは6m程度まで汎化可能！
```

---

## 推奨

### **研究目的の場合**

両方実施することを推奨：

1. **アプローチ 1 を先に実行**

   - 各期間の学習しやすさを分析
   - 最適なラベル期間を特定

2. **アプローチ 2 で検証**
   - 最適期間で訓練したモデルの汎化性能を確認
   - 実用性を評価

### **実用目的の場合**

**アプローチ 2**を推奨：

- 単一モデルで運用可能
- 様々な予測期間に対応

---

## 実装の技術的詳細

### 既存コードの活用

両アプローチとも、既存の`train_irl_within_training_period.py`の機能を活用：

```python
# 学習データ抽出（ラベル期間を指定）
train_trajectories = extract_temporal_trajectories_within_training_period(
    df=df,
    train_start=train_start,
    train_end=train_end,
    history_window_months=12,  # 固定
    future_window_start_months=0,
    future_window_end_months=3,  # ラベル: 3ヶ月後
    ...
)

# 評価データ抽出（予測期間を指定）
eval_trajectories = extract_temporal_trajectories_within_training_period(
    df=df,
    train_start=eval_start,
    train_end=eval_end,
    history_window_months=12,  # 固定（学習と同じ）
    future_window_start_months=0,
    future_window_end_months=6,  # 予測: 6ヶ月後（学習と異なってもOK）
    ...
)
```

### ポイント

- `history_window_months`は常に固定（12 ヶ月）
- `future_window_*`がラベル/予測期間を決定
- **学習時と評価時で`future_window_*`を変えられる**

---

## 実験の実行

### アプローチ 1: 個別モデル訓練

```bash
cd /Users/kazuki-h/rl/gerrit-retention

# 実験実行（4つのモデルを訓練）
bash scripts/training/irl/run_fixed_history_variable_label_experiments.sh

# 結果比較
python scripts/analysis/compare_fixed_history_results.py \
  --results-dir outputs/fixed_history_variable_label
```

**出力:**

- `outputs/fixed_history_variable_label/label_1m/` - 1 ヶ月後モデル
- `outputs/fixed_history_variable_label/label_3m/` - 3 ヶ月後モデル
- `outputs/fixed_history_variable_label/label_6m/` - 6 ヶ月後モデル
- `outputs/fixed_history_variable_label/label_12m/` - 12 ヶ月後モデル

### アプローチ 2: 単一モデル評価

```bash
cd /Users/kazuki-h/rl/gerrit-retention

# 実験実行（1つのモデルで複数期間評価）
bash scripts/training/irl/run_single_model_multi_eval.sh
```

**出力:**

- `outputs/single_model_multi_eval/irl_model.pth` - 訓練済みモデル
- `outputs/single_model_multi_eval/eval_1m.json` - 1 ヶ月後評価結果
- `outputs/single_model_multi_eval/eval_3m.json` - 3 ヶ月後評価結果
- `outputs/single_model_multi_eval/eval_6m.json` - 6 ヶ月後評価結果
- `outputs/single_model_multi_eval/eval_12m.json` - 12 ヶ月後評価結果

---

## まとめ

**答え: 学習時と異なる期間も予測できます！**

- ✅ 学習時: `--future-window-end 3` (3 ヶ月後)
- ✅ 予測時: `--future-window-end 6` (6 ヶ月後)

**ただし、精度は下がる可能性があります。**

研究としては**両方のアプローチを試す**ことで、

- 各期間の学習しやすさ（アプローチ 1）
- モデルの汎化性能（アプローチ 2）

の両面から分析できます！
