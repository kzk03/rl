# 精度改善のための課題と対策

## 現状の精度

### 対角線評価（同一期間）

| 期間        | AUC-PR | Precision | Recall | F1-score | サンプル数 | 正例 | 負例 | 正例率 |
| ----------- | ------ | --------- | ------ | -------- | ---------- | ---- | ---- | ------ |
| train_0-3m  | 0.653  | 0.593     | 0.762  | 0.667    | 60         | 21   | 39   | 35.0%  |
| train_3-6m  | 0.811  | 0.714     | 0.833  | 0.769    | 55         | 18   | 37   | 32.7%  |
| train_6-9m  | 0.749  | 0.800     | 0.615  | 0.696    | 42         | 13   | 29   | 31.0%  |
| train_9-12m | 0.651  | 0.556     | 0.938  | 0.698    | 39         | 16   | 23   | 41.0%  |

**平均 AUC-PR: 0.716**  
**合計サンプル数: 196 サンプル**

---

## 課題

### 1. サンプル数の少なさ

- **最小**: 39 サンプル（train_9-12m）
- **最大**: 60 サンプル（train_0-3m）
- **合計**: 196 サンプル（全期間）
- **問題**: サンプルが少ないと精度が不安定になる
- **特に影響**: train_6-9m（42 サンプル）、train_9-12m（39 サンプル）
- **クラス不均衡**: 正例率が 31.0% 〜 41.0% で、負例が約 2 倍（全期間で平均 34.7%）

### 2. AUC-PR のばらつき

- **最高**: 0.811（train_3-6m）
- **最低**: 0.651（train_9-12m）
- **範囲**: 0.160
- **問題**: 期間ごとに性能が大きく異なる
- **原因**: データの偏り、サンプル数の差

### 3. Precision vs Recall のバランス

- **train_6-9m**: Precision=0.800, Recall=0.615（精度重視）
- **train_9-12m**: Precision=0.556, Recall=0.938（再現率重視）
- **問題**: 理想的な閾値を見つけることが難しい
- **原因**: データの不均衡、サンプル数の少なさ

### 4. Recall=1.0 問題の解決

- **改善**: sample_weight=0.3 により Recall=1.0 問題を解決
- **残課題**: train_9-12m で Recall=0.938 と高め（許容範囲だが改善の余地あり）

---

## 改善案

### 1. データ収集の拡充

#### 追加データの取得

- **他のプロジェクト**: neutron, cinder などの OpenStack プロジェクトからデータを取得
- **期間の拡大**: より長期間のデータを取得
- **開発者数の増加**: より多くの開発者を対象に

#### データ拡張

- **合成データ生成**: SMOTE などのオーバーサンプリング手法
- **データ拡張**: 既存データの変形（ノイズ追加、特徴量の変形）

### 2. 特徴量の見直し

#### 追加候補特徴量

1. **レビューコメントの品質**

   - コメント数
   - コメントの詳細度（文字数、改行数）
   - コメントの言語（技術的、非技術的）

2. **コミュニケーション頻度**

   - 1 週間あたりのメッセージ数
   - レスポンスの頻度

3. **プロジェクトの参加度**

   - 参加しているプロジェクト数
   - 各プロジェクトでの貢献度

4. **コードレビューの深さ**
   - レビューした変更の複雑度
   - レビューコメントの技術的深度

#### 特徴量エンジニアリングの改善

- **特徴量選択**: 重要度の低い特徴量の除外
- **特徴量のスケーリング**: 各特徴量の分布を確認し、適切なスケーリングを適用
- **特徴量の組み合わせ**: 相互作用を考慮した特徴量の作成

### 3. モデルアーキテクチャの調整

#### ネットワーク構造の最適化

- **レイヤー数の調整**: 現在の構造が最適か確認
- **ドロップアウト率**: 0.3 が最適か検証
- **活性化関数**: ReLU 以外の活性化関数の検討

#### ハイパーパラメータの再調整

- **学習率**: 0.00005 が最適か検証（より小さく、または大きく）
- **エポック数**: 20 が最適か検証（過学習の確認）
- **バッチサイズ**: 現在の設定が最適か検証

### 4. 損失関数の見直し

#### Focal Loss の調整

- **alpha**: 現在の設定が最適か検証
- **gamma**: 現在の設定が最適か検証

#### サンプル重みの調整

- **sample_weight=0.3**: 更なる調整の可能性（0.2, 0.4 など）
- **期間ごとの重み**: 期間によって異なる重みを設定

### 5. 評価方法の改善

#### クロスバリデーション

- **期間分割**: より多くの期間に分割
- **stratified sampling**: クラス分布を維持した分割

#### メトリクスの見直し

- **AUC-PR 以外**: Precision@k, Recall@k などのメトリクスの追加
- **ビジネス指標**: 実際のビジネス価値に基づく評価

---

## 優先順位

### 高優先度

1. **データ収集の拡充**

   - サンプル数を増やすことが最も効果的
   - 他のプロジェクトからのデータ追加

2. **特徴量の追加**

   - レビューコメントの品質
   - コミュニケーション頻度

3. **ハイパーパラメータの再調整**
   - 学習率、エポック数、ドロップアウト率

### 中優先度

4. **モデルアーキテクチャの調整**

   - ネットワーク構造の最適化

5. **損失関数の見直し**
   - Focal Loss の調整
   - サンプル重みの調整

### 低優先度

6. **評価方法の改善**
   - クロスバリデーション
   - メトリクスの見直し

---

## まとめ

現状の精度は平均 AUC-PR=0.716 で、**それほど高くありません**。主な原因は：

1. **サンプル数の少なさ**（39-60 サンプル）
2. **データの偏り**（期間ごとの性能差）
3. **クラスの不均衡**（Precision vs Recall のバランス）

最も効果的な改善策は**データ収集の拡充**です。他のプロジェクトからデータを追加し、サンプル数を増やすことで、精度の向上が期待できます。
