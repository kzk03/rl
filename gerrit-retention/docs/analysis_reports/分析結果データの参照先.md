# 分析結果データの参照先

## 総合分析ドキュメントで使用したデータファイル

### 1. 予測結果の詳細データ

#### `outputs/review_acceptance_cross_eval_nova/detailed_prediction_analysis.csv`
- **内容**: 全784件の予測結果の詳細
- **カラム**:
  - `reviewer_email`: 開発者のメールアドレス
  - `predicted_prob`: 予測確率（0.434〜0.493）
  - `true_label`: 実際のラベル（0=非継続、1=継続）
  - `predicted_binary`: 予測ラベル（0=非継続、1=継続）
  - `history_request_count`: 訓練期間のレビュー依頼数
  - `history_acceptance_rate`: 訓練期間の受諾率
  - `eval_request_count`: 評価期間のレビュー依頼数
  - `eval_accepted_count`: 評価期間の受諾数
  - `eval_rejected_count`: 評価期間の拒否数
  - `train_period`: 訓練期間（例: 0-3m）
  - `eval_period`: 評価期間（例: 0-3m）
  - `prediction_result`: 予測結果（TP/FP/FN/TN）
  - `experience_level`: 経験レベル（新人/中堅/ベテラン/エキスパート）
  - `acceptance_level`: 受諾率レベル（非常に低/低/中/高）

**使用例**:
```python
import pandas as pd
df = pd.read_csv('outputs/review_acceptance_cross_eval_nova/detailed_prediction_analysis.csv')

# 経験レベル別の集計
experience_stats = df.groupby('experience_level').agg({
    'predicted_prob': 'mean',
    'history_acceptance_rate': 'mean',
    'prediction_result': 'count'
})

# 受諾率レベル別のF1スコア計算
from sklearn.metrics import f1_score
for level in df['acceptance_level'].unique():
    subset = df[df['acceptance_level'] == level]
    f1 = f1_score(subset['true_label'], subset['predicted_binary'])
    print(f"{level}: F1 = {f1:.4f}")
```

#### `outputs/review_acceptance_cross_eval_nova/combined_predictions_analysis.csv`
- **内容**: 同じデータだが、より集計向けの形式
- **サイズ**: 784行 × 14列

### 2. 特徴量重要度データ

#### `outputs/review_acceptance_cross_eval_nova/feature_importance_state_transition.csv`
- **内容**: 状態特徴量（10個）の期間別重要度
- **行**: 訓練期間（0-3m, 3-6m, 6-9m, 9-12m）
- **列**:
  - 経験日数
  - 総コミット数
  - 総レビュー数
  - 最近の活動頻度
  - 平均活動間隔
  - 活動トレンド
  - 協力スコア
  - コード品質スコア
  - 最近の受諾率
  - レビュー負荷

**使用例**:
```python
import pandas as pd
df = pd.read_csv('outputs/review_acceptance_cross_eval_nova/feature_importance_state_transition.csv', index_col=0)

# 最も重要な特徴量を期間別に表示
for period in df.index:
    top_feature = df.loc[period].idxmax()
    importance = df.loc[period].max()
    print(f"{period}: {top_feature} = {importance:.4f}")
```

#### `outputs/review_acceptance_cross_eval_nova/feature_importance_action_transition.csv`
- **内容**: 行動特徴量（4個）の期間別重要度
- **行**: 訓練期間（0-3m, 3-6m, 6-9m, 9-12m）
- **列**:
  - 強度（ファイル数）
  - 協力度
  - 応答速度
  - レビュー規模（行数）

### 3. 性能評価マトリクス

#### `outputs/review_acceptance_cross_eval_nova/matrix_AUC_PR.csv`
- **内容**: AUC-PRスコアの訓練期間 × 評価期間マトリクス
- **サイズ**: 4×4（対角線が同期間評価）

#### `outputs/review_acceptance_cross_eval_nova/matrix_F1_SCORE.csv`
- **内容**: F1スコアの訓練期間 × 評価期間マトリクス

#### `outputs/review_acceptance_cross_eval_nova/matrix_AUC_ROC.csv`
- **内容**: AUC-ROCスコアの訓練期間 × 評価期間マトリクス

#### `outputs/review_acceptance_cross_eval_nova/matrix_PRECISION.csv`
- **内容**: Precisionの訓練期間 × 評価期間マトリクス

#### `outputs/review_acceptance_cross_eval_nova/matrix_RECALL.csv`
- **内容**: Recallの訓練期間 × 評価期間マトリクス

**使用例**:
```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# F1スコアのヒートマップ
df = pd.read_csv('outputs/review_acceptance_cross_eval_nova/matrix_F1_SCORE.csv', index_col=0)
plt.figure(figsize=(8, 6))
sns.heatmap(df, annot=True, fmt='.3f', cmap='RdYlGn', center=0.65)
plt.title('F1 Score Heatmap')
plt.show()
```

### 4. 可視化済みの画像

#### `outputs/review_acceptance_cross_eval_nova/heatmaps/feature_importance_heatmap.png`
- **内容**: 状態特徴量と行動特徴量の期間別ヒートマップ
- **左パネル**: 状態特徴量（10個）× 4期間
- **右パネル**: 行動特徴量（4個）× 4期間

#### `outputs/review_acceptance_cross_eval_nova/heatmaps/feature_importance_transition.png`
- **内容**: 特徴量重要度の推移グラフ
- **上パネル**: 状態特徴量の上位5つの推移（折れ線グラフ）
- **下パネル**: 行動特徴量の全4つの推移（折れ線グラフ）

## データの読み込み方法

### Python での読み込み例

```python
import pandas as pd
import numpy as np
from pathlib import Path

# ベースディレクトリ
base_dir = Path('outputs/review_acceptance_cross_eval_nova')

# 1. 予測結果の詳細
predictions = pd.read_csv(base_dir / 'detailed_prediction_analysis.csv')
print(f"総予測数: {len(predictions)}")
print(f"ユニーク開発者数: {predictions['reviewer_email'].nunique()}")

# 2. 特徴量重要度
state_importance = pd.read_csv(
    base_dir / 'feature_importance_state_transition.csv',
    index_col=0
)
action_importance = pd.read_csv(
    base_dir / 'feature_importance_action_transition.csv',
    index_col=0
)

# 3. 性能マトリクス
f1_matrix = pd.read_csv(base_dir / 'matrix_F1_SCORE.csv', index_col=0)
auc_pr_matrix = pd.read_csv(base_dir / 'matrix_AUC_PR.csv', index_col=0)

# 4. 経験レベル別の集計
experience_stats = predictions.groupby('experience_level').apply(
    lambda g: pd.Series({
        'count': len(g),
        'avg_predicted_prob': g['predicted_prob'].mean(),
        'avg_acceptance_rate': g['history_acceptance_rate'].mean(),
        'TP': (g['prediction_result'] == 'TP').sum(),
        'FP': (g['prediction_result'] == 'FP').sum(),
        'FN': (g['prediction_result'] == 'FN').sum(),
        'TN': (g['prediction_result'] == 'TN').sum(),
    })
)
print(experience_stats)

# 5. 受諾率レベル別の集計
acceptance_stats = predictions.groupby('acceptance_level').apply(
    lambda g: pd.Series({
        'count': len(g),
        'avg_predicted_prob': g['predicted_prob'].mean(),
        'avg_experience': g['history_request_count'].mean(),
        'precision': (g['prediction_result'] == 'TP').sum() /
                    ((g['prediction_result'] == 'TP').sum() +
                     (g['prediction_result'] == 'FP').sum()),
        'recall': (g['prediction_result'] == 'TP').sum() /
                 ((g['prediction_result'] == 'TP').sum() +
                  (g['prediction_result'] == 'FN').sum()),
    })
)
print(acceptance_stats)
```

### R での読み込み例

```r
library(tidyverse)

# ベースディレクトリ
base_dir <- "outputs/review_acceptance_cross_eval_nova"

# 1. 予測結果の詳細
predictions <- read_csv(file.path(base_dir, "detailed_prediction_analysis.csv"))

# 2. 経験レベル別の集計
experience_stats <- predictions %>%
  group_by(experience_level) %>%
  summarise(
    count = n(),
    avg_predicted_prob = mean(predicted_prob),
    avg_acceptance_rate = mean(history_acceptance_rate),
    TP = sum(prediction_result == "TP"),
    FP = sum(prediction_result == "FP"),
    FN = sum(prediction_result == "FN"),
    TN = sum(prediction_result == "TN"),
    precision = TP / (TP + FP),
    recall = TP / (TP + FN),
    f1 = 2 * precision * recall / (precision + recall)
  )

print(experience_stats)

# 3. ヒートマップの作成
library(ggplot2)
library(viridis)

f1_matrix <- read_csv(file.path(base_dir, "matrix_F1_SCORE.csv"))
f1_long <- f1_matrix %>%
  pivot_longer(-1, names_to = "eval_period", values_to = "f1_score")

ggplot(f1_long, aes(x = eval_period, y = ...1, fill = f1_score)) +
  geom_tile() +
  geom_text(aes(label = round(f1_score, 3)), color = "white") +
  scale_fill_viridis() +
  labs(title = "F1 Score Heatmap", x = "Evaluation Period", y = "Training Period") +
  theme_minimal()
```

## データの特徴と注意点

### 1. 予測確率の集中
- **範囲**: 0.434 〜 0.493（非常に狭い）
- **標準偏差**: 約0.015
- **注意**: 継続/非継続の分離能力が限定的

### 2. クラス不均衡
- **正例（継続）**: 272件（34.7%）
- **負例（非継続）**: 512件（65.3%）
- **注意**: Accuracy よりも F1 や AUC-PR を重視すべき

### 3. セグメント別のサンプル数の偏り
- **新人**: 205件（26.1%）
- **中堅**: 223件（28.4%）
- **ベテラン**: 194件（24.7%）
- **エキスパート**: 162件（20.7%）

### 4. 受諾率の欠損値
- 一部の開発者（特に CI bot）は受諾率が計算不能（0件の場合）
- 欠損値は空文字列として記録されている

## まとめ

全ての分析データは `outputs/review_acceptance_cross_eval_nova/` 配下に整理されています。
- **詳細データ**: CSV形式で機械的に読み込み可能
- **可視化済み**: PNG形式でプレゼンテーション用に利用可能
- **再現性**: Python/R のサンプルコードで同じ集計を再現可能
