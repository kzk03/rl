# 将来的な比較実験の設計

## 🎯 可能な比較実験

現在の実装をベースに、以下の豊富な比較実験が可能です。

---

## 1. スライディングウィンドウ評価

### 1.1 履歴ウィンドウ × 将来窓の組み合わせ

**実験設計:**

```python
history_windows = [3, 6, 9, 12]  # 履歴ウィンドウ（ヶ月）
future_windows = [
    (0, 1),   # 0-1ヶ月後
    (1, 3),   # 1-3ヶ月後
    (3, 6),   # 3-6ヶ月後
    (6, 12),  # 6-12ヶ月後
]

# 4 × 4 = 16 組み合わせ
for history in history_windows:
    for future_start, future_end in future_windows:
        train_model(history, future_start, future_end)
```

**比較軸:**

| 履歴窓 | 将来窓 | AUC-ROC | AUC-PR | F1  | 用途       |
| ------ | ------ | ------- | ------ | --- | ---------- |
| 3m     | 0-1m   | ?       | ?      | ?   | 短期・短期 |
| 6m     | 0-1m   | ?       | ?      | ?   | 中期・短期 |
| 12m    | 6-12m  | ?       | ?      | ?   | 長期・長期 |

**期待される発見:**

- 短い履歴で長期予測は困難？
- 長い履歴で短期予測は過剰適合？
- 最適な組み合わせは？

---

### 1.2 サンプリング間隔の影響

**実験設計:**

```python
sampling_intervals = [1, 2, 4]  # 1ヶ月、2ヶ月、4ヶ月

# サンプル数の変化
# 1ヶ月: 12サンプル/年
# 2ヶ月: 6サンプル/年
# 4ヶ月: 3サンプル/年
```

**比較観点:**

- サンプル数 vs 予測精度
- 計算時間 vs 性能のトレードオフ
- 密なサンプリングの効果

---

### 1.3 学習期間の長さの影響

**実験設計:**

```python
training_periods = [
    ('2019-01-01', '2019-07-01'),   # 6ヶ月
    ('2019-01-01', '2020-01-01'),   # 12ヶ月
    ('2019-01-01', '2020-07-01'),   # 18ヶ月
    ('2019-01-01', '2021-01-01'),   # 24ヶ月
]
```

**比較観点:**

- 学習データ量の影響
- 季節性の捉え方
- 過学習のリスク

---

## 2. モデルアーキテクチャの比較

### 2.1 LSTM の有無

**実験設計:**

```python
# 実験A: LSTMあり（時系列モード）
model_lstm = train_irl(sequence=True, seq_len=15)

# 実験B: LSTMなし（最新の状態のみ）
model_no_lstm = train_irl(sequence=False)
```

**比較観点:**

- 時系列パターンの重要性
- 計算コスト vs 性能
- 過去のトレンドを捉える効果

---

### 2.2 シーケンス長の影響

**実験設計:**

```python
seq_lengths = [5, 10, 15, 20, 30]

for seq_len in seq_lengths:
    model = train_irl(sequence=True, seq_len=seq_len)
```

**比較観点:**

- 短期記憶 vs 長期記憶
- どこまで過去を見るべきか
- メモリ効率 vs 性能

---

## 3. 時間的な汎化性能の評価

### 3.1 複数の評価期間でテスト

**実験設計:**

```python
# 訓練期間固定
train_period = ('2019-01-01', '2020-01-01')

# 複数の評価期間
eval_periods = [
    ('2020-01-01', '2020-07-01'),  # 直後6ヶ月
    ('2020-07-01', '2021-01-01'),  # 6-12ヶ月後
    ('2021-01-01', '2021-07-01'),  # 12-18ヶ月後
    ('2021-07-01', '2022-01-01'),  # 18-24ヶ月後
]
```

**比較観点:**

- 時間経過による性能劣化
- モデルの汎化性能
- 再訓練のタイミング

---

### 3.2 ローリングウィンドウ評価

**実験設計:**

```python
# 訓練期間を3ヶ月ずつスライド
rolling_periods = [
    (train: '2019-01-01 ~ 2020-01-01', eval: '2020-01-01 ~ 2020-07-01'),
    (train: '2019-04-01 ~ 2020-04-01', eval: '2020-04-01 ~ 2020-10-01'),
    (train: '2019-07-01 ~ 2020-07-01', eval: '2020-07-01 ~ 2021-01-01'),
    (train: '2019-10-01 ~ 2020-10-01', eval: '2020-10-01 ~ 2021-04-01'),
]
```

**比較観点:**

- 季節性の影響
- 安定した性能か？
- プロジェクトの変化の影響

---

## 4. 異なる継続定義での比較

### 4.1 継続の厳しさを変える

**実験設計:**

```python
# 継続の定義を変更
continuation_criteria = [
    {'min_activities': 1, 'description': '1件でも貢献'},
    {'min_activities': 3, 'description': '3件以上貢献'},
    {'min_activities': 5, 'description': '5件以上貢献'},
]
```

**比較観点:**

- 継続の定義による予測難易度
- 実用的な継続の定義は？

---

### 4.2 複数の将来窓を組み合わせる

**実験設計:**

```python
# 複数期間での継続を同時に評価
combined_criteria = [
    {'pattern': '0-1m のみ', 'description': '短期継続のみ'},
    {'pattern': '0-1m & 1-3m', 'description': '短期+中期継続'},
    {'pattern': '0-1m & 3-6m', 'description': '短期+長期継続'},
    {'pattern': 'any(0-1m, 1-3m, 3-6m)', 'description': 'いずれかで継続'},
]
```

---

## 5. プロジェクト・開発者属性による層別分析

### 5.1 プロジェクト別の性能

**実験設計:**

```python
projects = ['nova', 'neutron', 'cinder', 'glance']

for project in projects:
    df_project = df[df['project'] == project]
    model = train_irl(df_project)
    evaluate(model, project)
```

**比較観点:**

- プロジェクトごとの特徴
- 汎用モデル vs 専用モデル

---

### 5.2 経験レベル別の予測

**実験設計:**

```python
experience_levels = [
    {'name': '新人', 'tenure_days': '<90'},
    {'name': '中堅', 'tenure_days': '90-365'},
    {'name': 'ベテラン', 'tenure_days': '>365'},
]

for level in experience_levels:
    test_data = filter_by_experience(level)
    metrics = evaluate(model, test_data)
```

**比較観点:**

- 経験レベルによる予測精度の違い
- 新人の離脱予測は難しい？

---

## 6. 実装済み vs 今後実装する比較

### ✅ 現在実装済み

1. **単一実験の実行**

   - `train_irl_within_training_period.py`
   - 指定した履歴窓・将来窓で訓練

2. **複数の将来窓の比較**

   - `run_future_window_experiments.sh`
   - 固定履歴窓で複数の将来窓を比較

3. **結果の可視化**
   - `compare_future_window_results.py`
   - 将来窓ごとのメトリクス比較

---

### 🚀 今後実装すべき機能

#### 6.1 スライディングウィンドウ評価スクリプト

**ファイル名:** `train_irl_sliding_window_evaluation.py`

**機能:**

```python
# 履歴窓 × 将来窓の全組み合わせを評価
history_windows = [3, 6, 9, 12]
future_windows = [(0,1), (1,3), (3,6), (6,12)]

# 4×4=16 組み合わせを自動実行
for h in history_windows:
    for (f_start, f_end) in future_windows:
        train_and_evaluate(h, f_start, f_end)

# 結果を行列形式で出力
# 行: 履歴窓、列: 将来窓
print_matrix_results()
```

**出力例:**

```
AUC-ROC 行列:
future_window    0-1m    1-3m    3-6m   6-12m
history_window
3m              0.731   0.682   0.654   0.612
6m              0.842   0.802   0.757   0.718
9m              0.853   0.750   0.727   0.762
12m             0.777   0.855*  0.799   0.791
```

---

#### 6.2 時間的汎化性能評価スクリプト

**ファイル名:** `evaluate_temporal_generalization.py`

**機能:**

```python
# 固定された訓練期間
train_period = ('2019-01-01', '2020-01-01')

# 複数の評価期間でテスト
eval_periods = [
    ('2020-01-01', '2020-07-01'),  # +0-6m
    ('2020-07-01', '2021-01-01'),  # +6-12m
    ('2021-01-01', '2021-07-01'),  # +12-18m
]

# 性能劣化を分析
analyze_degradation_over_time()
```

---

#### 6.3 ローリングウィンドウ評価スクリプト

**ファイル名:** `evaluate_rolling_window.py`

**機能:**

```python
# 訓練期間を3ヶ月ずつスライド
window_size = 12  # 12ヶ月
slide_months = 3  # 3ヶ月ずつスライド

for start_date in sliding_dates:
    train_period = (start_date, start_date + window_size)
    eval_period = (start_date + window_size, start_date + window_size + 6)

    model = train(train_period)
    metrics = evaluate(model, eval_period)

    results.append({
        'train_start': start_date,
        'metrics': metrics
    })

# 時系列プロット
plot_performance_over_time(results)
```

---

#### 6.4 層別分析スクリプト

**ファイル名:** `evaluate_stratified_analysis.py`

**機能:**

```python
# プロジェクト別
for project in projects:
    metrics = evaluate_by_project(model, project)

# 経験レベル別
for level in experience_levels:
    metrics = evaluate_by_experience(model, level)

# 活動レベル別
for activity_level in activity_levels:
    metrics = evaluate_by_activity(model, activity_level)

# 結果を比較表で出力
create_stratified_comparison_table()
```

---

## 7. 実装ロードマップ

### Phase 1: スライディングウィンドウ評価（優先度: 高）

**目的:** 履歴窓 × 将来窓の最適な組み合わせを発見

**実装タスク:**

- [ ] `train_irl_sliding_window_evaluation.py` を作成
- [ ] 行列形式の結果出力
- [ ] ヒートマップ可視化

**期間:** 1-2 日

---

### Phase 2: 時間的汎化性能評価（優先度: 中）

**目的:** モデルの長期的な性能を評価

**実装タスク:**

- [ ] `evaluate_temporal_generalization.py` を作成
- [ ] 性能劣化の時系列プロット
- [ ] 再訓練タイミングの推奨

**期間:** 1 日

---

### Phase 3: ローリングウィンドウ評価（優先度: 中）

**目的:** 季節性や時期による影響を分析

**実装タスク:**

- [ ] `evaluate_rolling_window.py` を作成
- [ ] 時系列プロット
- [ ] 安定性の統計分析

**期間:** 1 日

---

### Phase 4: 層別分析（優先度: 低）

**目的:** サブグループごとの性能を詳細分析

**実装タスク:**

- [ ] `evaluate_stratified_analysis.py` を作成
- [ ] プロジェクト別分析
- [ ] 経験レベル別分析

**期間:** 1-2 日

---

## 8. 期待される研究成果

### 8.1 論文での貢献

**RQ1: 最適な履歴窓と将来窓の組み合わせは？**

- スライディングウィンドウ評価で 16 組み合わせを比較
- AUC-ROC 行列で可視化
- 実用的な推奨設定を提示

**RQ2: 時系列モデル（LSTM）の効果は？**

- LSTM 有無での比較
- シーケンス長の影響分析
- 時系列パターンの重要性を定量化

**RQ3: モデルの時間的汎化性能は？**

- 複数の評価期間でテスト
- 性能劣化の分析
- 再訓練の必要性を示す

**RQ4: サブグループごとの予測精度の違いは？**

- プロジェクト別・経験別の層別分析
- 予測が難しいグループの特定
- 適応的なモデル選択の提案

---

### 8.2 実用的な推奨事項

**推奨 1: 最適設定**

- 履歴窓: 6 ヶ月
- 将来窓: 1-3 ヶ月
- サンプリング: 1 ヶ月間隔
- LSTM: 有効、seq_len=15

**推奨 2: 運用方針**

- 3 ヶ月ごとに再訓練
- プロジェクトごとに専用モデルを検討
- 新人には別のアプローチが必要

---

## 9. まとめ

### 現在できること

✅ 単一の履歴窓・将来窓での訓練  
✅ 複数の将来窓の比較  
✅ 基本的な結果可視化

### 将来できること

🚀 **履歴窓 × 将来窓の全組み合わせ評価**（Phase 1）  
🚀 **時間的汎化性能の評価**（Phase 2）  
🚀 **ローリングウィンドウ評価**（Phase 3）  
🚀 **層別分析**（Phase 4）

### 次のステップ

1. **Phase 1 を実装** → スライディングウィンドウ評価
2. **実験を実行** → 16 組み合わせの比較
3. **結果を分析** → 最適な設定を発見
4. **論文執筆** → RQ1-4 に答える

---

**作成日:** 2025-10-21  
**ステータス:** 設計書
