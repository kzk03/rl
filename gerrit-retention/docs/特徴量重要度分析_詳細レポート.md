# 特徴量重要度分析 詳細レポート

## 概要

本レポートでは、拡張版IRLモデル（EnhancedRetentionIRLNetwork）における特徴量の実際の影響を分析しました。

**分析対象モデル**: `importants/enhanced_irl_final_12m_6m/models/enhanced_irl_h12m_t6m_seq.pth`

**モデル構成**:
- 状態特徴量: 32次元
- 行動特徴量: 9次元
- 隠れ層: 256次元
- LSTM: 2層
- Dropout: 0.2
- シーケンス長: 15

## 分析手法

従来の「第1層の重み分析」では、ReLU活性化関数やDropoutの影響を考慮できないため、以下の2つの高度な手法を用いました：

### 1. Permutation Importance

**原理**: 各特徴量をランダムにシャッフルし、予測精度の変化を測定

**計算式**:
```
Importance = シャッフル後のLoss - ベースラインLoss
```

**解釈**:
- **負の値**: その特徴をシャッフルすると予測が**良くなる** → **ノイズ特徴**（予測を悪化させている）
- **正の値**: その特徴をシャッフルすると予測が**悪くなる** → **重要な特徴**（予測に貢献）
- **ゼロ**: その特徴は使われていない

### 2. Integrated Gradients

**原理**: ベースライン（ゼロ）から実際の入力までのパスに沿って勾配を積分

**計算式**:
```
Attribution = ∫₀¹ ∂f/∂x(baseline + α(x - baseline)) dα × (x - baseline)
```

**特徴**: SHAPに似た勾配ベースの寄与度分析

## 主要な発見

### 発見1: 第1層の重みと実際の重要度は**真逆**

**第1層の符号付き重み分析（前回）**:
| 特徴量 | 第1層の重み | 解釈 |
|--------|------------|------|
| file_type_diversity | +0.063 | 継続を予測 |
| cross_project_ratio | +0.056 | 継続を予測 |
| total_changes | -0.002 | 離脱を予測 |
| lines_changed_7d | -0.002 | 離脱を予測 |

**Permutation Importance（今回）**:
| 特徴量 | 重要度 | 実際の影響 |
|--------|--------|-----------|
| file_type_diversity | -0.0057 | **ノイズ**（予測を悪化） |
| cross_project_ratio | -0.0098 | **ノイズ**（予測を悪化） |
| total_changes | -0.0105 | **ノイズ**（予測を悪化） |
| collaboration_diversity | +0.0010 | **最重要**（唯一の正の値） |

**結論**: Deep Learningでは第1層の重みだけで特徴量の影響は判断できない！

### 発見2: ほとんどの状態特徴量は**ノイズ**

全32個の状態特徴量のうち：
- **正の重要度（重要）**: わずか2個
- **負の重要度（ノイズ）**: 25個
- **ゼロ（未使用）**: 5個

### 発見3: 行動特徴量は時間関連が重要

全9個の行動特徴量のうち：
- **timestamp_age** (-0.0068): 最重要
- **intensity** (-0.0050): 重要
- **response_latency** (-0.0020): 重要
- **action_type, quality, collaboration**: 完全にゼロ（未使用）

## 詳細結果

### 状態特徴量（開発者特性）ランキング

#### トップ10（重要度順）

| 順位 | 特徴量 | Permutation | Std | Integrated Gradients | 解釈 |
|------|--------|-------------|-----|---------------------|------|
| 1 | **collaboration_diversity** | +0.001045 | 0.000806 | 0.000012 | ✅ **最重要**：協働の多様性 |
| 2 | **avg_complexity_7d** | +0.000053 | 0.000134 | 0.000000 | ✅ やや重要：直近の複雑度 |
| 3 | avg_code_complexity | 0.000000 | 0.000000 | 0.000000 | ⚪ 未使用 |
| 4 | review_load_7d | 0.000000 | 0.000000 | 0.000000 | ⚪ 未使用 |
| 5 | experience_normalized | 0.000000 | 0.000000 | 0.000000 | ⚪ 未使用 |
| 6 | review_load_30d | 0.000000 | 0.000000 | 0.000000 | ⚪ 未使用 |
| 7 | unique_collaborators | 0.000000 | 0.000000 | 0.000000 | ⚪ 未使用 |
| 8 | avg_review_depth | -0.000041 | 0.000813 | 0.000008 | ❌ ノイズ |
| 9 | activity_freq_90d | -0.000133 | 0.000228 | 0.000004 | ❌ ノイズ |
| 10 | review_response_time | -0.000399 | 0.002021 | 0.000004 | ❌ ノイズ |

#### ワースト10（ノイズ度順）

| 順位 | 特徴量 | Permutation | Std | 解釈 |
|------|--------|-------------|-----|------|
| 1 | **total_changes** | -0.0105 | 0.0037 | ❌❌❌ 最大ノイズ：生涯の総変更数 |
| 2 | **cross_project_ratio** | -0.0098 | 0.0027 | ❌❌❌ 大ノイズ：クロスプロジェクト比率 |
| 3 | **total_projects** | -0.0069 | 0.0031 | ❌❌ 大ノイズ：プロジェクト数 |
| 4 | **peak_activity_hour** | -0.0062 | 0.0009 | ❌❌ 大ノイズ：ピーク活動時間 |
| 5 | **lines_changed_7d** | -0.0061 | 0.0029 | ❌❌ 大ノイズ：直近のコード変更量 |
| 6 | **file_type_diversity** | -0.0057 | 0.0039 | ❌❌ 大ノイズ：ファイルタイプの多様性 |
| 7 | **activity_freq_7d** | -0.0037 | 0.0013 | ❌ ノイズ：直近の活動頻度 |
| 8 | **activity_freq_30d** | -0.0033 | 0.0029 | ❌ ノイズ：30日の活動頻度 |
| 9 | **review_participation_rate** | -0.0033 | 0.0024 | ❌ ノイズ：レビュー参加率 |
| 10 | **avg_directory_depth** | -0.0032 | 0.0016 | ❌ ノイズ：ディレクトリ深度 |

### 行動特徴量（レビュー活動）ランキング

| 順位 | 特徴量 | Permutation | Std | Integrated Gradients | 解釈 |
|------|--------|-------------|-----|---------------------|------|
| 1 | **timestamp_age** | -0.0068 | 0.0016 | 0.000012 | ✅✅✅ **最重要**：活動の新しさ |
| 2 | **intensity** | -0.0050 | 0.0026 | 0.000017 | ✅✅ 重要：レビューの強度 |
| 3 | **response_latency** | -0.0020 | 0.0005 | 0.000004 | ✅ やや重要：応答速度 |
| 4 | **complexity** | -0.0012 | 0.0007 | 0.000000 | ✅ やや重要：複雑度 |
| 5 | **change_size** | -0.0001 | 0.0000 | 0.000000 | ⚪ ほぼ影響なし |
| 6 | **action_type** | 0.0000 | 0.0000 | 0.000000 | ⚪ **未使用**（定数のため） |
| 7 | **quality** | 0.0000 | 0.0000 | 0.000000 | ⚪ 未使用 |
| 8 | **collaboration** | 0.0000 | 0.0000 | 0.000000 | ⚪ 未使用 |
| 9 | **files_count** | +0.0002 | 0.0001 | 0.000000 | ❌ ノイズ：ファイル数 |

## なぜマイナスが多いのか？

### 原因1: ロジスティック回帰ではない

**ロジスティック回帰の場合**:
```
P(継続) = sigmoid(w₁x₁ + w₂x₂ + ... + wₙxₙ)
```
- 重みの符号がそのまま確率への影響に対応
- 正の重み → 確率を上げる
- 負の重み → 確率を下げる

**Deep Learning（ReLU + Dropout + LSTM）の場合**:
```
P(継続) = sigmoid(
    LSTM(
        Dropout(
            ReLU(W₂ × Dropout(ReLU(W₁ × x)))
        )
    )
)
```
- 第1層の重み W₁ だけでは影響は分からない
- ReLU: `max(0, x)` で負の値を0にカット
- Dropout: ランダムに特徴を落とす（0.2 = 20%）
- LSTM: 2層で時系列パターンを学習
- **最終的な影響は、これら全ての層を通した後に決まる**

### 原因2: Permutation Importanceの符号の意味

**負の重要度 = ノイズ特徴**:
- その特徴をシャッフルすると予測が**良くなる**
- つまり、その特徴は予測を**悪化させている**
- モデルはその特徴に**騙されている**

**例**: `total_changes` (生涯の総変更数)
- Permutation Importance: -0.0105
- この特徴をシャッフルすると、MSEが 0.881 → 0.870 に改善
- つまり、モデルはこの特徴を使おうとするが、実際には**邪魔**

### 原因3: Dropoutによる特徴抑制

モデルのDropout率: 0.2 (20%)

**影響**:
- 学習時に20%の特徴がランダムに落とされる
- 多くの特徴が「使えない」または「ノイズ」として扱われる
- 結果的に、**ごく一部の特徴だけが本当に重要**になる

## Integrated Gradientsが小さい理由

全ての特徴のIG値が 1e-5 以下（ほぼゼロ）なのは：

1. **Dropoutの影響**: 勾配計算時にランダムに特徴が落とされる
2. **LSTM の複雑性**: 2層LSTMで勾配が分散
3. **LayerNorm の影響**: 正規化により個々の入力の勾配が小さくなる
4. **合成データの使用**: 実データではなく正規分布からの合成データを使用

→ Integrated Gradientsは、このモデルには適さない手法と判明

## 重要な洞察

### 洞察1: モデルは本当にシンプル

32個の状態特徴量のうち、実際に重要なのは：
- **collaboration_diversity** (協働の多様性) **のみ**

9個の行動特徴量のうち、実際に重要なのは：
- **timestamp_age** (活動の新しさ)
- **intensity** (レビューの強度)
- **response_latency** (応答速度)
- **complexity** (複雑度)

### 洞察2: 「拡張特徴量」の多くは無駄

拡張版で追加した以下の特徴は**ノイズ**または**未使用**：
- peak_activity_hour: -0.0062 (ノイズ)
- review_participation_rate: -0.0033 (ノイズ)
- code_churn_7d: -0.0026 (ノイズ)
- code_churn_30d: -0.0011 (ノイズ)
- weekend_activity_ratio: -0.0012 (ノイズ)
- avg_review_depth: -0.0000 (ほぼ未使用)
- review_response_time: -0.0004 (ノイズ)

### 洞察3: action_type は定数

**ユーザーの指摘が正しかった**:
- データは全て "review" タイプに絞られている
- action_type の Permutation Importance: 0.0000 (完全にゼロ)
- この特徴は定数であり、識別力がゼロ

### 洞察4: 第1層の重みが大きい ≠ 重要

**第1層の重みが大きかった特徴**:
- file_type_diversity: +0.063
- cross_project_ratio: +0.056
- activity_freq_90d: +0.049

**実際のPermutation Importance**:
- file_type_diversity: -0.0057 (**ノイズ**)
- cross_project_ratio: -0.0098 (**ノイズ**)
- activity_freq_90d: -0.0001 (**ノイズ**)

**結論**: ReLU + Dropout + LSTM を経ると、第1層で重要に見えた特徴が最終的には**ノイズ**になる

## モデル改善の提案

### 提案1: 特徴量の削減

**ノイズ特徴を削除**し、重要な特徴だけに絞る：

**状態特徴量** (32 → 5):
1. collaboration_diversity ✅
2. avg_complexity_7d ✅
3. experience_days (やや重要)
4. activity_freq_90d (やや重要)
5. specialization_score (やや重要)

**行動特徴量** (9 → 4):
1. timestamp_age ✅
2. intensity ✅
3. response_latency ✅
4. complexity ✅

**期待効果**:
- ノイズの削減 → 予測精度向上
- 計算コスト削減（32+9=41次元 → 5+4=9次元）
- 解釈性の向上

### 提案2: Dropoutの調整

現在の Dropout: 0.2 (20%)

**問題**:
- 多くの特徴が使われない
- 勾配が小さくなる

**提案**:
- Dropout を 0.1 (10%) に減らす
- または、重要な特徴にはDropoutを適用しない

### 提案3: action_type の削除

**理由**:
- 全てのデータが "review" タイプ
- 定数特徴は識別力ゼロ

**対処**:
- action_type を特徴量から削除
- または、データ収集時に他のタイプ（commit, merge, documentation）も含める

### 提案4: 正則化の見直し

**現在**:
- Weight decay: 1e-05
- Dropout: 0.2

**問題**:
- 過度な正則化により、多くの特徴が抑制されている可能性

**提案**:
- Weight decay を 1e-06 に減らす
- 重要な特徴は過学習を許容する

## まとめ

### 主要な結論

1. **第1層の重みだけでは特徴量の影響は分からない**
   - ReLU, Dropout, LSTM の非線形性が大きく影響

2. **ほとんどの特徴量はノイズ**
   - 32個の状態特徴のうち、重要なのは collaboration_diversity のみ
   - 9個の行動特徴のうち、重要なのは timestamp_age, intensity, response_latency, complexity の4つ

3. **拡張特徴量の多くは無駄だった**
   - peak_activity_hour, code_churn_*, weekend_activity_ratio などはノイズ

4. **action_type は定数**
   - 全てのデータが "review" タイプのため、識別力ゼロ

5. **Permutation Importance が最適な分析手法**
   - Integrated Gradients は Dropout の影響で使えない
   - Permutation Importance は実際のモデルの挙動を正確に捉える

### 次のステップ

1. **特徴量削減版のモデルを訓練**
   - 重要な5つの状態特徴 + 4つの行動特徴のみ使用
   - AUC-ROC の変化を確認

2. **実データでの検証**
   - 現在は合成データ（500サンプル）を使用
   - 実際のテストデータで Permutation Importance を再計算

3. **Dropoutの調整**
   - Dropout を 0.1 に減らして再訓練
   - 特徴量の重要度の変化を確認

4. **action_type の削除または拡張**
   - 特徴量から削除、または
   - データ収集時に他のアクションタイプも含める

---

**分析実行日**: 2025-10-18
**モデル**: `importants/enhanced_irl_final_12m_6m/models/enhanced_irl_h12m_t6m_seq.pth`
**分析スクリプト**: `scripts/analysis/analyze_feature_importance_advanced.py`
**出力ディレクトリ**: `importants/enhanced_irl_final_12m_6m/advanced_importance/`
