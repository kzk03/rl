# モデル保存/読み込みの修正

## 🐛 問題の原因

### 発見された問題

**同じ評価データなのに予測結果が全く異なる**：

| 項目 | 訓練直後 | モデル再読み込み後 |
|------|---------|-------------------|
| 予測確率範囲 | 0.01-0.82 | 0.471-0.473 |
| 標準偏差 | 0.25 | 0.0004 |
| Precision | 0.92 | 0.27 |
| Recall | 0.52 | 1.00 |

### 根本原因

#### 1. モデル読み込みの誤り

```python
# 修正前（間違い）
irl_system = RetentionIRLSystem(config)  # 新規インスタンス作成
irl_system.load_model(args.model)  # クラスメソッドだが返り値を使っていない
# → 新規作成したインスタンスを使い続ける（パラメータが読み込まれていない）

# 修正後（正しい）
irl_system = RetentionIRLSystem.load_model(args.model)  # クラスメソッドの返り値を使う
# → 読み込まれたパラメータを持つインスタンスを使う
```

#### 2. モデル保存方法の改善

```python
# 修正前
torch.save(irl_system.network.state_dict(), model_path)
# → state_dict のみ保存（config が保存されない）

# 修正後
irl_system.save_model(str(model_path))
# → state_dict + optimizer + config を保存
```

---

## ✅ 修正内容

### 修正1: モデル読み込み

**ファイル**: `scripts/training/irl/train_irl_sliding_window.py`

```python
# Line 464
# 修正前
irl_system = RetentionIRLSystem(config)
irl_system.load_model(args.model)

# 修正後
irl_system = RetentionIRLSystem.load_model(args.model)
```

### 修正2: モデル保存

**ファイル**: `scripts/training/irl/train_irl_sliding_window.py`

```python
# Line 491
# 修正前
torch.save(irl_system.network.state_dict(), model_path)

# 修正後
irl_system.save_model(str(model_path))
```

---

## 📊 期待される改善

### 修正前

```
評価時（eval_0-3m）:
  予測確率: 全員 0.47 （固定）
  Precision: 0.27 (継続率と同じ)
  Recall: 1.00 (全員継続と予測)
  → モデルが機能していない
```

### 修正後（期待）

```
評価時（eval_0-3m）:
  予測確率: 0.0-0.8 （分散）
  Precision: 0.6-0.9
  Recall: 0.5-0.7
  → 訓練時と同じバランス
```

---

## 🧪 テスト方法

### 1つのモデルでテスト

```bash
# 1. train_0-3m を再訓練
rm -rf outputs/sliding_cross_eval_nova/train_0-3m
uv run python scripts/training/irl/train_irl_sliding_window.py \
  --reviews data/review_requests_openstack_multi_5y_detail.csv \
  --train-start 2021-01-01 \
  --train-end 2023-01-01 \
  --eval-start 2023-01-01 \
  --eval-end 2024-01-01 \
  --future-window-start 0 \
  --future-window-end 3 \
  --epochs 20 \
  --min-history-events 1 \
  --project openstack/nova \
  --output outputs/sliding_cross_eval_nova/train_0-3m

# 2. eval_0-3m を再評価
rm -rf outputs/sliding_cross_eval_nova/train_0-3m/eval_0-3m
uv run python scripts/training/irl/train_irl_sliding_window.py \
  --reviews data/review_requests_openstack_multi_5y_detail.csv \
  --train-start 2021-01-01 \
  --train-end 2023-01-01 \
  --eval-start 2023-01-01 \
  --eval-end 2024-01-01 \
  --future-window-start 0 \
  --future-window-end 3 \
  --eval-future-window-start 0 \
  --eval-future-window-end 3 \
  --epochs 0 \
  --min-history-events 1 \
  --project openstack/nova \
  --model outputs/sliding_cross_eval_nova/train_0-3m/irl_model.pt \
  --output outputs/sliding_cross_eval_nova/train_0-3m/eval_0-3m

# 3. 結果確認
python3 << 'PYTHON'
import json
import pandas as pd

# 訓練時
train_metrics = json.load(open('outputs/sliding_cross_eval_nova/train_0-3m/metrics.json'))
train_pred = pd.read_csv('outputs/sliding_cross_eval_nova/train_0-3m/predictions.csv')

# 評価時
eval_metrics = json.load(open('outputs/sliding_cross_eval_nova/train_0-3m/eval_0-3m/metrics.json'))
eval_pred = pd.read_csv('outputs/sliding_cross_eval_nova/train_0-3m/eval_0-3m/predictions.csv')

print("=== 訓練時 ===")
print(f"  Precision: {train_metrics['precision']:.3f}")
print(f"  Recall: {train_metrics['recall']:.3f}")
print(f"  予測確率: {train_pred['predicted_prob'].min():.4f} - {train_pred['predicted_prob'].max():.4f}")

print("\n=== 評価時 ===")
print(f"  Precision: {eval_metrics['precision']:.3f}")
print(f"  Recall: {eval_metrics['recall']:.3f}")
print(f"  予測確率: {eval_pred['predicted_prob'].min():.4f} - {eval_pred['predicted_prob'].max():.4f}")

print("\n=== 一致チェック ===")
print(f"  Precisionの差: {abs(train_metrics['precision'] - eval_metrics['precision']):.4f}")
print(f"  Recallの差: {abs(train_metrics['recall'] - eval_metrics['recall']):.4f}")
print(f"  ✅ 一致: {abs(train_metrics['precision'] - eval_metrics['precision']) < 0.01}")
PYTHON
```

### 全モデル再実行

```bash
# すべて削除して再実行
rm -rf outputs/sliding_cross_eval_nova
bash scripts/training/irl/run_sliding_cross_evaluation_nova.sh
```

---

## 📝 まとめ

### 問題
- モデル読み込み時にパラメータが正しく復元されていなかった
- 評価時の予測がランダムに近い状態になっていた

### 修正
- `load_model` の返り値を正しく使うように修正
- `save_model` メソッドを使ってconfig含めて保存

### 影響
- 全ての評価結果（eval_*）が無効
- 再実行が必要

実行しますか？
