# 拡張 IRL 不安定性の原因分析

## 🔍 問題の要約

拡張 IRL（32 次元特徴量）が通常 IRL（10 次元特徴量）よりも不安定になり、0-3m、0-6m、0-12m モデルで性能が大幅に低下。

---

## 📊 データ分析結果

### 訓練データの不均衡度

| モデル    | 継続ステップ率 | 負例の重み | 拡張 IRL AUC | 通常 IRL AUC | 結果              |
| --------- | -------------- | ---------- | ------------ | ------------ | ----------------- |
| **0-1m**  | 95.9%          | 23.11      | **0.803**    | 0.758        | ✅ **拡張が勝利** |
| **0-3m**  | 98.1%          | 51.67      | 0.505        | **0.769**    | ❌ 通常が勝利     |
| **0-6m**  | 99.0%          | 99.00      | 0.358        | **0.784**    | ❌ 通常が勝利     |
| **0-12m** | 99.5%          | 99.00      | 0.499        | **0.811**    | ❌ 通常が勝利     |

---

## 💡 原因の特定

### 1. **極端なデータ不均衡**

- **0-3m 以降**: 継続ステップ率が 98%以上
- **負例が極端に少ない**: 0-6m, 0-12m では負例が 1%以下
- **負例の重みが極端**: 99.00（ほぼ 100 倍）

### 2. **高次元特徴量 × 不均衡 = 過学習**

```
拡張IRL（32次元）:
  ┌─────────────────────────────────────┐
  │ 高次元特徴量（32次元）              │
  │   ↓                                 │
  │ モデルの表現力が高い                │
  │   ↓                                 │
  │ 不均衡データ（99%正例）             │
  │   ↓                                 │
  │ 極端な重み付け（99.00）             │
  │   ↓                                 │
  │ 【過学習】少数の負例に過適応        │
  │   ↓                                 │
  │ 評価データで汎化せず                │
  └─────────────────────────────────────┘

通常IRL（10次元）:
  ┌─────────────────────────────────────┐
  │ 低次元特徴量（10次元）              │
  │   ↓                                 │
  │ モデルの表現力が控えめ              │
  │   ↓                                 │
  │ 不均衡データでも過学習しにくい      │
  │   ↓                                 │
  │ 評価データで安定した性能            │
  └─────────────────────────────────────┘
```

### 3. **0-1m だけ成功した理由**

- 継続ステップ率が比較的低い（95.9%）
- 負例の重みが適度（23.11）
- 十分な負例が存在（4.1% = 2,635 ステップ）
- 高次元特徴量の表現力が活きた

---

## 📈 データ不均衡の詳細

### 継続ステップ率の推移

```
0-1m:  95.9% (60,904 / 63,539)  → 負例 4.1% (2,635)
0-3m:  98.1% (59,313 / 60,461)  → 負例 1.9% (1,148)
0-6m:  99.0% (52,363 / 52,888)  → 負例 1.0% (525)
0-12m: 99.5% (34,702 / 34,874)  → 負例 0.5% (172)
```

**問題**: 将来窓が長いほど、ほとんどのステップが「継続」ラベルになる

### レビュアー単位の継続率

```
0-1m:  25.9% (93 / 359)
0-3m:  34.4% (122 / 355)
0-6m:  40.8% (133 / 326)
0-12m: 45.8% (136 / 297)
```

**問題**: レビュアー単位では 25-45%なのに、ステップ単位では 95-99%

→ **月次集約ラベルの問題**: 活発なレビュアーほどステップ数が多く、継続ラベルが集中

---

## 🎯 結論

### なぜ拡張 IRL が不安定なのか？

1. **特徴量を増やしただけ** → 本来は性能向上するはず
2. **しかし極端なデータ不均衡** → 負例が 0.5-1.9%しかない
3. **高次元特徴量が裏目に** → 少数の負例に過適応
4. **通常 IRL は低次元** → 過学習しにくい

### 予想との違い

| 予想                            | 実際                       |
| ------------------------------- | -------------------------- |
| 特徴量増加 → 全モデルで精度向上 | 不均衡なモデルで大幅に悪化 |
| 表現力向上 → 安定した性能       | 過学習 → 不安定な性能      |

---

## 🔧 解決策

### 1. **負例の重みを制限**

```python
# 現在
neg_weight = positive_rate / (1 - positive_rate)  # 99.00になる

# 提案
neg_weight = min(positive_rate / (1 - positive_rate), 10.0)  # 上限を設定
```

### 2. **Focal Loss の調整**

```python
# 現在
alpha = 0.3
gamma = 3.0

# 提案（不均衡に強い設定）
alpha = 0.5  # 正例の重みを上げる
gamma = 5.0  # 難しい例により集中
```

### 3. **正則化の強化**

```python
# Dropoutを増やす
dropout = 0.5  # 現在: 0.3

# L2正則化を追加
optimizer = torch.optim.Adam(params, lr=1e-4, weight_decay=1e-3)
```

### 4. **ラベル定義の見直し**

- **月次集約の問題**: 活発なレビュアーに継続ラベルが集中
- **提案**: レビュアー単位のラベルに変更
  - 各レビュアーから 1 サンプル
  - 最終月のラベルのみ使用
  - ステップ単位の重み付けを排除

### 5. **特徴量の次元削減**

- PCA やオートエンコーダで 32 次元 →16 次元に削減
- 重要な特徴量のみ選択

### 6. **アンダーサンプリング**

- 正例の一部をランダムに削除
- 継続ステップ率を 80-85%程度に調整

---

## 📌 推奨アクション

### 短期（すぐに試せる）

1. **負例の重みに上限を設定** (max 10.0)
2. **Focal Loss のパラメータ調整** (alpha=0.5, gamma=5.0)
3. **Dropout を 0.5 に増やす**

### 中期（実験が必要）

4. **レビュアー単位ラベルの実験**
5. **アンダーサンプリングの実験**

### 長期（設計変更）

6. **ラベル定義の根本的見直し**
7. **特徴量選択・削減の検討**

---

## 🎓 教訓

1. **特徴量を増やすだけでは不十分**

   - データの質・バランスが重要

2. **高次元モデルは諸刃の剣**

   - 表現力 ↑ → 過学習リスク ↑

3. **データ不均衡の影響は特徴量次元に依存**

   - 低次元: 安定
   - 高次元: 不安定

4. **ラベル定義がデータ分布に影響**
   - 月次集約 → ステップ単位の偏り
   - レビュアー単位 → バランス改善の可能性

---

## 📊 次のステップ

1. 上記の解決策を 1 つずつ試す
2. 0-3m モデルで効果を確認
3. 効果があれば 0-6m, 0-12m にも適用
4. 結果をドキュメント化
