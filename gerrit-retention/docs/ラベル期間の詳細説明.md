# ラベル期間の詳細説明

## ✅ 確認：予測は「範囲内」です

### 現在の実装

```python
# パラメータ例
future_window_start = 0
future_window_end = 3

# 実際の処理
future_start = sampling_point + 0ヶ月  # サンプリング時点
future_end = sampling_point + 3ヶ月    # 3ヶ月後

# 範囲内のデータを抽出
future_df = df[
    (df['date'] >= future_start) &
    (df['date'] < future_end)
]

# ラベル: 範囲内に1件でも活動があればTrue
future_contribution = len(future_df) > 0
```

### 具体例

```
サンプリング時点: 2024-01-01
future_window_start: 0
future_window_end: 3

将来窓: 2024-01-01 ～ 2024-04-01（3ヶ月間）

ラベル: この3ヶ月間に1件でも貢献があるか？
  - 2024-01-15に貢献あり → True ✓
  - 2024-02-20に貢献あり → True ✓
  - 2024-03-25に貢献あり → True ✓
  - 何もなし → False
```

---

## 📊 ラベル期間比較実験

### 実験設計

```
目的: どのラベル期間が最も学習しやすいか？

固定:
  - 履歴窓: 12ヶ月
  - 訓練期間: 2022-2024（2年）
  - 評価期間: 2024-2025（1年）

可変:
  - ラベル期間: 1m, 3m, 6m, 12m
```

### 各実験の詳細

#### 実験 1: 1 ヶ月ラベル

```python
学習設定:
  future_window_start = 0
  future_window_end = 1

意味: サンプリング時点から0-1m範囲内に貢献があるか

例（サンプリング時点: 2022-01-01）:
  ラベル範囲: 2022-01-01 ～ 2022-02-01
  ラベル: この1ヶ月間に貢献あり？

評価設定:
  同じ（0-1m範囲内）
```

#### 実験 2: 3 ヶ月ラベル

```python
学習設定:
  future_window_start = 0
  future_window_end = 3

意味: サンプリング時点から0-3m範囲内に貢献があるか

例（サンプリング時点: 2022-01-01）:
  ラベル範囲: 2022-01-01 ～ 2022-04-01
  ラベル: この3ヶ月間に貢献あり？

評価設定:
  同じ（0-3m範囲内）
```

#### 実験 3: 6 ヶ月ラベル

```python
学習設定:
  future_window_start = 0
  future_window_end = 6

意味: サンプリング時点から0-6m範囲内に貢献があるか

例（サンプリング時点: 2022-01-01）:
  ラベル範囲: 2022-01-01 ～ 2022-07-01
  ラベル: この6ヶ月間に貢献あり？

評価設定:
  同じ（0-6m範囲内）
```

#### 実験 4: 12 ヶ月ラベル

```python
学習設定:
  future_window_start = 0
  future_window_end = 12

意味: サンプリング時点から0-12m範囲内に貢献があるか

例（サンプリング時点: 2022-01-01）:
  ラベル範囲: 2022-01-01 ～ 2023-01-01
  ラベル: この12ヶ月間に貢献あり？

評価設定:
  同じ（0-12m範囲内）
```

---

## 🔬 期待される結果

### 継続率の変化

```
期間が長いほど継続率は高くなる:

実験1（1m）: 継続率 70%
実験2（3m）: 継続率 80%
実験3（6m）: 継続率 85%
実験4（12m）: 継続率 90%

理由: 期間が長いほど「どこかで貢献する」確率が上がる
```

### 予測精度の変化

```
仮説: 中期（3-6m）が最も学習しやすい

実験1（1m）: AUC-PR 0.85 （短すぎて難しい）
実験2（3m）: AUC-PR 0.89 （バランスが良い）✓
実験3（6m）: AUC-PR 0.87 （やや長い）
実験4（12m）: AUC-PR 0.82 （長すぎる）

理由:
  - 1m: 継続率が低すぎて正例が少ない
  - 3m: 正例・負例のバランスが良く、パターンが学習しやすい
  - 12m: ほとんどが正例になり、識別が難しい
```

---

## 💻 実行方法

### フル実験

```bash
cd /Users/kazuki-h/rl/gerrit-retention
bash scripts/training/irl/run_label_period_comparison.sh
```

### クイックテスト

```bash
# テスト用（短期間・少エポック）
bash scripts/training/irl/run_quick_test_fixed_label.sh
```

---

## 📁 出力

```
outputs/label_period_comparison/
├── label_1m/
│   ├── irl_model.pth
│   ├── evaluation_results.json
│   └── training.log
├── label_3m/
│   ├── irl_model.pth
│   ├── evaluation_results.json
│   └── training.log
├── label_6m/
│   ├── irl_model.pth
│   ├── evaluation_results.json
│   └── training.log
├── label_12m/
│   ├── irl_model.pth
│   ├── evaluation_results.json
│   └── training.log
├── fixed_history_comparison.png      # 比較グラフ
├── detailed_metrics_comparison.png   # 詳細グラフ
├── sample_analysis.png               # サンプル分析
└── fixed_history_report.md           # レポート
```

---

## 📊 結果の見方

### JSON 結果（例: label_3m/evaluation_results.json）

```json
{
  "auc_roc": 0.5,
  "auc_pr": 0.892,
  "f1": 0.879,
  "precision": 0.785,
  "recall": 1.0,
  "test_samples": 724,
  "positive_samples": 568,
  "positive_rate": 0.785
}
```

### 重要な指標

1. **AUC-PR**: モデルの総合的な予測精度

   - 高いほど良い（0.8 以上が優秀）

2. **Precision**: 「継続する」と予測した人の的中率

   - 高いほど誤検知が少ない

3. **Recall**: 実際に継続した人の捕捉率

   - 高いほど見逃しが少ない

4. **継続率（positive_rate）**: ラベルの正例率
   - 0.5 付近がバランスが良い
   - 0.9 以上だと識別が難しい

### 比較のポイント

```
各実験の結果を比較:

              AUC-PR  継続率  バランス
実験1（1m）:   0.85    0.70    やや低い
実験2（3m）:   0.89    0.80    良好 ✓
実験3（6m）:   0.87    0.85    やや高い
実験4（12m）:  0.82    0.90    高すぎ

結論: 3ヶ月が最も学習しやすい
```

---

## ❓ よくある質問

### Q1: なぜ「範囲内」なのか？「時点」ではないのか？

**A:** 実用的には「範囲内」の方が自然です。

```
時点の場合:
  「ちょうど3ヶ月後に貢献するか」
  → 3ヶ月1日後だとカウントされない（不自然）

範囲の場合:
  「0-3ヶ月の間に貢献するか」
  → いつでも良い（自然）
```

### Q2: 学習期間内で完結とは？

**A:** すべてのデータが訓練期間内に収まることを保証します。

```
訓練期間: 2022-01-01 ～ 2024-01-01

サンプリング時点: 2023-10-01
  履歴: 2022-10-01 ～ 2023-10-01 ✓（訓練期間内）
  将来: 2023-10-01 ～ 2024-01-01 ✓（訓練期間内）

サンプリング時点: 2023-11-01（NG例）
  履歴: 2022-11-01 ～ 2023-11-01 ✓
  将来: 2023-11-01 ～ 2024-02-01 ✗（訓練期間を超える！）
  → このサンプルは除外される
```

### Q3: 異なるラベル期間で訓練したモデルは互換性があるか？

**A:** ありません。各期間ごとに専用のモデルです。

```
1mモデル: 1m範囲を予測するように訓練
3mモデル: 3m範囲を予測するように訓練

1mモデルで3m範囲を予測すると精度が下がる
```

もし 1 つのモデルで複数期間を予測したい場合は、
別のスクリプト（`train_irl_fixed_train_label_multi_eval.py`）を使用してください。

---

## 🎯 まとめ

**確認事項:**

- ✅ 予測は「範囲内」です
- ✅ 学習も「範囲内」です
- ✅ 学習期間内で完結します
- ✅ 各ラベル期間ごとに専用モデルを訓練します

**実験の目的:**

- どのラベル期間が最も学習しやすいかを比較
- 継続率と予測精度のバランスを分析
- 実用的な設定を見つける

**推奨:**

- まずフル実験を実行
- 結果を分析して最適な期間を特定
- 論文やレポートにまとめる
