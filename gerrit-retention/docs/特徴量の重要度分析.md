# 特徴量の重要度分析

## 概要

IRL モデルが使用している特徴量とその重要度を分析するためのガイドです。

## 使用している特徴量

### 状態特徴量（State Features）- 10 次元

| No. | 特徴量名         | 説明                         | 正規化        |
| --- | ---------------- | ---------------------------- | ------------- |
| 1   | 経験日数         | 初回活動からの経過日数       | /365 (年単位) |
| 2   | 総変更数         | これまでの総コミット数       | /100          |
| 3   | 総レビュー数     | これまでの総レビュー数       | /100          |
| 4   | プロジェクト数   | 参加プロジェクト数           | /10           |
| 5   | 最近の活動頻度   | 直近 30 日の活動頻度         | -             |
| 6   | 平均活動間隔     | 活動間の平均日数             | /30 (月単位)  |
| 7   | 活動トレンド     | increasing/stable/decreasing | one-hot 的    |
| 8   | 協力スコア       | 他の開発者との協力度         | 0-1           |
| 9   | コード品質スコア | コード品質の推定値           | 0-1           |
| 10  | 時間経過         | context_date からの経過      | /365 (年単位) |

### 行動特徴量（Action Features）- 5 次元

| No. | 特徴量名   | 説明                     | 正規化        |
| --- | ---------- | ------------------------ | ------------- |
| 1   | 行動タイプ | commit/review/merge 等   | エンコード値  |
| 2   | 強度       | 行動の強度（変更規模等） | 0-1           |
| 3   | 品質       | 行動の品質               | 0-1           |
| 4   | 協力度     | その行動での協力度       | 0-1           |
| 5   | 時間経過   | 行動からの経過時間       | /365 (年単位) |

## 特徴量の重要度測定方法

### 1. Permutation Importance（推奨）

**原理:**

- 各特徴量を 1 つずつランダムな値に置き換える
- モデルの性能（AUC-ROC）がどれだけ低下するかを測定
- 低下が大きい = その特徴量が重要

**利点:**

- 実装が簡単
- 解釈が直感的
- モデルに依存しない

**実行方法:**

```bash
uv run python scripts/analysis/feature_importance_analysis.py \
  --model outputs/full_cross_eval/train_0-3m/irl_model.pt \
  --reviews data/review_requests_openstack_multi_5y_detail.csv \
  --eval-start 2023-01-01 \
  --eval-end 2024-01-01 \
  --history-window 12 \
  --future-window-start 0 \
  --future-window-end 3 \
  --output outputs/feature_importance \
  --method permutation \
  --n-repeats 10
```

### 2. Gradient-based Importance

**原理:**

- 予測値に対する各特徴量の勾配を計算
- 勾配の絶対値が大きい = その特徴量が予測に強く影響

**利点:**

- 計算が速い
- 特徴量間の相互作用を考慮

**実行方法:**

```bash
uv run python scripts/analysis/feature_importance_analysis.py \
  --model outputs/full_cross_eval/train_0-3m/irl_model.pt \
  --reviews data/review_requests_openstack_multi_5y_detail.csv \
  --eval-start 2023-01-01 \
  --eval-end 2024-01-01 \
  --history-window 12 \
  --future-window-start 0 \
  --future-window-end 3 \
  --output outputs/feature_importance \
  --method gradient
```

### 3. 両方実行

```bash
uv run python scripts/analysis/feature_importance_analysis.py \
  --model outputs/full_cross_eval/train_0-3m/irl_model.pt \
  --reviews data/review_requests_openstack_multi_5y_detail.csv \
  --eval-start 2023-01-01 \
  --eval-end 2024-01-01 \
  --history-window 12 \
  --future-window-start 0 \
  --future-window-end 3 \
  --output outputs/feature_importance \
  --method both \
  --n-repeats 10
```

## 出力結果

### 1. feature_importance.json

各手法での特徴量重要度スコア:

```json
{
  "baseline_auc": 0.6234,
  "n_samples": 260,
  "methods": {
    "permutation": {
      "state": {
        "0": 0.0234,  // 経験日数
        "1": 0.0456,  // 総変更数
        "2": 0.0123,  // 総レビュー数
        ...
      },
      "action": {
        "0": 0.0089,  // 行動タイプ
        "1": 0.0234,  // 強度
        ...
      }
    },
    "gradient": {
      ...
    }
  }
}
```

### 2. 可視化ファイル

- `feature_importance_permutation.png`: Permutation Importance の棒グラフ
- `feature_importance_gradient.png`: Gradient-based Importance の棒グラフ

## 実行中のモデルで確認

現在実行中のクロス評価の結果で重要度を分析:

```bash
# 0-3m訓練モデルで分析
uv run python scripts/analysis/feature_importance_analysis.py \
  --model outputs/full_cross_eval/train_0-3m/irl_model.pt \
  --reviews data/review_requests_openstack_multi_5y_detail.csv \
  --eval-start 2023-01-01 \
  --eval-end 2024-01-01 \
  --history-window 12 \
  --future-window-start 0 \
  --future-window-end 3 \
  --output outputs/feature_importance_0-3m \
  --method both \
  --n-repeats 10
```

## 解釈のポイント

### Permutation Importance

- **スコアが正**: その特徴量は性能向上に寄与
- **スコアが負**: その特徴量はノイズか過学習の可能性
- **スコアがゼロ**: その特徴量は使われていない

### Gradient-based Importance

- **値が大きい**: 予測に強く影響
- **値が小さい**: 予測への影響が小さい

## クロス評価での比較

異なる訓練ラベル（0-1m, 0-3m, 0-6m 等）で訓練したモデルで特徴量重要度がどう変わるかを比較:

```bash
# 各モデルで重要度分析
for LABEL in "0-1m" "0-3m" "0-6m" "0-9m" "0-12m"; do
  uv run python scripts/analysis/feature_importance_analysis.py \
    --model outputs/full_cross_eval/train_${LABEL}/irl_model.pt \
    --reviews data/review_requests_openstack_multi_5y_detail.csv \
    --eval-start 2023-01-01 \
    --eval-end 2024-01-01 \
    --history-window 12 \
    --future-window-start 0 \
    --future-window-end 3 \
    --output outputs/feature_importance_${LABEL} \
    --method both \
    --n-repeats 5
done
```

## 今後の拡張可能性

### SHAP 値（Shapley Additive Explanations）

より詳細な特徴量の寄与度分析が可能:

```python
import shap

# SHAP Explainerの作成
explainer = shap.DeepExplainer(model, background_data)
shap_values = explainer.shap_values(test_data)

# 可視化
shap.summary_plot(shap_values, test_data, feature_names=STATE_FEATURE_NAMES)
```

### Attention Weights（将来実装）

LSTM に Attention 機構を追加すれば、どの時点の活動が重要か可視化可能。

## トラブルシューティング

### エラー: モデルが読み込めない

```bash
# configを確認
python -c "import torch; print(torch.load('model.pt', map_location='cpu').keys())"
```

### 重要度がすべてゼロ

- モデルが正しく学習できていない可能性
- 評価データが少なすぎる可能性
- `--n-repeats` を増やして試す

### 実行が遅い

- `--n-repeats` を減らす（デフォルト 5→3）
- Gradient-based 手法のみ使用（より高速）
