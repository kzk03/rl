# 全シーケンス＋月次集約ラベル実験結果

**実験日時**: 2025-10-23  
**実験目的**: サンプリングを廃止し、全シーケンス＋月次集約ラベルで適切な継続率と高精度を達成する

---

## 📊 実験結果サマリー

### ✅ **大幅改善を達成！**

| 指標           | 従来手法  | 今回の手法 | 改善率    |
| -------------- | --------- | ---------- | --------- |
| **AUC-ROC**    | ~0.50     | **0.740**  | **+48%**  |
| **AUC-PR**     | N/A       | **0.849**  | -         |
| **Precision**  | 0.00-0.59 | **0.825**  | -         |
| **Recall**     | 1.00      | **0.588**  | -         |
| **F1 Score**   | 0.00-0.74 | **0.686**  | -         |
| **訓練継続率** | 98-100%   | **34.4%**  | ✅ 適正化 |

---

## 🔧 実験設定

### データ構成

```
学習期間: 2021-01-01 ～ 2023-01-01 (2年間)
評価期間: 2023-01-01 ～ 2024-01-01 (1年間)
将来窓: 0-3ヶ月
履歴窓: 12ヶ月
```

### モデル設定

```
エポック数: 5
最適化手法: Adam
損失関数: Binary Cross Entropy (クラス重み付き)
負例重み: 51.67 (継続率34.4%に基づく)
```

### データ統計

```
訓練サンプル数: 355レビュアー
総ステップ数: 60,461
レビュアー単位継続率: 34.4% (122/355)
ステップ単位継続率: 98.1% (参考値)

評価サンプル数: 260レビュアー
評価継続率: 61.5% (160/260)
```

---

## 📈 訓練経過

### 損失推移

```
エポック0: 5.2705
最終損失: 2.4653
損失減少率: 53.4%
```

### 評価メトリクス（最適閾値 0.100）

```json
{
  "auc_roc": 0.74,
  "auc_pr": 0.849,
  "precision": 0.825,
  "recall": 0.588,
  "f1": 0.686,
  "optimal_threshold": 0.1,
  "sample_count": 260,
  "positive_count": 160,
  "negative_count": 100,
  "continuation_rate": 0.615
}
```

---

## 🎯 成功した要因

### 1. **サンプリング廃止**

- **従来**: 各レビュアーから月次で複数サンプル抽出
- **改善**: 各レビュアーから 1 サンプルのみ
- **効果**:
  - データの独立性が向上
  - 過学習リスク低減
  - 継続率が適正化（34.4%）

### 2. **全シーケンス活用**

- **従来**: 固定長（seq_len=20, 50 等）で履歴を切断
- **改善**: 可変長 LSTM で全活動履歴を使用
- **効果**:
  - 情報損失ゼロ
  - 長期的パターン学習が可能
  - 60,461 ステップの豊富な学習データ

### 3. **月次集約ラベル**

- **ラベル付けロジック**:
  ```
  各月末から0-3ヶ月後に活動があるか
  → 同月内の全活動に同一ラベルを適用
  ```
- **効果**:
  - 各ステップでの極端な継続バイアス解消
  - レビュアー単位での継続判定が可能
  - 最終月のラベルで継続率評価

### 4. **レビュアー単位評価**

- **評価方法**: 最終月のラベルで継続/非継続を判定
- **効果**: 実際のビジネス目標（開発者継続予測）に一致

---

## 📁 出力ファイル

```
outputs/test_variable_length/train_0-3m_variable_length/
├── irl_model.pt              # 学習済みモデル
├── metrics.json              # 評価メトリクス
├── training.log              # 訓練ログ
├── train_trajectories.pkl    # 訓練データ
└── eval_trajectories.pkl     # 評価データ
```

---

## 🔄 次のステップ

### 短期的改善（推奨）

1. **エポック数増加**: 5 → 20-30

   - 損失がまだ減少傾向
   - さらなる精度向上が期待できる

2. **将来窓の最適化**: 0-1m, 0-6m, 0-9m, 0-12m で比較
   - 最適な予測期間の特定

### 中期的改善

3. **クロス評価**: 異なる訓練ラベルで評価

   ```
   訓練: 0-1m, 0-3m, 0-6m, 0-9m, 0-12m
   評価: 0-3m, 3-6m, 6-9m, 9-12m
   ```

4. **ハイパーパラメータチューニング**:
   - LSTM 層数・次元数
   - Dropout 率
   - 学習率スケジューリング

### 長期的改善

5. **データ拡張**: より長い学習期間（3-5 年）
6. **特徴量エンジニアリング**: プロジェクト固有特徴、ソーシャルネットワーク特徴など
7. **アンサンブル学習**: 複数モデルの組み合わせ

---

## 📊 比較: 従来手法 vs 新手法

| 項目             | 従来手法                  | 新手法（全シーケンス＋月次集約）            |
| ---------------- | ------------------------- | ------------------------------------------- |
| **サンプリング** | 月次サンプリング          | サンプリングなし（1 レビュアー=1 サンプル） |
| **シーケンス長** | 固定（seq_len=20, 50 等） | 可変長（全活動履歴）                        |
| **ラベル付け**   | 各ステップ個別            | 月次集約                                    |
| **継続率評価**   | ステップ単位              | レビュアー単位（最終月）                    |
| **訓練継続率**   | 98-100%（不適切）         | 34.4%（適正）                               |
| **AUC-ROC**      | ~0.50                     | **0.740**                                   |
| **実用性**       | ❌ ランダム予測レベル     | ✅ 実用可能レベル                           |

---

## 💡 重要な学び

### 1. **継続率が精度の鍵**

- 不均衡すぎるラベル（98%継続）では学習不可能
- 適切なバランス（34.4%継続）で大幅改善

### 2. **サンプリングが諸悪の根源**

- 月次サンプリングでデータが偏る
- 1 レビュアー 1 サンプルで明確な学習が可能

### 3. **月次集約が最適解**

- 各ステップ個別: 99%継続（学習不可能）
- サンプリングポイント単一: 適正だが情報損失
- 月次集約: 適正＋各ステップで学習

### 4. **全シーケンスの重要性**

- 固定長で切ると長期パターンを見逃す
- 可変長 LSTM で全履歴を活用

---

## ✅ 結論

**全シーケンス＋月次集約ラベルのアプローチが成功！**

- AUC-ROC 0.740 を達成（従来の 0.5 から+48%改善）
- 適切な継続率（34.4%）でバランス良く学習
- エポック数増加でさらなる改善が期待できる

**この手法を標準として、今後の実験を進めることを推奨します。**
