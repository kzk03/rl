# Precision-Recall不均衡の分析

## 問題の発見

新版（スライディングウィンドウ）では、**Precisionは高いがRecallが低い**という不均衡が見られる。

## 数値の比較

### 従来版（累積ラベル）nova

| 訓練ラベル | Precision | Recall | F1    | バランス |
| ---------- | --------- | ------ | ----- | -------- |
| 0-1m       | 0.958     | 0.821  | 0.885 | ✅ 良好   |
| 0-3m       | 0.923     | 0.667  | 0.774 | ⚠️ やや偏り |
| 0-12m      | 0.769     | 0.800  | 0.784 | ✅ 良好   |

### 新版（スライディングウィンドウ）nova

| 訓練ラベル | Precision | Recall | F1    | バランス |
| ---------- | --------- | ------ | ----- | -------- |
| 0-3m       | 0.923     | 0.522  | 0.667 | ❌ 不均衡  |
| 3-6m       | 1.000     | 0.522  | 0.686 | ❌ 不均衡  |
| 6-9m       | 0.724     | 0.600  | 0.656 | ⚠️ やや偏り |
| 9-12m      | 0.774     | 0.558  | 0.649 | ⚠️ やや偏り |

**特に train_3-6m**: Precision 1.00（完璧）だが Recall 0.52（半分見逃し）

---

## この不均衡の意味

### Precision高い・Recall低い = 保守的な予測

```
予測「継続する」:
  ✅ 予測した人はほぼ確実に継続する（Precision 0.92-1.00）
  ❌ 継続する人の半分しか見つけられない（Recall 0.52-0.60）
```

### 具体例

```
実際の継続者: 100人

新版の予測:
  予測「継続」: 52人 → 実際に継続: 52人 (Precision 1.00)
  予測「離脱」: 48人 → 実際には継続してた (見逃し)
  
  Recall = 52/100 = 0.52
```

### 比較：従来版

```
実際の継続者: 100人

従来版の予測:
  予測「継続」: 85人 → 実際に継続: 82人 (Precision 0.96)
  予測「離脱」: 15人 → 実際には継続してた (見逃し)
  
  Recall = 82/100 = 0.82
```

---

## 原因分析

### 1. クラス不均衡の影響

```
継続率の違い:
- 従来版 train_0-1m: 36.4% (少数派だが適度)
- 新版 train_0-3m:   27.5% (より少数派)
- 新版 train_6-9m:   21.0% (非常に少数派)

→ 継続者がより少ない
→ モデルが保守的になる
```

### 2. Focal Lossの設定

現在の設定:
```python
alpha = 0.3  # 正例（継続者）の重み
gamma = 3.0  # 難しい例への集中度
```

**問題点**:
- `gamma=3.0` が高すぎる可能性
- 「確信できる例」だけを学習
- 境界線上の例を「離脱」と予測しがち

### 3. 閾値の問題

最適閾値の確認:
```
train_0-3m: threshold = 0.11 (非常に低い)
train_3-6m: threshold = ?
```

→ 閾値が低いのに Recall が低い = 予測確率が極端に偏っている可能性

### 4. タスクの難しさ

```
新版のタスク:
「いつ活動するか」を予測 → より難しい
→ モデルが確信できる人だけ「継続」と予測
→ Precision ↑, Recall ↓
```

---

## 予測確率分布の確認が必要

### 仮説1: 予測確率が0か1に偏っている

```
良い分布:
  継続者: 0.6-0.9の確率を持つ人が多い
  離脱者: 0.1-0.4の確率を持つ人が多い

悪い分布（現状の可能性）:
  ほとんどの人: 0.0-0.2の確率
  ごく一部: 0.8-1.0の確率
  → 0.8-1.0の人は確実に継続（Precision高）
  → でも数が少ない（Recall低）
```

### 仮説2: 学習が不十分

```
サンプル数が少ない:
  nova単一プロジェクト: ~167サンプル
  継続者（正例）: ~46人

→ 学習データ不足
→ 保守的な予測
```

---

## 解決策

### 優先度高：すぐ実装可能

#### 1. Focal Loss のパラメータ調整

```python
# 現在
alpha = 0.3  # → 0.4-0.5 に増やす（正例の重み増）
gamma = 3.0  # → 2.0 に減らす（難しい例への集中を緩和）

# 調整後
alpha = 0.4  # 正例をより重視
gamma = 2.0  # 境界線上の例も学習
```

#### 2. クラスウェイトの調整

```python
# 現在（動的計算）
pos_weight = neg_count / pos_count

# 提案
pos_weight = min(neg_count / pos_count * 1.5, 5.0)
# → 正例の重みを1.5倍増やす（上限5.0）
```

#### 3. 閾値の調整

```python
# 現在: F1最大化で閾値選択
# 提案: Recall優先の閾値選択

# Recallが0.7以上になる最大閾値を選ぶ
target_recall = 0.70
optimal_threshold = find_threshold_for_recall(target_recall)
```

### 優先度中：少し手間

#### 4. データ増強

```python
# 複数プロジェクトのデータを使う
# 現状: nova単一（167サンプル）
# 改善: 全プロジェクト（数千サンプル）
```

#### 5. モデルの正則化緩和

```python
# 現在
dropout = 0.3

# 提案
dropout = 0.1-0.2  # 過学習を恐れず学習
```

### 優先度低：大きな変更

#### 6. Label Smoothing

```python
# 正例: 1.0 → 0.9
# 負例: 0.0 → 0.1
# → モデルの過信を防ぐ
```

#### 7. アンサンブル学習

```python
# 複数モデルの予測を平均
# → より安定した予測
```

---

## 実装の優先順位

### Phase 1: パラメータチューニング（即実装）

1. **Focal Loss調整**:
   ```bash
   alpha=0.4, gamma=2.0 で再学習
   ```

2. **閾値調整**:
   ```bash
   Recall優先の閾値選択（target_recall=0.70）
   ```

3. **実行**:
   ```bash
   # 1つのモデルでテスト
   uv run scripts/training/irl/train_irl_sliding_window.py \
     --future-window-start 0 --future-window-end 3 \
     --project openstack/nova --epochs 30
   ```

### Phase 2: データとモデル（時間かかる）

4. **複数プロジェクトで再実行**:
   ```bash
   # projectオプションを外す
   bash scripts/training/irl/run_sliding_cross_evaluation.sh
   ```

5. **Dropout調整**:
   ```python
   # retention_irl_system.py を修正
   dropout = 0.2
   ```

---

## 期待される改善

### Phase 1 実装後

```
改善前:
  Precision: 0.92, Recall: 0.52, F1: 0.67

改善後（予測）:
  Precision: 0.75-0.85, Recall: 0.65-0.75, F1: 0.70-0.80

→ Recallが+15-20%向上
→ Precisionは若干低下するが許容範囲
→ F1は向上
```

### Phase 2 実装後

```
さらなる改善（予測）:
  Precision: 0.80-0.90, Recall: 0.70-0.80, F1: 0.75-0.85

→ より多くのデータで安定化
```

---

## 実用上の考慮

### 現状の Precision高・Recall低 でも使える場合

**用途**: 確実な継続者の特定
- ✅ 「この人は確実に継続する」→ 重要タスクを任せる
- ✅ False Positive（誤検出）を避けたい

### Recall向上が必要な場合

**用途**: 離脱リスクの早期発見
- ✅ 「継続しそうな人を見逃さない」→ 全員に介入策
- ✅ False Negative（見逃し）を避けたい
- → **こちらが研究の本来の目的**

---

## 次のステップ

1. ✅ **予測確率分布の可視化** → 現状把握
2. ⚠️ **Focal Loss調整** → 即実装
3. ⚠️ **閾値調整** → 即実装
4. ⬜ **複数プロジェクトで再実行** → 時間があれば

どれから始めますか？
