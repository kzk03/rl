# 閾値決定方法の試行錯誤

## 📊 問題の背景

### Recall=1.0の問題
評価データでの予測において、Recall=1.0となるケースが頻発しました。これは「全サンプルを継続予測している」ことを意味します。

## 🔍 原因分析

### 予測確率の分布
- **範囲**: [0.449, 0.482] （非常に狭い）
- **標準偏差**: 0.003～0.005程度
- **分散**: 極めて小さい

### 根本原因
予測確率の分散が非常に小さいため、どんな閾値を選んでも全サンプルが同じクラスに分類されてしまいます。

## 🧪 試した方法

### 1. 訓練データで閾値決定（F1最大化）
**手法**: 訓練データ上で最適閾値を探索（F1スコア最大化）

**結果**:
- 訓練データ上では機能
- 評価データで分布シフト
- 訓練データ: 閾値 = 0.4439
- 評価データ: 最小確率 = 0.4486
- **→ 全サンプルが閾値以上 → Recall=1.0**

**問題点**: 訓練データと評価データで予測確率の分布が異なる

### 2. 正例率ベースの閾値決定
**手法**: 訓練データの正例率に基づいてパーセンタイル閾値を設定

**結果**:
- 訓練データ上では機能（Precision=0.545, Recall=0.571）
- 評価データで分布シフト
- **→ 全サンプルが閾値以上 → Recall=1.0**

**問題点**: 訓練データと評価データで予測確率の分布が異なる

### 3. 評価データ上で閾値決定（元の方法）
**手法**: 評価データ上で最適閾値を探索（F1スコア最大化）

**結果**:
- 評価データ上で最適化される
- Recall=1.0の問題は回避される

**問題点**: データリーク（評価データの正解ラベルを見てから閾値を決めている）

## 💡 結論

### 根本的な問題
**予測確率の分散が小さい**ことが問題の根本原因です。

### 分散が小さい理由
1. **特徴量の影響が小さい**: 多くの特徴量が正規化されており、違いが小さくなっている
2. **モデルの学習不足**: データが少ない、または学習が不十分
3. **データの性質**: レビュー承諾の予測自体が困難

### 現実的な対応

#### 1. 閾値に依存しない指標を重視
- **AUC-PR**: 閾値に依存しない
- **AUC-ROC**: 閾値に依存しない
- 現在のモデルはAUC-PR=0.718と良好

#### 2. 予測確率そのものを使う
- 閾値で二値化せず、確率そのものを使う
- ランキングでの利用
- リスク評価での利用

#### 3. 予測確率の分散を拡大
- **温度スケーリング**: 出力確率を調整
- **Dropout調整**: 過学習を防ぎ、分散を拡大
- ただし、性能が低下する可能性（実際に0.718→0.647に低下）

#### 4. 実際の運用では人間が調整
- 閾値を固定値（0.5）で運用
- または、ドメイン知識に基づいて閾値を調整
- ビジネス要件に応じて調整

## 📊 各方法の比較

| 方法 | AUC-PR | Recall=1.0 | データリーク | 実用性 |
|------|--------|-----------|-------------|--------|
| 評価データで探索 | 0.718 | ❌ なし | ⚠️ あり | ✅ 高 |
| 訓練データで探索 | 0.647 | ❌ あり | ✅ なし | ⚠️ 低 |
| 固定閾値（0.5） | ? | ? | ✅ なし | ⚠️ 中 |

## 🎯 推奨されるアプローチ

### 短期対応
1. **閾値に依存しない指標（AUC-PR）を重視**
2. **評価データ上で閾値を決定**（データリークありだが実用的）
3. **実際の運用では人間が調整**

### 長期対応
1. **予測確率の分散を拡大する方法を研究**
2. **特徴量の改善**
3. **モデルアーキテクチャの改善**

## 📅 実施日

2024年10月30日

## 🔗 関連ドキュメント

- [結果考察と特徴量重要度分析.md](結果考察と特徴量重要度分析.md)
- [デフォルト値14日の影響.md](デフォルト値14日の影響.md)
- [再訓練結果_デフォルト値3日.md](再訓練結果_デフォルト値3日.md)

