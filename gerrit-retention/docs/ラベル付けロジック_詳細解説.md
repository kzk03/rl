# ラベル付けロジック - 詳細解説

## 概要

現在のシステムは「レビュアーが将来のレビュー依頼を受諾するかどうか」を予測することを目的としています。

---

## 期間設定

### 例: `train_0-3m` の場合

```
訓練開始日: 2021-01-01
訓練終了日: 2023-01-01 (cutoff)
特徴量計算期間: 2021-01-01 ～ 2023-01-01
ラベル計算期間: 2023-01-01 ～ 2023-04-01 (0-3ヶ月後)
履歴ウィンドウ: 12ヶ月
```

---

## 手順 1: サンプル抽出

### 処理内容

1. **期間**: 特徴量計算期間（2021-01 ～ 2023-01）にレビュー依頼を受けたレビュアーを抽出
2. **条件**: 最小依頼数 3 件以上
3. **例**: レビュアー A（依頼 5 件）

### コード位置

- ファイル: `scripts/training/irl/train_irl_review_acceptance.py`
- 行 169-184

```python
active_reviewers = history_df[reviewer_col].unique()

for reviewer in active_reviewers:
    reviewer_history = history_df[history_df[reviewer_col] == reviewer]

    # 最小レビュー依頼数を満たさない場合はスキップ
    if len(reviewer_history) < min_history_requests:
        skipped_min_requests += 1
        continue
```

---

## 手順 2: ラベル付け（全体ラベル）

### 2-1. ラベル計算期間に依頼がない場合

**処理**: 除外される（スキップ）

**例**:

- レビュアー C
- ラベル計算期間（2023-01 ～ 2023-04）に依頼なし
- → 訓練サンプルから除外

**問題点**:

- 0-3m で活動がなく、4 ヶ月目に依頼があった開発者 → 除外される
- これにより訓練サンプル数が減少（32 人、44 人など）

### 2-2. ラベル計算期間に依頼があり、1 件以上承諾

**処理**: 正例（future_acceptance=True）

**例**:

- レビュアー A は 3 件の依頼を受けた
- 承諾した依頼: 2 件
- 拒否した依頼: 1 件
- → `future_acceptance = True`

### 2-3. ラベル計算期間に依頼があり、全て拒否

**処理**: 負例（future_acceptance=False）

**例**:

- レビュアー B は 2 件の依頼を受けた
- 承諾した依頼: 0 件
- 拒否した依頼: 2 件
- → `future_acceptance = False`

### コード位置

- ファイル: `scripts/training/irl/train_irl_review_acceptance.py`
- 行 187-203

```python
# ラベル計算期間のレビュー依頼
reviewer_label = label_df[label_df[reviewer_col] == reviewer]

# ラベル計算期間にレビュー依頼を受けていない場合はスキップ
if len(reviewer_label) == 0:
    skipped_no_label_requests += 1
    continue

# 継続判定：ラベル計算期間内に少なくとも1つのレビュー依頼を承諾したか
accepted_requests = reviewer_label[reviewer_label[label_col] == 1]
rejected_requests = reviewer_label[reviewer_label[label_col] == 0]
future_acceptance = len(accepted_requests) > 0
```

---

## 手順 3: 月次ラベル付け（LSTM 訓練用）

### 処理内容

特徴量計算期間の各月について、将来期間での受諾状況をラベルとして付与します。

### 例: 2021-01 月の場合

```
対象月: 2021-01
ラベル計算期間: 2021-01 ～ 2021-04 (3ヶ月後)

ケース1: 将来期間に依頼を受けなかった
  → ラベル = 0

ケース2: 将来期間に依頼を受け、1件以上承諾した
  → ラベル = 1

ケース3: 将来期間に依頼を受けたが、全て拒否
  → ラベル = 0
```

### コード位置

- ファイル: `scripts/training/irl/train_irl_review_acceptance.py`
- 行 205-246

```python
for month_start in history_months[:-1]:
    month_end = month_start + pd.DateOffset(months=1)

    # 将来期間の計算
    future_start = month_end + pd.DateOffset(months=future_window_start_months)
    future_end = month_end + pd.DateOffset(months=future_window_end_months)

    # 将来期間のレビュー依頼
    month_future_df = df[
        (df[date_col] >= future_start) &
        (df[date_col] < future_end) &
        (df[reviewer_col] == reviewer)
    ]

    # ラベルの決定
    if len(month_future_df) == 0:
        # レビュー依頼なし → ラベル0
        month_label = 0
    else:
        # レビュー依頼あり → 承諾の有無
        month_accepted = month_future_df[month_future_df[label_col] == 1]
        month_label = 1 if len(month_accepted) > 0 else 0
```

---

## 問題点

### 1. 評価期間を超えた依頼は考慮されない

**問題**:

- 0-3m で活動がなく、4 ヶ月目に依頼があった開発者 → 除外される
- 理由: 行 191-193 で「ラベル計算期間に依頼がない場合はスキップ」

**影響**:

- 訓練サンプル数が減少
- 一部の開発者の行動パターンが学習されない

### 2. 拒否履歴と離脱の関係が不明確

**問題**:

- 過去に全て拒否 → 現在も拒否 → 将来も拒否？
- 一度拒否したら離脱したと判定すべき？

**現在の処理**:

- 全て拒否しても `0` となり、離脱とは判定されない
- 行 238-244 の処理より

**影響**:

- 離脱予測ができない
- 拒否パターンの学習が不十分

### 3. 訓練サンプル数が少ない

**問題**:

- train_0-3m: 44 人
- train_3-6m: 45 人
- train_6-9m: 32 人 ⚠️
- train_9-12m: 39 人

**影響**:

- train_6-9m で Recall=1.0 問題が発生
- モデルの汎化性能が低下

---

## ユーザーの質問への回答

### Q1: 0-3m で活動がなくて 4 ヶ月目に依頼があった開発者はどうなる？

**回答**: 除外される

**理由**:

- 行 191-193 で「ラベル計算期間に依頼がない場合はスキップ」
- 4 ヶ月目の依頼は評価期間を超えているため、考慮されない

**改善策**:

- 評価期間を延長（例: 0-6m、0-12m）
- より長期的な行動パターンを学習

### Q2: 一旦拒否判定になった開発者は離脱判定になる？

**回答**: ならない

**理由**:

- 行 238-244 で「依頼がない=0、依頼ありで承諾=1、依頼ありで拒否=0」
- 全て拒否しても離脱とは判定されない
- 単に「受諾しなかった（0）」という扱い

**改善策**:

- 拒否履歴を考慮した離脱判定を追加
- 例: 直近 N 回全て拒否 → 離脱判定
- 例: 拒否率が閾値を超えた → 離脱判定

---

## 改善案

### ✅ 実装済み: 拡張ラベル期間チェック（オプション3の改良版）

**実装日**: 2025-10-30

**内容**:

- 現在: 評価期間に依頼がない場合、除外
- 改善: 依頼がない場合、拡張期間（0-12m）をチェック
  - 拡張期間に依頼あり → 負例または正例として扱う
  - 拡張期間にも依頼なし → 除外（本当に離脱）

**メリット**:

- 訓練サンプル数が増加（0-3mで依頼なしでも4ヶ月目以降に活動があるケースを含む）
- より正確な学習（短期では活動なしだが長期では継続しているパターンを学習）
- ノイズを抑制（拡張期間にも依頼がない場合は除外）

**実装詳細**:

- `extended_label_window_months` パラメータを追加（デフォルト12ヶ月）
- `extract_review_acceptance_trajectories` 関数に実装
- `extract_evaluation_trajectories` 関数に実装
- 統計情報に「拡張期間で救済」カウントを追加

**ラベル付けロジック**（修正版 - 期間特化型）:

1. ラベル期間（0-3m）に依頼がある場合：
   - 承諾あり → 正例（1）
   - 全て拒否 → 負例（0）

2. ラベル期間（0-3m）に依頼がない場合：
   - 拡張期間（0-12m）をチェック
   - 拡張期間に依頼あり → **負例（0）** ✅ この期間では活動しなかった
   - 拡張期間にも依頼なし → 除外（本当に離脱）

**重要な変更点**:
- 拡張期間で活動があっても、**ラベル期間で活動がなければ負例（0）**
- これにより、各モデルが**その期間特有の貢献パターン**を学習

**損失関数への影響**: なし（ラベルは2値のまま、Binary Cross Entropy継続使用可能）

**重み付きバイナリラベル**（さらなる改善）:

- 拡張期間チェックで負例になったサンプルには**低い重み（0.5）**を付与
- 通常の依頼あり→拒否のサンプルには**通常の重み（1.0）**を付与
- これにより、「依頼あり→拒否」と「依頼なし」を区別して学習

```python
trajectory = {
    'future_acceptance': 0 or 1,  # ラベル（2値）
    'had_requests': True or False,  # 依頼があったか
    'sample_weight': 1.0 or 0.5     # サンプル重み
}

# 損失計算時
loss = bce_loss(pred, label)
weighted_loss = loss * sample_weight  # 重み適用
```

**重みの意味**:
- `weight=1.0`: 依頼あり→拒否 → 明確な拒否シグナル、重要
- `weight=0.5`: 依頼なし → 不確実（アサインされなかっただけ）、重要度低

**学習される内容**:
- **0-3mモデル**: 即時貢献する人の特徴・行動パターンを学習
- **3-6mモデル**: 3-6mに貢献する人の特徴・行動パターンを学習
- **6-9mモデル**: 6-9mに貢献する人の特徴・行動パターンを学習
- **9-12mモデル**: 9-12mに貢献する人の特徴・行動パターンを学習

**IRLでの学習メカニズム**:
- 各モデルは報酬関数を通じて「いつ活動する人か」を区別
- 例: 高頻度活動 → 0-3mモデルで高報酬、6-9mモデルで低報酬
- 例: 断続的活動 → 6-9mモデルで高報酬、0-3mモデルで低報酬

**予測時の活用**:
- 各モデルで予測スコアを取得
- スコアが高いモデルの期間 → その期間にアサインすべき
- 「いつアサインすべきか」の最適なタイミングを判断可能

---

### オプション 1: 評価期間を延長（未実装）

**内容**:

- 現在: 0-3m、3-6m、6-9m、9-12m
- 改善: 0-6m、0-12m、0-18m も追加

**メリット**:

- より長期的な行動パターンを学習
- 訓練サンプル数が増加

**デメリット**:

- 評価が長くなる
- ラベルが不正確になる可能性

### オプション 2: 拒否履歴を考慮した離脱判定を追加（未実装）

**内容**:

- 直近 N 回全て拒否 → 離脱判定
- 拒否率が閾値を超えた → 離脱判定

**メリット**:

- 離脱予測が可能
- 拒否パターンの学習が向上

**デメリット**:

- 離脱の定義が難しい
- 仮説検証が必要

---

## 関連ファイル

- `scripts/training/irl/train_irl_review_acceptance.py`
  - 行 160-321: 訓練用軌跡抽出（`extract_training_trajectories`）
  - 行 324-483: 評価用軌跡抽出（`extract_evaluation_trajectories`）

---

## 備考

- 本ドキュメントは `train_irl_review_acceptance.py` のラベル付けロジックを基に作成
- 他のファイル（`train_irl_within_training_period.py`等）では異なるロジックを使用している場合がある
